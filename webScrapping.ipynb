{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "from dateutil import parser\n",
    "import html\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapCorpus(sources,keyword,nb_docs):\n",
    "\n",
    "    source = \"\"\n",
    "    position = \"\"\n",
    "    company = \"\"\n",
    "    workplace = \"\"\n",
    "    published_date = \"\"\n",
    "    contract_type = \"\"\n",
    "    long_infos = \"\"\n",
    "    # 20 offres par pages\n",
    "    pages = math.ceil(nb_docs/20)\n",
    "\n",
    "    if  \"emploi-territorial\" in sources:\n",
    "        source = \"emploi-territorial\"\n",
    "        rootLink = \"https://www.emploi-territorial.fr\"\n",
    "        # 20 offres par pages\n",
    "        # pages = math.ceil(nb_docs/20)\n",
    "        url = f\"{rootLink}/emploi-mobilite/?adv-search={keyword}&page={pages}\"\n",
    "        response = requests.get(url) \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        root = soup.find(\"body\")\n",
    "        offresLinkElems = root.select(\"div[class*='bloc-lien-offre'] > a[class*='lien-details-offre']\")[:nb_docs]    \n",
    "        links = [rootLink+offresLinkElem.get(\"href\") for offresLinkElem in offresLinkElems]\n",
    "\n",
    "        corpus = list(dict())\n",
    "\n",
    "        for link in links:\n",
    "            response = requests.get(link)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            root = soup.find(\"body\")\n",
    "\n",
    "            position = root.select(\"h2[class*='set-line-emploi']\")[0].text\n",
    "            company = root.select(\"div[class*='offre-item-value'] > strong > a\")[0].text if root.select(\"div[class*='offre-item-value'] > strong > a\") else \"NULL\"\n",
    "            workplace = root.select_one(\"div[class*='offre-item-label']:contains('Lieu de travail') + .offre-item-value\").text if root.select_one(\"div[class*='offre-item-label']:contains('Lieu de travail') + .offre-item-value\") else \"NULL\"\n",
    "            published_date = root.select_one(\"div[class*='px-3']:contains('Publiée le') > .set-color-green\").text if root.select_one(\"div[class*='px-3']:contains('Publiée le') > .set-color-green\") else \"NULL\"\n",
    "            contract_type = root.select_one('div[class*=\"offre-item-label\"]:contains(\"Type d\\'emploi\") + .offre-item-value').text if root.select_one('div[class*=\"offre-item-label\"]:contains(\"Type d\\'emploi\") + .offre-item-value') else \"NULL\"\n",
    "            \n",
    "            long_text = root.select('div[class*=\"offre-item-text\"]')\n",
    "\n",
    "            long_infos = \" \".join([long_text[0].text,long_text[1].text,long_text[2].text])\n",
    "\n",
    "            corpus.append({\"source\":source,\"position\":position,\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":long_infos})\n",
    "    \n",
    "    if \"apec\" in sources:\n",
    "        source = \"apec\"\n",
    "        service = ChromeService(\"C:/Users/leogo/Downloads/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        try:\n",
    "            for page in range(pages):    \n",
    "                try:\n",
    "                    driver.get(f'https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles={keyword}&page={pages}')\n",
    "                    # Initial find of elements\n",
    "                    try:\n",
    "                        deny_cookies_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#onetrust-reject-all-handler'))\n",
    "                        )\n",
    "\n",
    "                        deny_cookies_button.click()\n",
    "                    except TimeoutException:\n",
    "                        pass\n",
    "\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "                    )\n",
    "\n",
    "                    # Getting docs left if last page to query\n",
    "                    if nb_docs%20 != 0 and page==pages-1: \n",
    "                        limit = nb_docs%20+1\n",
    "                        div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, 'div.card-offer')[:limit]\n",
    "                    else :\n",
    "                        div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, 'div.card-offer')\n",
    "                        \n",
    "                    for index in range(len(div_elements_to_click_list)):\n",
    "                        try:\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "                            )\n",
    "                            # Re-find elements after navigating back\n",
    "                            div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, 'div.card-offer')\n",
    "\n",
    "                            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "                            )\n",
    "                            # Check if the index is within the valid range\n",
    "\n",
    "                            div_elements_to_click = div_elements_to_click_list[index]\n",
    "                            company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "                            contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "                            workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "                            published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "                            # Scroll into view\n",
    "\n",
    "                            actions = ActionChains(driver)\n",
    "                            actions.move_to_element(div_elements_to_click).click().perform()\n",
    "\n",
    "                            # Wait for the child element to become present in the DOM\n",
    "                            WebDriverWait(driver, 20).until(\n",
    "                                EC.presence_of_element_located((By.XPATH, f\"//h4[text()='Descriptif du poste']\"))\n",
    "                            )\n",
    "                            # Get the page source after the click\n",
    "                            page_source = driver.page_source\n",
    "\n",
    "                            # Use Beautiful Soup to parse the page source\n",
    "                            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                            # Example: Retrieve the text of a specific element\n",
    "                            desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "                            descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "                            profile = soup.select(\"h4:contains('Profil recherché') + p\")\n",
    "                            profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "                            position = soup.select_one(\"h4:contains('Métier') + span\").text\n",
    "\n",
    "                            long_infos = \" \".join([descText,profileText])\n",
    "                            \n",
    "                            corpus.append({\"source\":source,\"position\":position,\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":long_infos})\n",
    "                        except Exception as e:\n",
    "                            # Print the exception for debugging purposes\n",
    "                            print(f\"Error: {e}\")\n",
    "\n",
    "                        finally:\n",
    "                            # Navigate back to the main page\n",
    "                            driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Print the exception for debugging purposes\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "        finally:\n",
    "            driver.quit()\n",
    "    return(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF79DFE82B2+55298]\n",
      "\t(No symbol) [0x00007FF79DF55E02]\n",
      "\t(No symbol) [0x00007FF79DE105AB]\n",
      "\t(No symbol) [0x00007FF79DE5175C]\n",
      "\t(No symbol) [0x00007FF79DE518DC]\n",
      "\t(No symbol) [0x00007FF79DE8CBC7]\n",
      "\t(No symbol) [0x00007FF79DE720EF]\n",
      "\t(No symbol) [0x00007FF79DE8AAA4]\n",
      "\t(No symbol) [0x00007FF79DE71E83]\n",
      "\t(No symbol) [0x00007FF79DE4670A]\n",
      "\t(No symbol) [0x00007FF79DE47964]\n",
      "\tGetHandleVerifier [0x00007FF79E360AAB+3694587]\n",
      "\tGetHandleVerifier [0x00007FF79E3B728E+4048862]\n",
      "\tGetHandleVerifier [0x00007FF79E3AF173+4015811]\n",
      "\tGetHandleVerifier [0x00007FF79E0847D6+695590]\n",
      "\t(No symbol) [0x00007FF79DF60CE8]\n",
      "\t(No symbol) [0x00007FF79DF5CF34]\n",
      "\t(No symbol) [0x00007FF79DF5D062]\n",
      "\t(No symbol) [0x00007FF79DF4D3A3]\n",
      "\tBaseThreadInitThunk [0x00007FFF1E43257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFF1E82AA58+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = scrapCorpus(sources=[\"emploi-territorial\",\"apec\"],keyword=\"data\",nb_docs=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n",
      "CALL pInsertDW(%s, %s, %s)\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Replace these values with your database connection details\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'database': 'job_scrapping'\n",
    "}\n",
    "\n",
    "def call_dynamic_insert_procedure(cursor, procedure_name, param_dict):\n",
    "    try:\n",
    "        # Prepare the SQL statement with placeholders for parameters\n",
    "        placeholders = ', '.join(['%s'] * len(param_dict))\n",
    "        sql = f\"CALL {procedure_name}({placeholders})\"\n",
    "        print(sql)\n",
    "\n",
    "        # Execute the SQL statement with the values from the dictionary\n",
    "        cursor.callproc(procedure_name, list(param_dict.values()))\n",
    "\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "# Connect to the database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Call the generic stored procedure\n",
    "\n",
    "def insertTable(table_name, column_name, items):\n",
    "    for item in items:\n",
    "        parameters = {'pTableName': table_name, 'pColumnNames': column_name, 'pColumnValues': f'\"{item}\"'}\n",
    "        call_dynamic_insert_procedure(cursor, \"pInsertDW\", parameters)   \n",
    "\n",
    "def refreshDW():\n",
    "    try:\n",
    "        cursor.callproc('pTruncateDW')\n",
    "        insertTable(\"d_website\", 'label', set([item[\"source\"].upper() for item in corpus]))\n",
    "        insertTable(\"d_contract_type\", 'contract_type', set([item[\"contract_type\"].upper() for item in corpus]))\n",
    "        insertTable(\"d_company\", 'label', set([item[\"company\"].upper() for item in corpus]))\n",
    "        insertTable(\"d_city\", 'city', set([item[\"workplace\"].upper() for item in corpus]))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "refreshDW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"OPT'IN RECRUTEMENT\",\n",
       " 'OEB',\n",
       " 'STUDIO RH',\n",
       " 'ADEQUATION',\n",
       " 'FITEC',\n",
       " 'CONSEIL DEPARTEMENTAL DE MEURTHE ET MOSELLE',\n",
       " 'KAISENS DATA',\n",
       " 'ASSYSTEM',\n",
       " 'NULL',\n",
       " 'HELLOWORK',\n",
       " 'CONSEIL DEPARTEMENTAL DES PYRÉNÉES-ATLANTIQUES',\n",
       " 'GRAVOTECH MARKING',\n",
       " 'CONSEIL REGIONAL OCCITANIE ',\n",
       " \"GRAND MONTAUBAN COMMUNAUTÉ D'AGGLOMÉRATION\",\n",
       " 'CONSEIL DEPARTEMENTAL DE  LA SEINE MARITIME',\n",
       " 'METROPOLE AIX-MARSEILLE-PROVENCE',\n",
       " 'CHAVILLE',\n",
       " 'CONSEIL DÉPARTEMENTAL DU CALVADOS',\n",
       " 'DÉPARTEMENT DES HAUTS-DE-SEINE',\n",
       " 'REGION GRAND EST',\n",
       " 'ORGANISATION PROFESSIONNELLE DE LA PREVENTION DANS LE BTP',\n",
       " 'METEOJOB',\n",
       " 'GESER BEST',\n",
       " \"COLLECTIVITE EUROPEENNE D'ALSACE\",\n",
       " 'MICHAEL PAGE INTERNATIONAL FRANCE',\n",
       " 'METROPOLE LYON',\n",
       " 'BUSINESS & DECISION CORPORATE SERVICES',\n",
       " 'NOISY-LE-GRAND',\n",
       " 'GRENOBLE-ALPES MÉTROPOLE']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([item[\"company\"].upper() for item in corpus]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page = 0\n",
      "page = 1\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "service = ChromeService(\"C:/Users/leogo/Downloads/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "key_word = \"data\"\n",
    "driver = webdriver.Chrome(service=service)\n",
    "corpustest = list()\n",
    "try:\n",
    "    for page in range(pages):    \n",
    "        try:\n",
    "            driver.get(f'https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles={key_word}&page={page}')\n",
    "            # Initial find of elements\n",
    "            try:\n",
    "                deny_cookies_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#onetrust-reject-all-handler'))\n",
    "                )\n",
    "\n",
    "                deny_cookies_button.click()\n",
    "            except TimeoutException:\n",
    "                pass\n",
    "\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "            )\n",
    "            div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, 'div.card-offer')\n",
    "            for index in range(len(div_elements_to_click_list)):\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "                    )\n",
    "                    # Re-find elements after navigating back\n",
    "                    div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, 'div.card-offer')\n",
    "\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "                    )\n",
    "                    # Check if the index is within the valid range\n",
    "\n",
    "                    div_elements_to_click = div_elements_to_click_list[index]\n",
    "                    company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "                    contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "                    workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "                    published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "                    # Scroll into view\n",
    "\n",
    "                    actions = ActionChains(driver)\n",
    "                    actions.move_to_element(div_elements_to_click).click().perform()\n",
    "\n",
    "                    # Wait for the child element to become present in the DOM\n",
    "                    WebDriverWait(driver, 20).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//h4[text()='Descriptif du poste']\"))\n",
    "                    )\n",
    "                    # Get the page source after the click\n",
    "                    page_source = driver.page_source\n",
    "\n",
    "                    # Use Beautiful Soup to parse the page source\n",
    "                    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                    # Example: Retrieve the text of a specific element\n",
    "                    desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "                    descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "                    profile = soup.select(\"h4:contains('Profil recherché') + p\")\n",
    "                    profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "                    position = soup.select_one(\"h4:contains('Métier') + span\").text\n",
    "\n",
    "                    corpustest.append({\"position\":position,\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":\" \".join([descText,profileText])})\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Print the exception for debugging purposes\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "                finally:\n",
    "                    # Navigate back to the main page\n",
    "                    driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Print the exception for debugging purposes\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'position': 'Data engineer',\n",
       "  'company': '(CONFIDENTIELLE)',\n",
       "  'workplace': 'Seine-Saint-Denis - 93',\n",
       "  'published_date': '21/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': 'Description du posteNous recrutons un Data Analyst / Data Engineer.Dans un contexte : Datalake / Datalab :Être force de proposition pour permettre la meilleure performance des rapports pour les partenaires métiers, la partie Query, le modèle de données utilisé, la publication le rafraichissement, la disponibilité des données ;Participer à la production de rapports dans le cadre de projet ;Assurer la collecte des besoins auprès des partenaires métiers pour leur garantir un pilotage et une maîtrise de leur processus métier ;Participer à la récolte et à la conception de la répartition des données nécessaires aux rapports sur notre Datalake ;Rédiger une spécification technico fonctionnelle pour chaque reporting à produire et à monitorer ;Réaliser des tests de recette auprès de partenaires métiers, ainsi que des tests de performance avec nos partenaires IT ;Réaliser les développements et les publications jusqu’en production des rapports.Tâches :Modéliser les traitements de données ;Produire les rapports et tableaux de bords ;Réaliser et maintenir à jours tous les supports de documentations ;Spécification technico-fonctionnelle ;PV de recette ;Dossier d’exploitation ;Être force de proposition, pour produire un service de qualité auprès de nos partenaires métier.\\xa0 Description du profilProfil recherché :De formation Bac +5 Ecole d’Ingénieur ou équivalentAnglais courant (niveau B2 minimum)Vous avez +5 ans d’expérience minimum dans la double compétence Data Analyst / Data EngineerCompétences :Maitriser toutes les facettes d’un outil de datavisualisation et d’ETL.Environnement Technique : Power BI, SQL, Azure, PowerQuery, DataLake, Python, R, Excel'},\n",
       " {'position': 'Data engineer',\n",
       "  'company': 'PRO À PRO',\n",
       "  'workplace': 'Montauban - 82',\n",
       "  'published_date': '12/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': 'Description du posteNous recrutons un Data Analyst / Data Engineer.Dans un contexte : Datalake / Datalab :Être force de proposition pour permettre la meilleure performance des rapports pour les partenaires métiers, la partie Query, le modèle de données utilisé, la publication le rafraichissement, la disponibilité des données ;Participer à la production de rapports dans le cadre de projet ;Assurer la collecte des besoins auprès des partenaires métiers pour leur garantir un pilotage et une maîtrise de leur processus métier ;Participer à la récolte et à la conception de la répartition des données nécessaires aux rapports sur notre Datalake ;Rédiger une spécification technico fonctionnelle pour chaque reporting à produire et à monitorer ;Réaliser des tests de recette auprès de partenaires métiers, ainsi que des tests de performance avec nos partenaires IT ;Réaliser les développements et les publications jusqu’en production des rapports.Tâches :Modéliser les traitements de données ;Produire les rapports et tableaux de bords ;Réaliser et maintenir à jours tous les supports de documentations ;Spécification technico-fonctionnelle ;PV de recette ;Dossier d’exploitation ;Être force de proposition, pour produire un service de qualité auprès de nos partenaires métier.\\xa0 Description du profilProfil recherché :De formation Bac +5 Ecole d’Ingénieur ou équivalentAnglais courant (niveau B2 minimum)Vous avez +5 ans d’expérience minimum dans la double compétence Data Analyst / Data EngineerCompétences :Maitriser toutes les facettes d’un outil de datavisualisation et d’ETL.Environnement Technique : Power BI, SQL, Azure, PowerQuery, DataLake, Python, R, Excel'},\n",
       " {'position': 'Data scientist',\n",
       "  'company': 'ARCHERY DATA & ANALYTICS',\n",
       "  'workplace': 'Tours - 37',\n",
       "  'published_date': '08/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': 'Rattaché(e) au Responsable du service Data, vos missions seront les suivantes :Vous recueillez les besoins auprès des différentes directions, trouver les sources de données pertinentes et les retraitez pour réaliser des analyses métiers (tableaux de bord, reporting, …),Vous réalisez les extractions des données du système source et traduisez ces données business en données statistiques, vous donnez du sens à la data,Vous contrôlez la qualité des données et vous les documentez (de la source à l’indicateur),Vous construisez et faites évoluer les applications à partir des solutions de Business Intelligence et/ou Web Analytics pour permettre aux différentes équipes d’avoir une vision cohérente des services de l’entreprise,Vous assurez la bonne interprétation et la diffusion des rapports d’analyse résultant des solutions BI et/ou Web Analytics,Vous avez la capacité de développer applications Analytics (Bonnes maitrise de Python, SQL) et/ou d’implémenter des modèles de Machine Learning et Système de Recommandations. De formation Bac + 4/5 en informatique avec spécialisation en analyses statistiques, vous avez une première expérience sur un poste similaire, idéalement dans le secteur de la distribution.Vous avez une bonne connaissance des langages SQL, Python, des outils de Web Analytics et des technologies spécifiques au big data.Vous êtes à l’aise dans la modélisation de bases de données relationnelles et multi-dimensionnelles et maitrisez les solutions de Datavisualisation de type Qliksense, Tableau ou Power BIVous aimez travailler en équipe, avez un bon sens de la communication, du service client, et une bonne capacité à cerner, et synthétiser les problématiques. Vous avez un esprit d’analyse développé et d’excellentes qualités de rigueur et d’organisation.'},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'ANAYA',\n",
       "  'workplace': 'Paris 01 - 75',\n",
       "  'published_date': '24/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"LA MISSIONNotre client souhaite mettre à disposition des informations concernant ses actifs techniques pour orienter les stratégies de gestion des actifs. Ces informations sont de deux natures :Qualité de la donnée (QDD) pour la Gestion des Actifs : présenter la qualité (complétude, cohérence…) des données utiles à la gestion des actifs, il s’agit principalement de données patrimoniales et géographiques,Grandeurs éclairantes (GE) pour la Gestion des Actifs : mettre en évidence des indicateurs pertinents pour identifier des dynamiques développement des parcs de matériels, de vieillissement ou de dégradation prématurée, pour éclairer les décideurs sur la mise en place de politiques techniques ou la mise à jour de politiques existantes.Des premiers prototypes de traitement de données ont été mis en place pour les deux tableaux de bord et la mission a pour objectif de généraliser les traitements à l’ensemble des données et indicateurs identifiés et d’automatiser la production des tableaux de bord. VOTRE PROFILVous êtes au minimum confirmé.e (Au minimum 3 ans d'expérience hors alternances. Nous avons aussi des besoins pour des candidat.es très expérimenté.es).Pour mener à bien cette mission vous devrez :Maîtriser PythonMaîtrise RMaîtriser différents formats de données, y compris volumineuxSi possible avoir développé des API en R, avoir utilisé RShiny, etc.Utiliser Git\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'CADREMPLOI',\n",
       "  'workplace': 'Niort - 79',\n",
       "  'published_date': '27/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"¿¿Instruire la demande. extraire, mettre en forme et vérifier les données et résultats produits.\\n¿¿Mettre en oeuvre les analyses associées en apportant l'expertise nécessaire à la définition et production d'indicateurs\\n¿¿Préparer et explorer les données\\n¿¿Etudes d'impacts\\n¿¿Rédaction des spécifications fonctionnelles et techniques\\n¿¿Concevoir techniquement la solution\\n¿¿Etre en support du développement de la solution\\n¿¿Approuver la solution (techniquement et fonctionnellement)\\n¿¿Livrer la solution\\n¿¿Gérer les incidents et les impacts projets\\n¿¿Composants applicatifs et documentation associée\\n¿¿Plan et fiches de test\\n¿¿Suivi de son activité\\n¿¿Supports de présentation ... 👉Capacité à comprendre les besoins métiers\\n👉Force d'analyse et de modélisation des architectures d'alimentation vers les bases décisionnelles\\n👉Bonne connaissance des pratiques de tests et recettes techniques et fonctionnelles\\n👉Connaissance des pratiques ETL\\n👉Qualités relationnelles et rédactionnelles\\n👉Autonomie ...\"},\n",
       " {'position': 'Data engineer',\n",
       "  'company': 'CARAZ',\n",
       "  'workplace': 'Paris 08 - 75',\n",
       "  'published_date': '11/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Vous intégrez l'équipe Datahub de l'entreprise composée d'un Lead Data Engineer, 3 Data Engineers et une Product Manager.Missions principales :\\xa0Créer de nouveaux jeux de données pour répondre aux besoins métiers et faire évoluer les jeux de données existantsProgrammer, automatiser et optimiser les algorithmes afin de permettre au Data Scientist et au Data Analyst d'analyser les données collectéesParticiper à l’amélioration continue de la plateforme en restant dynamique sur la veille technologique et en étant force de propositionStack:\\xa0SQL, Python, Azure, Azure DevOps, Sonarcloud, Snyk, Terraform et Jira. Titulaire d’un diplôme Bac +5 en Ecole d'Ingénieur ou Université avec une spécialité en Informatique ou Data, vous avez min. de 5 ans d'expérience en tant que Data Engineer sur Azure.Compétences requises :\\xa0Maîtrise des bases de données relationnelles type SQL ServerTraitements des données et Data cleaning (Python, SQL)Connaissance AzureBon niveau Anglais\"},\n",
       " {'position': 'Data engineer',\n",
       "  'company': 'MICHAEL PAGE INTERNATIONAL FRANCE',\n",
       "  'workplace': 'Paris 01 - 75',\n",
       "  'published_date': '12/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Vous intégrez l'équipe Datahub de l'entreprise composée d'un Lead Data Engineer, 3 Data Engineers et une Product Manager.Missions principales :\\xa0Créer de nouveaux jeux de données pour répondre aux besoins métiers et faire évoluer les jeux de données existantsProgrammer, automatiser et optimiser les algorithmes afin de permettre au Data Scientist et au Data Analyst d'analyser les données collectéesParticiper à l’amélioration continue de la plateforme en restant dynamique sur la veille technologique et en étant force de propositionStack:\\xa0SQL, Python, Azure, Azure DevOps, Sonarcloud, Snyk, Terraform et Jira. Titulaire d’un diplôme Bac +5 en Ecole d'Ingénieur ou Université avec une spécialité en Informatique ou Data, vous avez min. de 5 ans d'expérience en tant que Data Engineer sur Azure.Compétences requises :\\xa0Maîtrise des bases de données relationnelles type SQL ServerTraitements des données et Data cleaning (Python, SQL)Connaissance AzureBon niveau Anglais\"},\n",
       " {'position': 'Data engineer',\n",
       "  'company': 'HELLOWORK',\n",
       "  'workplace': 'Paris 01 - 75',\n",
       "  'published_date': '07/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"En tant que Data Engineer, vous rejoindrez l'équipe Datahub, constituée d'un Lead Data Engineer, de trois Data Engineers et d'une Product Manager. CORUM a créé son propre Datahub autour des technologies Azure (Azure SQL Server, Data Factory, Azure Function, Cosmos DB). Ce datahub intègre des données brutes diverses (Csv, CRM Dynamics, API REST, Excel), les nettoie et alimente des Datamarts.Sous la supervision du Lead Data Engineer, vous serez amené à :* Créer de nouveaux jeux de données pour répondre aux besoins métiers et faire évoluer les jeux de données existants,* Programmer, automatiser et optimiser nos algorithmes afin de permettre au Data Scientist et au Data Analyst d'analyser les données collectées,* Participer à l'amélioration continue de la plateforme en restant dynamique sur la veille technologique et en étant force de proposition.Les langages utilisés sont SQL et Python.Technologies :* Azure (Azure SQL Server, Data Factory, Azure Function, Cosmos DB),* Azure DEVOPS pour la partie CI/CD,* Sonarcloud et Snyk pour l'analyse de code,* Terraform pour déployer nos infrastructures,* Jira pour la gestion du sprint. * Vous êtes titulaire d'un diplôme Bac +5 minimum (école d'Ingénieur ou Université) spécialisé en informatique ou Data,* Vous avez une expérience d'au moins 5 ans en tant que Data Engineer sur Azure,* Vous êtes rigoureux et intransigeant sur la livraison zéro défaut,* Vous faites preuve d'autonomie et êtes force de proposition,* Anglais courant.Compétences souhaitées :* Maîtrise des bases de données relationnelles type SQL Server,* Traitements des données et Data cleaning (Python, SQL),* Connaissance Azure.\"},\n",
       " {'position': 'Data engineer',\n",
       "  'company': 'EVOTEO',\n",
       "  'workplace': 'Lyon 07 - 69',\n",
       "  'published_date': '21/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"En tant que Data Engineer, vous rejoindrez l'équipe Datahub, constituée d'un Lead Data Engineer, de trois Data Engineers et d'une Product Manager. CORUM a créé son propre Datahub autour des technologies Azure (Azure SQL Server, Data Factory, Azure Function, Cosmos DB). Ce datahub intègre des données brutes diverses (Csv, CRM Dynamics, API REST, Excel), les nettoie et alimente des Datamarts.Sous la supervision du Lead Data Engineer, vous serez amené à :* Créer de nouveaux jeux de données pour répondre aux besoins métiers et faire évoluer les jeux de données existants,* Programmer, automatiser et optimiser nos algorithmes afin de permettre au Data Scientist et au Data Analyst d'analyser les données collectées,* Participer à l'amélioration continue de la plateforme en restant dynamique sur la veille technologique et en étant force de proposition.Les langages utilisés sont SQL et Python.Technologies :* Azure (Azure SQL Server, Data Factory, Azure Function, Cosmos DB),* Azure DEVOPS pour la partie CI/CD,* Sonarcloud et Snyk pour l'analyse de code,* Terraform pour déployer nos infrastructures,* Jira pour la gestion du sprint. * Vous êtes titulaire d'un diplôme Bac +5 minimum (école d'Ingénieur ou Université) spécialisé en informatique ou Data,* Vous avez une expérience d'au moins 5 ans en tant que Data Engineer sur Azure,* Vous êtes rigoureux et intransigeant sur la livraison zéro défaut,* Vous faites preuve d'autonomie et êtes force de proposition,* Anglais courant.Compétences souhaitées :* Maîtrise des bases de données relationnelles type SQL Server,* Traitements des données et Data cleaning (Python, SQL),* Connaissance Azure.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'DEVOTEAM',\n",
       "  'workplace': 'Levallois-Perret - 92',\n",
       "  'published_date': '23/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Dans le cadre de notre croissance et pour répondre aux besoins évolutifs de nos clients, nous recherchons un.e #DATA Analyst afin d intégrer nos équipes.Vos missions :Analyser les besoins avec les équipes métiers et #DATA analystesParticiper\\xa0aux choix des solutions à mettre en placeConcevoir, développer et garantir la qualité des traitements de données et réaliser les tests de validationCollecter, sauvegarder et traiter\\xa0dles donnéesAdministrer\\xa0un clusterRéaliser les ordonnancements des traitementsIndustrialiser les traitements #DATA science au sein du #DATA lakeTravailler sur la mise en place du déploiementAssurer la mise en œuvre, le suivi, l'exploitation et la mise à jour des différents outils déployés Nous recherchons avant tout des personnalités : curieuses, habiles, sociales, adaptables et passionnées.De formation BAC+5 (Master 2,DESS,DEA), formation ingénieure ou informatique, tu as une expérience d'au moins 2 ans en Analyse de #DATA.Les technos :Base de données GCP/ BigQueryDéveloppement (Python, R)QlikSense/ Tableau Software / Power BIEn bonus :Evolution dans un environnement Big #DATACapacité à gérer un projet de #DATA AnalysisCe poste en CDI est à pourvoir dès que possible sur la région lyonnaise.Vous êtes un futur collaborateur acteur, en quête de perspectives d évolution, capable de rigueur et d'esprit d'analyse ? Rejoignez-nous !\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'HELLOWORK',\n",
       "  'workplace': 'Montauban - 82',\n",
       "  'published_date': '17/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Nous recherchons pour le compte de notre client un Data Analyst (F/H). Le poste est à pourvoir en CDI chez un client final à Montauban.Le poste se découpe en plusieurs activités :-  Data Strategy et mise en place de projets Data : le Data Analyst participera à l'élaboration d'une stratégie Data cohérente et générant de la valeur pour l'entreprise. Des projets Data seront leadés par le Data Analyst.-  Création de Reportings Power BI :Répondre aux besoins des différents services (Sales, Supply Chain, Marketing, Engineering) en concevant des tableaux de bord à l'aide de Power BI. Création de rapports automatisés pour suivre les indicateurs clés de performance et les tendances.-  Manipulation et Nettoyage des Données :Utilisation de Python & SQL ou d'autres outils (machine learning, ou AI au sens large) appropriés pour collecter, nettoyer, et préparer les données en vue de l'analyse. Identification et résolution des incohérences et des erreurs dans les données.-  Customer Relationship Management (CRM) :Collaboration avec les équipes CRM pour concevoir des stratégies de gestion des relations clients basées sur les insights tirés des données. Utilisation des données pour personnaliser les interactions et améliorer la rétention et la fidélisation des clients.-  Data Warehouse :Participation à la conception et à la mise en place d'un entrepôt de données pour stocker et organiser efficacement les données de l'entreprise. Création de schémas et de structures de données adaptées pour faciliter l'analyse et le reporting.-  Customer Data Platform (CDP) :Gestion de la plateforme CDP pour l'intégration, la gestion et l'analyse des données clients. Création de segments, suivi des comportements, et recommandation d'améliorations basées sur les données clients.Compétences techniques nécessaires : PowerBI, Python, Excel.Avoir déjà approché un ERP/CRMAnglais courant Vous devez avoir un diplôme universitaire en informatique, en statistiques, en sciences des données ou dans un domaine connexe.Vous avez une expérience professionnelle pertinente (à minima 3 ans) en tant que Data Analyst, avec une expérience démontrée dans la manipulation, le nettoyage et l'analyse de données.Un anglais courant est nécessaire afin d'évoluer dans un contexte international.Vous avez une expérience dans la conception de solutions de gestion de données et de reporting, en utilisant des outils tels que Power BI.Une expérience tangible sur des outils CRM, Data Warehouse ou CDP est un plus important.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'EXPECTRA',\n",
       "  'workplace': 'Montauban - 82',\n",
       "  'published_date': '14/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Nous recherchons pour le compte de notre client un Data Analyst (F/H). Le poste est à pourvoir en CDI chez un client final à Montauban.Le poste se découpe en plusieurs activités :-  Data Strategy et mise en place de projets Data : le Data Analyst participera à l'élaboration d'une stratégie Data cohérente et générant de la valeur pour l'entreprise. Des projets Data seront leadés par le Data Analyst.-  Création de Reportings Power BI :Répondre aux besoins des différents services (Sales, Supply Chain, Marketing, Engineering) en concevant des tableaux de bord à l'aide de Power BI. Création de rapports automatisés pour suivre les indicateurs clés de performance et les tendances.-  Manipulation et Nettoyage des Données :Utilisation de Python & SQL ou d'autres outils (machine learning, ou AI au sens large) appropriés pour collecter, nettoyer, et préparer les données en vue de l'analyse. Identification et résolution des incohérences et des erreurs dans les données.-  Customer Relationship Management (CRM) :Collaboration avec les équipes CRM pour concevoir des stratégies de gestion des relations clients basées sur les insights tirés des données. Utilisation des données pour personnaliser les interactions et améliorer la rétention et la fidélisation des clients.-  Data Warehouse :Participation à la conception et à la mise en place d'un entrepôt de données pour stocker et organiser efficacement les données de l'entreprise. Création de schémas et de structures de données adaptées pour faciliter l'analyse et le reporting.-  Customer Data Platform (CDP) :Gestion de la plateforme CDP pour l'intégration, la gestion et l'analyse des données clients. Création de segments, suivi des comportements, et recommandation d'améliorations basées sur les données clients.Compétences techniques nécessaires : PowerBI, Python, Excel.Avoir déjà approché un ERP/CRMAnglais courant Vous devez avoir un diplôme universitaire en informatique, en statistiques, en sciences des données ou dans un domaine connexe.Vous avez une expérience professionnelle pertinente (à minima 3 ans) en tant que Data Analyst, avec une expérience démontrée dans la manipulation, le nettoyage et l'analyse de données.Un anglais courant est nécessaire afin d'évoluer dans un contexte international.Vous avez une expérience dans la conception de solutions de gestion de données et de reporting, en utilisant des outils tels que Power BI.Une expérience tangible sur des outils CRM, Data Warehouse ou CDP est un plus important.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'ANAYA',\n",
       "  'workplace': 'Paris 09 - 75',\n",
       "  'published_date': '24/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Nous recherchons pour le compte de notre client un Data Analyst (F/H). Le poste est à pourvoir en CDI chez un client final à Montauban.Le poste se découpe en plusieurs activités : \\n- Data Strategy et mise en place de projets Data : le Data Analyst participera à l'élaboration d'une stratégie Data cohérente et générant de la valeur pour l'entreprise. Des projets Data seront leadés par le Data Analyst.\\n\\n- Création de Reportings Power BI : \\nRépondre aux besoins des différents services (Sales, Supply Chain, Marketing, Engineering..) en concevant des tableaux de bord à l'aide de Power BI. Création de rapports automatisés pour suivre les indicateurs clés de performance et les tendances. \\n\\n- Manipulation et Nettoyage des Données : \\nUtilisation de Python & SQL ou d'autres outils (machine learning, ou AI au sens large) appropriés pour collecter, nettoyer, et préparer les données en vue de l'analyse. Identification et résolution des incohérences et des erreurs dans les données. \\n\\n- Customer Relationship Management (CRM) : \\nCollaboration avec les équipes CRM pour concevoir des stratégies de gestion des relations clients basées sur les insights tirés des données. Utilisation des données pour personnaliser les interactions et améliorer la rétention et la fidélisation des clients. \\n\\n- Data Warehouse : \\nParticipation à la conception et à la mise en place d'un entrepôt de données pour stocker et organiser efficacement les données de l'entreprise. Création de schémas et de structures de données adaptées pour faciliter l'analyse et le reporting. \\n\\n- Customer Data Platform (CDP) : \\nGestion de la plateforme CDP pour l'intégration, la gestion et l'analyse des données clients. Création de segments, suivi des comportements, et recommandation d'améliorations basées sur les données clients. \\n\\nCompétences techniques nécessaires : PowerBI, Python, Excel.\\nAvoir déjà approché un ERP/CRM\\nAnglais courant Vous devez avoir un diplôme universitaire en informatique, en statistiques, en sciences des données ou dans un domaine connexe. \\nVous avez une expérience professionnelle pertinente (à minima 3 ans) en tant que Data Analyst, avec une expérience démontrée dans la manipulation, le nettoyage et l'analyse de données. \\nUn anglais courant est nécessaire afin d'évoluer dans un contexte international.\\nVous avez une expérience dans la conception de solutions de gestion de données et de reporting, en utilisant des outils tels que Power BI. \\nUne expérience tangible sur des outils CRM, Data Warehouse ou CDP est un plus important.\"},\n",
       " {'position': 'Data engineer',\n",
       "  'company': 'MYDRAL',\n",
       "  'workplace': 'Paris 02 - 75',\n",
       "  'published_date': '27/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"A titre d'exemple, le.la consultant.e aura pour missions :\\xa0Remédiation du code existant pour mise en conformité aux standards BNPP;Mise en place des process d'industrialisation de l'application (tests, déploiements, architecture);Documentation;Analyse et développement des nouvelles évolutions. VOTRE PROFILMaîtrise Language - PYTHONMaîtrise Language - SQLVous pratiquez aussi d'autres technologies telles que celles-ci (non exhaustif) :Pratique Language - SHELLNotions Outils - Quality CenteretcMaîtrise Anglais Vous avez au minimum 5 ans d'expérience. Nous cherchons aussi\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'INETUM',\n",
       "  'workplace': 'Lille - 59',\n",
       "  'published_date': '13/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les tâches proposées ?Sous la supervision du Directeur des services, vous intégrez une équipe de purs\\xa0players de la BI, basée en Île-de-France. Vous participez à toutes les phases de mise en œuvre d une application décisionnelle de BI agile et êtes amené à :Analyser l'existantRecueillir les besoins et estimer les chargesPrendre en charge les spécifications fonctionnellesAnimer des ateliers clientModéliser des processus métiers / Comportements à partir des données sourcesEffectuer des connexions de donnéesIntégrer la solutionCréer de KPIs et Dashboards prédictifs pour le métierCréer des applications sous Tableau SoftwareRédiger et suivre la stratégie de recetteRéaliser et suivre les développementsFormer des utilisateurs \\xa0Le profil recherché ?Passionné de la Data et diplômé d'un BAC+5 en Ecole d ingénieur (EISTI, Polytech, Télécom Paristech, MIAGE, etc.)Vous avez\\xa0une\\xa0expérience significative\\xa0(par exemple dans le cadre d'alternance) sur\\xa0des projets data\\xa0avec de fortes compétences en modélisation (Analyse de données, modélisation statistique ),\\xa0réalisation d applications décisionnelles et datavisualisation.Vous souhaitez monter en compétences sur les outils de nos partenaires :\\xa0Tableau\\xa0Desktop, Tableau\\xa0Server, Tableau Prep,\\xa0Knime\\xa0Analytics, Knime Server, Vertica, Snowflake, etc.\\xa0Vous avez de bonnes connaissances techniques sur les outils de Data Preparation, de Data Science, de Stockage de la donnée et de Data visualisation, etc.Vous avez développé un fort sens du service, un bon relationnel avec vos clients et la rigueur nécessaire au succès de vos projets.Qualités indispensables pour réussir chez Mydral : smart, réactif, autonome, rigoureux, fiable, organisé et SYMPA !Vous vous reconnaissez dans cette description ? Oui ?! Nous avons une place pour vous !\"},\n",
       " {'position': 'Data engineer',\n",
       "  'company': 'KAISENS DATA',\n",
       "  'workplace': 'Fontenay-sous-Bois - 94',\n",
       "  'published_date': '13/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Dans le cadre de la croissance de notre agence lilloise, nous développons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv.Les besoins métiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversité de compétences.Vous pourriez être l’un d’eux et rejoindre Inetum.En tant que Data Engineer, vos principales missions consistent àAnalyser et retranscrire le besoin clientConcevoir et mettre en œuvre les solutions permettant de traiter des volumes de données important afin de les mettre à disposition des Data Analyst ou Data ScientistVous êtes le premier maillon de la chaîne garantissant l'intégrité et la qualité de la donnée Pour mener à bien votre rôle, il vous fautUne maîtrise de la conception des entrepôts de donnéesUne expertise dans le stockage de données et leurs manipulationsBase de données parmi les SGBD MySQL, PostgreSQL, Oracle, Snowflake, BigQuery, etc...NoSQL parmi MongoDB, Cassandra, HBase, Neo4J, etc...ETL parmi Talend, Stambia, SSIS, etc...Une appétence pour la programmation parmi Python, Scala, Java, NodeJS, etc..Et si en plus vous disposez des compétences dans les environnements cloud et/ou dans les technologies BigData Hadoop, Spark, Kafka, etc...un choix de missions encore plus large s'offre à vous.Vous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !Notre plusRejoindre la région Nord-Est, c’est bénéficier des avantages d’un Grand Groupe tout en gardant la proximité régionale.Nous mettrons tout en œuvre pour vous apporter un équilibre vie perso / vie pro. C’est pourquoi nous vous proposons un rythme hybride (selon les contraintes clients).Inetum a d’ailleurs signé un accord de télétravail en 2021 pour que chaque collaborateur puisse adapter son rythme de travail.Une trajectoire de carrière personnalisée et adaptée à vos souhaits d'évolution grâce à une implantation à l’international (26 pays, 7 Fablab), des formations ciblées et des projets couvrant l’ensemble de la chaîne de valeur IT (+25 filières métiers).Intégrer un collectif d’experts partageant des valeurs de solidarité et d’excellence.\"},\n",
       " {'position': 'Data engineer',\n",
       "  'company': 'CENISIS',\n",
       "  'workplace': 'Lille - 59',\n",
       "  'published_date': '13/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Kaisens data est un éditeur de logiciel informatique spécialisé en Data science / Machine Learning / TextMining avec une filiale de conseil.Dans le cadre d'un projet d'analyse sémantique du contenu textuel, KAISENS DATA recrute 2 à 3 Data Engineer.Vous êtes intéressé(e)s par le défi ? Rejoignez-nous !Kaisens Data, experts dans la conception et la réalisation de projets Big Data et Data Science, nous partageons notre activité entre l'édition de logiciels et le conseil.Nous proposons des solutions sur mesure et accompagnons nos clients au plus près de leurs projets.Nous traitons le Churn en temps réel, le smart pricing, la détection de fraude, le dédoublonnage de stock, la prédiction de pannes, l'analyse de sentiments et bien d autres applications.Votre mission :Participer aux projets R&D Big Data réalisées en interne ou chez nos clients.Conseiller sur les meilleurs choix techniques en fonction des cas d'usages.Concevoir et développer des solutions Big Data industrialisées.Assurer le suivi, les tests et la qualité des développements réalisés. Prérequis :Solide socle technique (BI / Big Data / Traitement des données / Analyse textuelle).Autonomie, initiative et sens de la pédagogie.La maitrise, à minima, de l'un des langages suivants est un pré requis : Python, Java, Scala.Niveau d'études minimum : Bac+5Formation / Spécialisation : Data Engineer.Niveau d'expérience minimum : Au moins 1\\xa0ans.Avantages :Salaire selon le profilAvantage en nature tickets restaurant\\xa0 + 50 % frais transportsMutuellePlusieurs possibilités d'évolution de carrière.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'EPSILON FRANCE',\n",
       "  'workplace': 'Paris 11 - 75',\n",
       "  'published_date': '30/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Tu souhaites rejoindre une communauté Data Addict à taille humaine ?\\xa0Nous recherchons un\\xa0Data Analyst F/H\\xa0qui aura un rôle à part entière dans la communauté CENISIS.\\xa0Nous t'apportons l'opportunité d'intervenir sur un large choix de projets mais également de faire partie de la CENISIS Academy.\\xa0\\xa0\\xa0Tes missions ?\\xa0Comprendre les besoins et les enjeux du client afin d'apporter une vision cohérente de ses activités, \\xa0Recueillir, traiter et étudier les données afin de soumettre des recommandations pertinentes, \\xa0Exploiter les informations recueillies par différents canaux afin de faciliter les prises de décisions du client, \\xa0Collaborer à la mise en production de requêtes. \\xa0 Tu es issu(e) d'une formation supérieure Bac+3/5 de type licence ou master dans le domaine de l'ingénierie avec une orientation Data. Idéalement tu possèdes une expérience significative de minimum 5 ans dans la Data.\\xa0\\xa0Ton savoir-être :\\xa0\\xa0Ta capacité à fédérer une équipe et à contribuer à la réussite de celle-ci dans ses différents projets\\xa0Ta curiosité, ton envie de toujours innover, et ton autonomie\\xa0\\xa0Tu es force de proposition et tu aimes le challenge et challenger les autres\\xa0Ta différence, ce qui fait ta force et ta richesse pour l'entreprise\\xa0\\xa0Ton savoir-faire :\\xa0\\xa0Ton appétence pour le management des SI\\xa0\\xa0Ta connaissance des méthodes de développements agiles (SCRUM, sprint)\\xa0Ta maîtrise des outils techniques tels que les Databases (Oracle, SQL Server, ), l'utilisation de tableau SoftWare, MetaBase\\xa0Alors tu es partant(e) pour relever le défi ? N' hésite pas à postuler, ce serait le début d une superbe aventure ensemble !\\xa0\"},\n",
       " {'position': 'Data scientist',\n",
       "  'company': 'CADREMPLOI',\n",
       "  'workplace': 'Paris 01 - 75',\n",
       "  'published_date': '08/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Vous intégrerez le Pôle Data Science, constitué de 90 personnes intervenant directement chez le client ou depuis le siège.Nous accompagnons nos clients sur toutes les problématiques métier qui touchent à la Data\\xa0:- La connaissance client pour accompagner les annonceurs dans la personnalisation et l’optimisation du parcours client (dont la mise en place d’outils de modélisation tels que des segmentations, scores…)-\\xa0 L’Intelligence Artificielle et la Data Science pour mettre en place des outils permettant d’optimiser les processus d’entreprises et proposer de nouveaux services apporteurs de valeur-\\xa0 Le développement de l’insight sur des données CRM, Digitales et Média pour apporter une vision 360 aux annonceurs afin de les aider dans leur prise de décision, dans leurs choix d’investissements médias et digitaux (modèles d’attributions et de contribution, MMM…) et dans le développement d’outils permettant d’acquérir des nouvelles cibles à travers des analyses de parcours et des look alike.QUE FAIT UN CONSULTANT CONFIRME DATA SCIENTIST/DATA ANALYST\\xa0(H/F)\\xa0- Réalisez des études statistiques (data management, reporting, scoring, segmentation, analyses de résultats d’enquêtes …) adaptées aux besoins de nos clients-\\xa0Déployez les méthodes de Machine Learning adaptées pour répondre aux problématiques\\xa0 \\xa0 posées,- Restituez les résultats au client dans le respect des engagements de qualité et de délai,-\\xa0Mesurez l’efficacité des actions marketing et digitales mises en place,- Participez au développement de nouvelles approches. De formation supérieure en statistiques, vous avez acquis au moins 3 ans d'expériences en tant que Data Scientist\\xa0/ Data Analyst .\\xa0Vous maîtrisez les méthodes statistiques et leurs applications opérationnelles, ainsi que l’un des principaux outils statistiques du marché Python, R, SAS, Spark.Vous avez déjà travaillé sur une plateforme Cloud\\xa0: Google, Azure.Curieux, ouvert, vous avez à cœur de mettre votre passion pour la Data Science au service de la réussite opérationnelle de vos projets.CHOISISSEZ :\\xa0Un centre de compétences spécialisé en Data Science,Des formations sur des sujets pointus (Machine Learning, R, Python, Py Spark, GCP, Agilité, …),Un parcours collaborateur dédié et de nombreuses possibilités d’évolutions,Notre diversité de projets et de clients (BPCE, Leclerc, Fnac, Blédina, Beaumanoir, Petit Bateau, ACCOR, Système U, Renault, Engie),Notre fort investissement dans l’innovation (20 projets par an).\\xa0Informations supplémentairesLocalisation\\xa0: Campus 5.9 (Wasquehal)Rémunération\\xa0:\\xa0Nous savons que le salaire est un élément essentiel pour vous ! C’est pourquoi nous en parlerons sans tabou dès les premiers échanges.\\xa0Les + EPSILON France\\xa0:Tickets Restaurants\\xa0Travail Hybride\\xa0grâce à notre Accord Télétravail qui autorise jusqu’à 2 jours par semaineEngagé avec le\\xa0Forfait Mobilité DurableDispositif d’Epargne Salariale\\xa0(Accord d’intéressement et de participation)Work Your World\\xa0: travailler dans le monde entier jusqu’à 6 semaines continues chaque année à partir d’un an d’anciennetéFormation\\xa0: +30.000 modules accessibles en e-learning, et comprenant des certifications, en partenariat avec LinkedIn Learning sur la plateforme propriétaire Marcel Classes\\xa0Viva La Différence !Cette philosophie de Publicis Groupe témoigne depuis toujours de notre engagement pour la diversité et de la conviction que nos talents sont notre plus grande richesse et notre meilleur atout. Nous valorisons ainsi toutes les singularités, sans distinction d’âge, de sexe, de couleur de peau, d’origine sociale, de religion, ou d’orientation sexuelle… seules les compétences et l’énergie comptent. Nous encourageons toutes les candidatures qualifiées et seront ravis d’accompagner tout au long du processus de recrutement, de manière personnalisée, une candidate ou un candidat en situation de handicap qui en ferait la demande. Publicis France est engagé pour l’égalité des chances et l’équité d’opportunités pour tous et toutes.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'FINANCEPEOPLE',\n",
       "  'workplace': 'Landerneau - 29',\n",
       "  'published_date': '14/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"En tant que Data Analyst spécialisé dans la transition/migration. Vous serez responsable de la mise en place des programmes dans notre nouveau système tout en maintenant l'ancien. Votre analyse des mécanismes de migration guidera les décisions métier. Vous travaillerez sur plus de 400 flux, internes et externes.\\n\\nResponsabilités : \\n\\n * Gérer la transition/migration des outils back office,\\n * Analyser les mécanismes de migration pour des décisions éclairées,\\n * Collaborer avec les équipes métier et garantir la qualité des données,\\n * Gérer plus de 400 flux internes et externes,\\n * Identifier des opportunités d'amélioration et optimiser les flux de données. ... * Expérience solide en Data Analyst, de préférence en transition/migration,\\n * Excellentes compétences analytiques et maîtrise des outils et langages java et talend,\\n * Gestion de projet, autonomie et respect des délais,\\n * Curiosité, adaptabilité et bonnes compétences en communication,\\n * Expérience dans la gestion de multiples flux est un plus,\\n * Diplôme en informatique, statistiques ou domaine connexe. ...\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'HELLOWORK',\n",
       "  'workplace': 'Guyancourt - 78',\n",
       "  'published_date': '07/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"En tant que Data Analyst, vous serez responsable de projets data orientés métier avec le recueil, la structuration et la valorisation des données, que ce soit pour les fonctions support avec les besoins de reporting opérationnels et analytiques liés à la mise en place du nouvel ERP, ou pour les activités coeur de métier de l'ingénierie, du conseil ou de l'exploitation.Vous contribuerez à l'analyse des données provenant des différents systèmes opérationnels et définirez des indicateurs, jusqu'à la construction d'outils d'analyse et de visualisation graphique des données.Vous veillerez à l'atteinte des objectifs et des résultats escomptés en coordonnant les dimensions techniques, sécuritaires et financières. De formation Bac +5, vous avez une bonne maîtrise des outils d'analyse et de traitement de données quantitatives : décisionnel / big data (Data warehouse, Datamart, Datalake, Lakehouse).Vous maîtrisez la modélisation de données, en particulier les méthodes de modélisation pour usage analytique (modélisation en étoile ou dimensionnelle). Vous concevez les traitements de données permettant de transformer des données transactionnelles en données analytiques.Vous avez une bonne connaissance opérationnelle des outils BI, particulier Power BI. La connaissance des outils de reporting Oracle (OTBI, BI Publisher, OAC/FAW) est un plus, ou a minima l'appétence à monter en compétence sur ces outilsConnaissance des technologies suivantes :- Azure Data Factory ou autres ETL- Databricks ou expérience sur SparkLangages de programmation :- Python (numpy pandas, pyspark),- SQLVous connaissez standards d'ingénierie logicielle de type DEVOPS (CI/CD, git)Vous avez une connaissance des méthodes de traitement de donnée de séries temporelles des techniques de Machine Learning / Deep Learning.Vous connaissez les méthodologies de gestion de projets informatiques (cycle en V, agile)\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'ARAVATI',\n",
       "  'workplace': 'Lognes - 77',\n",
       "  'published_date': '07/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"En tant que Data Analyst, vous serez responsable de projets data orientés métier avec le recueil, la structuration et la valorisation des données, que ce soit pour les fonctions support avec les besoins de reporting opérationnels et analytiques liés à la mise en place du nouvel ERP, ou pour les activités coeur de métier de l'ingénierie, du conseil ou de l'exploitation.Vous contribuerez à l'analyse des données provenant des différents systèmes opérationnels et définirez des indicateurs, jusqu'à la construction d'outils d'analyse et de visualisation graphique des données.Vous veillerez à l'atteinte des objectifs et des résultats escomptés en coordonnant les dimensions techniques, sécuritaires et financières. De formation Bac +5, vous avez une bonne maîtrise des outils d'analyse et de traitement de données quantitatives : décisionnel / big data (Data warehouse, Datamart, Datalake, Lakehouse).Vous maîtrisez la modélisation de données, en particulier les méthodes de modélisation pour usage analytique (modélisation en étoile ou dimensionnelle). Vous concevez les traitements de données permettant de transformer des données transactionnelles en données analytiques.Vous avez une bonne connaissance opérationnelle des outils BI, particulier Power BI. La connaissance des outils de reporting Oracle (OTBI, BI Publisher, OAC/FAW) est un plus, ou a minima l'appétence à monter en compétence sur ces outilsConnaissance des technologies suivantes :- Azure Data Factory ou autres ETL- Databricks ou expérience sur SparkLangages de programmation :- Python (numpy pandas, pyspark),- SQLVous connaissez standards d'ingénierie logicielle de type DEVOPS (CI/CD, git)Vous avez une connaissance des méthodes de traitement de donnée de séries temporelles des techniques de Machine Learning / Deep Learning.Vous connaissez les méthodologies de gestion de projets informatiques (cycle en V, agile)\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'DECIDEOM',\n",
       "  'workplace': 'Lille - 59',\n",
       "  'published_date': '24/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': 'Au sein de la Direction des ventes e-commerce et Omnicanalité et rattaché(e) à la responsable du service UX et Web Analyse, vous êtes responsable de la stratégie data analyse au service de la performance e-commerce.Vous devez répondre à l’ensemble des enjeux liés à la data analyse de la collecte de la donnée, à son utilisation par le plus grand nombre tout en assurant un stack technique optimal.Vos missions seront les suivantes :\\xa0Suivre des KPI’s et les objectifs de notre site e-commerceFournir des études ad-hoc aux différentes équipes métier sur l’utilisation du site\\xa0Réaliser des études permettant de mieux comprendre les évolutions des différents indicateurs et produire les restitutions adéquatesDocumenter les analyses réalisées, assurer la traçabilité et l’historisation des résultats obtenusContribuer à la maintenance et à l’amélioration du plan de taggageImplémenter des évolutions et recette du plan de taggageAnalyser la donnée et proposer des solutions de nettoyage et de redressementRéconcilier les différentes sources de données pour répondre aux besoins métiersGérer le déroulement de projets stratégiques data de bout en boutAnimer des ateliers avec les interlocuteurs métiers et DSIIdentifier et comprendre la structure des sources de données, valider la pertinence et la qualité des donnéesStructurer et réaliser les recettes fonctionnelles et techniques dans le cadre des projets Bac +5. Formation supérieure informatique, statistique ou marketing3 ans min sur un poste équivalentMaitrise des outils : Google Analytics, Data Studio, Tag commander, Seenaptic, Big Query et ContentsquareVous êtes organisé(e), doté(e) d’une bonne capacité d’analyse et de synthèse.Vous êtes capable de restituer les bons insigths avec pédagogieVous avez le sens de l’organisation et des priorités, êtes autonome, rigoureux(se) et force de proposition.\\xa0Vous avez également de bonnes qualités relationnelles.Vous avez une forte appétence à la data, maitrise du tag management, des outils de dataviz, des bases de données et un niveau avancé en excel.\\xa0Management d’un web analyste et d’un alternant'},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'UPTALENT',\n",
       "  'workplace': 'Nantes - 44',\n",
       "  'published_date': '11/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Vos missions :\\xa0Vous serez amené(e) à créer des tableaux de bord pour répondre aux besoins et récolter les attentes des métiers. Vous aurez à utiliser les différents outils de data visualisation lors de la création de dashboards (tableau, Qlik, Power BI).\\xa0Vous contribuez à partagez votre expertise avec l'équipe data, notamment avec le data engineer qui se chargera de vous fournir des données fiables et de qualité.\\xa0Vous effectuez une veille sur les nouvelles technologies et solutions logicielles d'analyse de données.\\xa0Vous mettez en place une documentation fonctionnelle et technique.\\xa0 Votre profil :\\xa0Vous êtes une personne force de proposition dans les solutions de restitution, rigoureu(se)(x) dans documentation et vous avez l'esprit d'analyse et de synthèse afin de comprendre les besoins des métiers et d'apporter les solutions les plus optimales.\\xa0Vous êtes diplômé(e) d'une formation Bac+3/+5 en statistiques, traitement de l'information et vous êtes spécialisé(e) en informatique décisionnelle ou vous avez suivi un cursus en école d'ingénieur.\\xa0Une première expérience réussie d'au moins trois ans en tant que data analyst est nécessaire.\\xa0Vos compétences techniques :\\xa0Vous avez une expertise des outils de data visualisation (tableau, Qlik, Power BI) et une maîtrise de base de données ou cloud provider (Semarchy, GCP, AWS, AZURE).\\xa0Vous maîtrisez le SQL et avez éventuellement des connaissances en Python.\\xa0Vous avez pu travailler avec des méthodes de développement agile ou en cycle V.\\xa0\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'CAPGEMINI TECHNOLOGY SERVICES',\n",
       "  'workplace': 'Issy-les-Moulineaux - 92',\n",
       "  'published_date': '20/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"En tant que Data Analyst, accompagné par 2 consultants au sein de l'équipe, vous serez responsable de la qualité de la data et participerez pleinement à l'optimisation des outils de collecte et d'analyse. Dans le cadre de vos projets vous aurez pour missions:L'analyse de comptes Analytics (GA, GTM...)Mise en place et analyse des plans de marquage\\xa0Mise en place d'outils d'analyse (GA, Plausible...)Paramétrage des outils de tracking\\xa0Réalisation de dashboardsAutomatisation de requêtes SQL d'une formation de niveau Bac+5, vous avez au minimum 4 ans d'expérience dans la collecte et l'analyse de données. Vous maitrisez:Les outils GoogleExcel & VBALes méthodes de tracking\\xa0Connaissance des langages de programmation (Javascript, SQL, Python)Vous êtes méthodique, bon communiquant, possédez de solides compétences analytiques et souhaitez rejoindre une nouvelle aventure ? Ce job est fait pour vous !\\xa0\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'DGA DRH CPP FDCO',\n",
       "  'workplace': 'Rennes - 35',\n",
       "  'published_date': '08/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Vos principales missions seront les suivantes :\\xa0Développer des flux d'alimentation de Data Lake et de traitement des donnéesConcevoir les modèles de donnéesParticiper à la mise en place de l architecture BIG DATAParticiper à la réalisation technique de chargement / traitement des donnéesTravailler en méthode Agile De formation BAC+5 ingénieur, vous disposez d une expérience de minimum 2\\xa0années dans un ou plusieurs projets Big Data.Vous maîtrisez les environnements techniques suivants :\\xa0Hadopp, Spark, Scala, Kafka et/ou Elasticsearch.Vous disposez d un background sur les langages\\xa0Java et/ou C++.Vous parlez anglais couramment.\"},\n",
       " {'position': 'Ingénieur sécurité informatique',\n",
       "  'company': 'INFOTEL MONACO SAM',\n",
       "  'workplace': 'Monaco',\n",
       "  'published_date': '12/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Contexte :Dans le cadre du renfort de ses activités de recherche et développement dans les domaines de la sécurité informatique et de la Cyberdéfense, les divisions Cyber de la Direction Générale de l'Armement, site de Bruz (près de Rennes), recrutent un ou une ingénieur chargé de l'analyse des données d'intérêt Cyber.Mission :La personne titulaire du poste sera intégrée dans une équipe dédiée à la conception de plateformes Big Data permettant d'exploiter les données d'intérêt pour la Cyberdéfense dans les 3 domaines de la lutte informatique. Dans un processus d'amélioration continue, elle sera chargée de contribuer au choix des datasets utiles aux métiers, au recueil, à l'intégration et à l'exploitation de cesdonnées dans un data lake.Mots clés :#analyse #fingerprint #OSINT #bigdata Le poste consiste à :Identifier et analyser les données d'intérêt pour la Cyberdéfense.Spécifier les pipelines de données conjointement avec l'équipe d'ingénierie Big Data.Contribuer au développement d'outils d analyse et d'étiquetage des données avec les équipes Data & IA dans une démarche CI/CD.Capitaliser et valoriser les connaissances acquises dans le strict respect des exigences du ministère de la défense et des différents domaines de la lutte informatique (LID, LIO et L2I).Titulaire d'un diplôme de niveau BAC+5 (ingénieur, master 2, etc.), vous justifiez de compétences sur l'un ou plusieurs des sujets suivants :Maitrise d'outils d'analyse et visualisation de données type Kibana, Zeppelin,Scripting et développement (Bash, Python, Java, Scala).Fonctionnement des réseaux et des systèmes.La connaissance supplémentaire des techniques de hacking (fingerprinting, détection et exploitation de vulnérabilités, etc) seraient un plus.Qualités personnelles :Esprit de synthèseBon relationnel\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'SII',\n",
       "  'workplace': 'Lille - 59',\n",
       "  'published_date': '11/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Missions :Recueil de besoin métier (cahier des charges, animation d atelier, présentation)Développement des intégrations de données (architecture datahub/datawarehouse) via l ETL BODS ou Oracle Data IntegratorSupport applicatif : correction des erreurs de flux, mise en productionAdministration Tableau server (planification, abonnement, gestion des groupes)Veille aux bonnes pratiques en termes de développements (référentiel documentaire, qualité du code, déploiement)Recette intégration et tableau de bord Master (bac +5) en informatique ou est diplômé d'une école d'ingénieurs\\xa0Minimum 5 ans dans un poste d'intégrateur data, data analyst, data engineer\\xa0Minimum 3 ans d'expérience sur Tableau + outil ETL (BODS, ODI)\\xa0Secteur du luxe privilégié\\xa0Anglais courant\\xa0Esprit analytique et synthétique\\xa0Profil technico-fonctionnel (adaptation du discours, interprétation du besoin)\\xa0Maîtrise technique :Langages : SQL, Python, PL/SQLVisualisation : Tableau, SAP Business ObjectTechnologies : ETL (BODS) / GoldenGate + Oracle Data Integrator (ORACLE)Systèmes en environnements virtualisés (Windows, Linux)SGBD (Oracle, SQL Server, ), NoSQL (MongoDB), ELK Maîtrise des bonnes pratiques de la sécurité informatique (ANSSI) et du RGPDEsprit d'analyse et de synthèseEsprit d'équipe\\xa0Capacité à se former en permanence\\xa0Adaptabilité face à l'évolution technologique\\xa0Aisance relationnelle et capacités de communication\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'GROUPE ROULLIER',\n",
       "  'workplace': 'Dinard - 35',\n",
       "  'published_date': '27/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Devenez le prochain collaborateur d'SII Nord, en tant que :\\xa0Data analyst (H/F)En intégrant l’équipe data de l'un de nos client, les missions qui vous sont confiées sont :•\\xa0\\xa0 \\xa0D’aider à la conception des modèles de données•\\xa0\\xa0 \\xa0D’optimiser/améliorer le reporting existant•\\xa0\\xa0 \\xa0D’aider sur le calcul des KPI•\\xa0\\xa0 \\xa0D’optimiser les requêtes\\xa0•\\xa0\\xa0 \\xa0De participer aux divers projets liés à la data (développement d’algorithme, croisement de données etc.) Dans l’idéal (oui uniquement dans l’idéal, chez nous on ne cherche pas qu’un CV mais une collaboration durable), vous êtes issu d’une formation supérieure Bac +5 et vous justifiez d’une expérience de 2 ans\\xa0 min sur un poste de Data Analyst.\\xa0BigQuery, PowerBI ou encore GCP\\xa0n’ont plus de secret pour vous.\\xa0Au-delà des compétences techniques, vous êtes/avez :\\xa0•\\xa0\\xa0 \\xa0Rigoureux :\\xa0chaque détail a son importance\\xa0•\\xa0\\xa0 \\xa0Curieux :\\xa0Désireux de connaître le « pourquoi » et le « comment »\\xa0•\\xa0\\xa0 \\xa0Organisé :\\xa0chaque journée commence par une « To do »\\xa0•\\xa0\\xa0 \\xa0Sens du service :\\xa0la satisfaction client est votre objectif premier\\xa0Ces qualités vous permettent de mener à bien le projet.\\xa0\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'ALTEN',\n",
       "  'workplace': 'Boulogne-Billancourt - 92',\n",
       "  'published_date': '13/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Intégré(e) au sein de l'équipe BI & DATA de la DSI du Groupe ROULLIER, vous accompagnerez les métiers du Groupe dans la valorisation de leurs données. Vous prendrez en charge la gestion applicative et la mise en oeuvre de solutions Data & Business Intelligence.Vos missions sont les suivantes :1) Développer des solutions BI- Pilotage des projets BI/Reporting de bout en bout dans le respect des engagements (coûts / délais / qualité)- Recueil et analyse des besoins exprimés avec un rôle de conseil et d'accompagnateur auprès de nos métiers- Conception et réalisation (Transformation, modélisation et design de rapport)2) Maintenir et faire évoluer les outils existants :- Flux et modélisation de données- Maintien en condition opérationnelle du portefeuille d'applications- Suivi d'exploitation Assistance auprès de nos métiers sur les applications Data- Optimisation de rapport existant3) Contribuer à l'évolution de l'architecture Data & des pratiques BI- Création de nouveaux flux de données- Architecture du Data Warehouse- Veille sur les nouvelles tendances/méthodes- Accompagnement et formation des utilisateurs aux bonnes pratiques- Participer activement à la diffusion de la culture data - Min 3 ans d'expériences- Vous maîtrisez l'anglais technique- Votre capacité d'adaptation, votre autonomie, votre sens du service ainsi que vos qualités relationnelles seront vos atouts pour réussir et évoluer au sein de la structure.Compétences :- Outils BI : Power BI, SSRS, Jedox, Cognos- Langage de prog. : SQL, Python- Intégration de données : SSIS, Talend- BDD : SQL Server, Oracle DWH- Environnement : Windows, LinuxQu'avons-nous à offrir- Jusqu'à 2 jours de télétravail par semaine- RTT- Une Prise en charge de l'abonnement transports en commun à hauteur de 75%- Un Comité interentreprise- Des accords de participation et d'intéressement- Une participation aux repasMais aussi- Un cadre de travail agréable situé à deux pas de la mer- Un bâtiment dédié aux activités\\xa0culturelles- Une vie interne dynamique : Afterwork, teambuilding\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': '(CONFIDENTIELLE)',\n",
       "  'workplace': 'Gironde - 33',\n",
       "  'published_date': '08/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Intégré(e) au sein de l'équipe BI & DATA de la DSI du Groupe ROULLIER, vous accompagnerez les métiers du Groupe dans la valorisation de leurs données. Vous prendrez en charge la gestion applicative et la mise en oeuvre de solutions Data & Business Intelligence.Vos missions sont les suivantes :1) Développer des solutions BI- Pilotage des projets BI/Reporting de bout en bout dans le respect des engagements (coûts / délais / qualité)- Recueil et analyse des besoins exprimés avec un rôle de conseil et d'accompagnateur auprès de nos métiers- Conception et réalisation (Transformation, modélisation et design de rapport)2) Maintenir et faire évoluer les outils existants :- Flux et modélisation de données- Maintien en condition opérationnelle du portefeuille d'applications- Suivi d'exploitation Assistance auprès de nos métiers sur les applications Data- Optimisation de rapport existant3) Contribuer à l'évolution de l'architecture Data & des pratiques BI- Création de nouveaux flux de données- Architecture du Data Warehouse- Veille sur les nouvelles tendances/méthodes- Accompagnement et formation des utilisateurs aux bonnes pratiques- Participer activement à la diffusion de la culture data - Min 3 ans d'expériences- Vous maîtrisez l'anglais technique- Votre capacité d'adaptation, votre autonomie, votre sens du service ainsi que vos qualités relationnelles seront vos atouts pour réussir et évoluer au sein de la structure.Compétences :- Outils BI : Power BI, SSRS, Jedox, Cognos- Langage de prog. : SQL, Python- Intégration de données : SSIS, Talend- BDD : SQL Server, Oracle DWH- Environnement : Windows, LinuxQu'avons-nous à offrir- Jusqu'à 2 jours de télétravail par semaine- RTT- Une Prise en charge de l'abonnement transports en commun à hauteur de 75%- Un Comité interentreprise- Des accords de participation et d'intéressement- Une participation aux repasMais aussi- Un cadre de travail agréable situé à deux pas de la mer- Un bâtiment dédié aux activités\\xa0culturelles- Une vie interne dynamique : Afterwork, teambuilding\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'ENYGEA',\n",
       "  'workplace': 'Englos - 59',\n",
       "  'published_date': '17/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"En tant que Data Analyst, vous contribuerez à la réalisation de projets data orientés métier. Dans le cadre de ces projets, vous serez amené(e) à identifier, recueillir les besoins métiers et objectifs de l entreprise en terme de valorisation des données, définir des approches et road maps analytiques, identifier et implémenter des indicateurs de suivi et de pilotage ou encore réaliser des études quantitatives et mettre en lumière les insights business (études ad hoc, scores, segmentation, etc.). Vous pourrez également contribuer à l orchestration des processus analytiques permettant de mettre en œuvre une stratégie data driven, ainsi qu à l accompagnement des utilisateurs dans la prise en main des outils analytiques mis en œuvre.\\xa0Vous maîtrisez idéalement l’un des principaux outils analytiques du marché\\xa0 (Dataiku, SAS Viya, Alteryx, IBM SPSS Modeler, etc..), les langages de programmation (SAS, R, Python), les bases de données (SQL) et vous disposez d’une expérience avérée en Data Analyse (segmentation, score, études quantitatives, reporting, etc..) opérée au sein d’une direction métier. Issu(e) d’une formation supérieure\\xa0Bac +5 ou plus (école d’ingénieurs, doctorat,\\xa0master, master spécialisé), nous recherchons des collaborateurs avec différents niveaux d'expérience tels que des\\xa0Consultants, Senior Consultants, Lead Consultants, Project Managers, …Vous êtes passionné(e) par la data, à l’écoute, doté(e) d’un très bon relationnel et vous savez faire preuve de prise de recul. Garant de la connaissance métier, vous êtes capable de vous approprier les enjeux stratégiques et les problématiques opérationnelles. Vous êtes à l’aise pour conseiller, accompagner les demandes de vos clients et être force de proposition dans la mise en place de nouveaux cas d’usage.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'BUSINESS & DECISION CORPORATE SERVICES',\n",
       "  'workplace': 'Niort - 79',\n",
       "  'published_date': '13/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Vos mission\\nEn tant que Data Analyst , vous secondez le chef de projet fonctionnel. Votre rôle tourne autour de la Data, du Support et de la formation des utilisateurs. Passionné.e de gestion de données avant tout, vous aurez les missions suivantes\\xa0:\\n\\n1/ Data :\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Gérer l'extraction et la structuration des bases de données,\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Créer des requêtes (SQL),\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Modéliser des rapports,\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Assurez le développement et la maintenance technique concernant nos rapports sous PowerBI en vous assurant de la bonne qualité des données,\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Identifier et construire des variables importantes au pilotage de l’activité,\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Présenter et partager les résultats des analyses grâce aux outils de data visualisation (Power BI),\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Participer aux ateliers d’expression des besoins internes transverses.\\n\\nNous sommes à la recherche d’une personne polyvalente qui aura également les attributions ci-dessous\\xa0:\\n\\n2/ Support :\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Assistez et coachez quotidiennement l’ensemble des utilisateurs sur nos logiciels,\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Remonter les besoins d’évolution et de correctifs auprès du chef de projet fonctionnel,\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Tester les nouvelles versions d'applications métier (notamment sur VARY),\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Valider le développement ou signifier les anomalies,\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Référer au chef de projet fonctionnel ou mettre directement en œuvre la correction.\\n\\n3/ Formation :\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Accompagnez l’entreprise dans la poursuite des différents projets de dématérialisation (espace clients, mise en place d’un nouveau CRM HUBSPOT, dématérialisation des documents RH, etc.),\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Formez l’ensemble des métiers à notre ERP (Vary) et aux différents logiciels du groupe.\\n\\nListe non exhaustive\\n Profil\\n\\nVous êtes idéalement diplômé BAC + 2- type STID\\n\\nSurtout vous savez faire preuve de pédagogie et vous savez adapter votre communication aux différents interlocuteurs.\\nVous êtes réactif/réactive, agile et vous savez faire preuve de rigueur.\\nVous avez une bonne connaissance du SQL et idéalement de Power BI.\\n\\nDe plus, vous justifiez d’une expérience confirmée d’au moins minimum 2 ans sur un poste similaire ? Alors postulez !\\n\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'BUSINESS & DECISION LIFE SCIENCES',\n",
       "  'workplace': 'Paris 13 - 75',\n",
       "  'published_date': '07/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': 'Au sein de notre site Niortais, intégré(e) dans une équipe projet, vous mettez en œuvre des solutions d’aide à la décision permettant d’améliorer le pilotage stratégique et opérationnel de nos clients et de valoriser leurs données.Vos missions sont les suivantes :•\\xa0\\xa0 \\xa0Instruire les besoins client : recueil et compréhension•\\xa0\\xa0 \\xa0Concevoir les solutions techniques et fonctionnelles sous forme de spécifications•\\xa0\\xa0 \\xa0Accompagner les utilisateurs dans le maquettage de leurs tableaux de bord•\\xa0\\xa0 \\xa0Gérer la priorisation, la planification et le suivi des charges•\\xa0\\xa0 \\xa0Assurer le lien entre les besoins métiers et l’équipe de développement•\\xa0\\xa0 \\xa0Rédiger les cahiers de recettes applicatives•\\xa0\\xa0 \\xa0Assurer la coordination et le suivi de la recette fonctionnelle\\xa0•\\xa0\\xa0 \\xa0Dispenser un support aux métiers QualificationsDepuis au moins 3 ans, vous mettez en pratique vos acquis et compétences en tant que Data Analyst F/H.Outre votre expérience, c’est une personnalité qui est aussi recherchée !\\xa0\\xa0Informations complémentairesCe que nous vous proposons :•\\xa0\\xa0 \\xa0Une carrière dans un environnement multiculturel, dynamique et formateur,•\\xa0\\xa0 \\xa0Une réelle possibilité de télétravail,•\\xa0\\xa0 \\xa0Un appui et un suivi régulier d’un manager sénior dans le métier,•\\xa0\\xa0 \\xa0Des formations et les certifications associées au parcours de carrière choisi\\xa0•\\xa0\\xa0 \\xa0Des possibilités d’activités complémentaires (avant-vente, formation, conseil, expertise, montage d’offre, POC..),•\\xa0\\xa0 \\xa0Des événements festifs,•\\xa0\\xa0 \\xa0Une intégration au sein d’une communauté\\xa0d’expert(e)s passionné(e)sVous êtes partant(e) pour vivre l’aventure ? Postulez dès maintenant en nous envoyant votre CV.\\xa0'},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'HELLOWORK',\n",
       "  'workplace': 'Montpellier - 34',\n",
       "  'published_date': '04/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Vos missions :- Élaborer des rapports et des analyses à l'aide de Power BI.Gérer et concevoir l'environnement de reporting, y compris les sources de données, la sécurité et les métadonnées.Evaluer les tests et mettre en œuvre des logiciels nouveaux ou mis à niveau et contribuer aux décisions stratégiques concernant les nouveaux systèmes.Former les utilisateurs finaux aux nouveaux rapports et tableaux de bord.Élaborer des documents de qualité appropriés.\\xa0Soutenir l'entrepôt de données dans l'identification et la révision des exigences en matière de rapports.Évaluer les changements et les mises à jour des systèmes de production source.Fournir une expertise technique (transformation numérique) en matière de structures de stockage des données, d'exploration des données et de nettoyage des données.Gérer les utilisateurs et leurs rôles.La mise en service et le déclassement des ensembles de données. Votre profil :Vous justifiez minimum de 2 ans d'expérience en tant que Data AnalystVous justifiez impérativement d'une expérience dans l'industrie pharmaceutique!Connaissance en Power BIVous interviendrez au sein des équipes du laboratoires qui est situé en Ile-de-France avec du télétravail. Pour une date de démarrage début 2024.Vous avez envie de nous rejoindre\\xa0? Ce serait avec plaisir de vous rencontrer ! N'hésitez pas à nous envoyer votre CV.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': \"L'OPCOMMERCE\",\n",
       "  'workplace': 'Paris 17 - 75',\n",
       "  'published_date': '01/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Au sein de notre agence Occitanie, site de Montpellier, intégré dans une équipe projet, vous mettez en oeuvre des solutions d'aide à la décision permettant d'améliorer le pilotage stratégique et opérationnel de nos clients et de valoriser leurs données.  Vos missions sont les suivantes :-  Instruire les besoins client : recueil et compréhension-  Concevoir les solutions techniques et fonctionnelles sous forme de spécifications-  Accompagner les utilisateurs dans le maquettage de leurs tableaux de bord-  Gérer la priorisation, la planification et le suivi des charges-  Assurer le lien entre les besoins métiers et l'équipe de développement-  Rédiger les cahiers de recettes applicatives-  Assurer la coordination et le suivi de la recette fonctionnelle-  Dispenser un support aux métiers QualificationsDepuis au moins 3 ans, vous mettez en pratique vos acquis et compétences en tant que Data Analyst.Outre votre expérience, c'est une personnalité qui est aussi recherchée !Informations supplémentairesÊtre un collaborateur chez Business & Decision (Orange Business) c'est :-   Faire partie d'un acteur majeur dans les nouvelles technologies-   Travailler sur des projets d'envergure pour des clients de tous secteurs d'activités-   Évoluer dans un environnement d'experts passionnés-   Faire évoluer tes compétences techniques et fonctionnelles (formations, certifications) grâce à un accompagnement de proximité et à notre université interne, Business & Decision University-   Profiter d'un employeur qui accorde autant d'attention à l'humain qu'à l'expertise.En participant à l'aventure Business & Decision (Orange Business), tu vas donner à ton parcours professionnel une longueur d'avance. Rejoins-nous !\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'HELLOWORK',\n",
       "  'workplace': 'Paris 01 - 75',\n",
       "  'published_date': '11/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Rattaché(e) à la Direction\\ndes Systèmes d’Information, il/elle aura les missions suivantes\\xa0:\\n\\n\\xa0\\n\\nActivités\\xa0:\\n\\nAnalyser et exploiter les données des différents outils du système\\n     d’informationRecenser les besoins des opérationnelsRéaliser des rapports en fonction des demandes opérationnellesMaitriser et garantir la qualité des donnéesEffectuer des contrôles de cohérenceFaire des préconisationsParticiper aux projets en méthode AGILE (SCRUM)Assurer le\\n     reporting des donnéesEquipe\\ncomposée de 12 personnes (une journée par semaine sera dédiée au maintien en\\ncondition opérationnelle) De formation Bac+5\\nspécialisée dans le domaine de la data ou statistique, vous possédez\\nimpérativement une expérience significative en tant que Data Analyst ou\\ndéveloppeur décisionnel. \\xa0-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nVous êtes curieux(se) et ouvert(e), vous faites preuve\\nd'aisance relationnelle et apprécié(e) challenger les idées.-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nVous avez un très bon niveau de maitrise d’outil de dataviz\\n(Power BI)-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nVous avez des connaissances de langage de script (Python,\\netc…)-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nVous avez des compétences techniques SGBD (SQL, SQL Server…)-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nVous avez des bonnes connaissances des outils Microsoft\\nAzure (Data Lake, Data Factory, Power BI, Purview, etc…)-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nVous êtes autonome, rigoureux(se), organisé(e), force\\nde proposition\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n-\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nVous avez un bon sens du relationnel afin de communiquer auprès de\\ndifférents interlocuteurs permettant le travail en équipe\\n\\n\\n\\n\\xa0\\n\\nConditions d’emploi et avantages\\xa0:\\n\\n\\xa0\\n\\nTemps\\nde travail\\xa0: forfait jours (212 jours)13ème\\nmoisTitres\\nrestaurantCompte\\népargne temps (CET)Possibilité\\nde télétravailPoste\\nbasé à Paris avec déplacement possible Lille\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nL’Opcommerce\\ndéveloppe une politique active d'accueil des personnes en situation de\\nhandicap. Les candidatures sont étudiées selon ce principe.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'RECSI-GROUP',\n",
       "  'workplace': 'Paris 16 - 75',\n",
       "  'published_date': '17/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"En tant que Data Analyste, vous serez responsable de l'analyse et de l'interprétation des données pour fournir des informations exploitables aux équipes internes de l'entreprise. Vous travaillerez en étroite collaboration avec les équipes DSID en charge du déploiement des usages Data auprès des directions métiers clientes. Vous serez à même de résoudre les problèmes et prendre des décisions éclairées basées sur les données.A ce titre, vous veillerez :- Collecter, nettoyer et organiser les données provenant de diverses sources internes et externes.- Analyser les données pour identifier les tendances, les modèles et les insights pertinents.- Développer et mettre en oeuvre des tableaux de bord, des rapports et des visualisations pour présenter les résultats de manière claire et concise.- Collaborer avec les équipes en charge de répondre aux usages métiers pour définir les besoins en matière d'analyse de données et les objectifs à atteindre.- Fournir des recommandations basées sur les analyses de données pour améliorer les performances commerciales, les stratégies marketing et les processus opérationnels.- Suivre les KPIs clés et les métriques de performance, en identifiant les écarts et en proposant des actions correctives.- Maintenir une veille technologique pour rester à jour sur les nouvelles méthodes, les outils et les tendances en matière d'analyse de données. Vos compétences et atouts- Solides compétences analytiques et capacité à travailler avec de grandes quantités de données.- Excellentes compétences en programmation et maîtrise des langages couramment utilisés en data analysis (SQL, etc.).- Expérience avec les outils d'analyse de données tels que SAAS, Excel, etc.- Connaissance des techniques d'exploration de données, de modélisation statistique.- Capacité à communiquer efficacement les résultats d'analyse de données à des parties prenantes non techniques.- Capacité à travailler de manière autonome et à gérer plusieurs projets simultanément.- Attention aux détails et souci de la qualité des données.- Compréhension des concepts fondamentaux du business et des indicateurs de performance clés.Savoirs :Connaissance du domaine de l'assurance Santé/Prévoyance.Sensibilisation aux évolutions règlementaires et éthique dans l'usage dedonnées (RGPD) ;Maîtrise des techniques d'extraction, d'analyse et de traitement de la donnée ;Savoir - Faire :Travail en équipe et mode collaboratifCapacités d'analyse et de synthèse.Capacité à comprendre le besoin du métier afin de produire une solution adaptée ;Maîtrises des langages informatiques de traitement de données ;Capacité d'analyse et de synthèse développée ;Connaissance d'outils de mise en oeuvre de tableau de bord ;Capacité à expliquer sa démarche et à présenter ses résultats d'analyse ;Capacité à utiliser les outils transverses de travail en équipe.Savoir - Être :Excellent relationnel, qualité d'écoute.Sens du service, disponibilité, pédagogie.En tant que Data Analyst, vous jouerez un rôle clé dans la transformation des données brutes et gérées en informations utiles pour prendre des décisions stratégiques. Votre expertise analytique et votre capacité à structurer les données aideront l'entreprise à comprendre ses clients, à améliorer ses produits et à stimuler sa croissance.\"},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'LEASECOM',\n",
       "  'workplace': 'Carquefou - 44',\n",
       "  'published_date': '13/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': 'Rattaché à la direction Digitale, vos missions seront dans les grandes lignesAssurer la collecte et la qualité des données des périmètres suivisProduire des analyses fiables, documentées et pertinentes pour permettre la prise de décision stratégiqueRéaliser des études pour accroitre la connaissance utilisateurContribuer à diffuser la culture data au sein de l’entrepriseParticiper de façon continue à l’amélioration des outils mis à dispositionVeille active des évolutions de marché & maintenir la société au plus haut niveau d’analyse des performances.Actions à mener auprès des éditeurs, des prestataires et des utilisateurs Vous êtes issus d’une école d’ingénieur, minimum 2 ans d’expériences, avez une appétence pour les médias.Connaissance des Outils Weborama et/ou Mediarithmics, Piano AnalyticsCapacité de travail analytiqueEsprit de synthèse et rigueurAppétence pour les médiasTrès bonne maîtrise des outils web analytics, de tableur, et de data visualisationAutonome, pro-actif, organisé, vous avez une très forte sensibilité business.'},\n",
       " {'position': 'Data analyst',\n",
       "  'company': 'MP DATA',\n",
       "  'workplace': 'Boulogne-Billancourt - 92',\n",
       "  'published_date': '14/11/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Rattaché (e) à la responsable du pôle DATA, nous vous proposons de rejoindre notre équipe SI où vous aurez pour principales missions le traitement d’analyse de base de données de nature commerciale, de données financières et du back office prévisionnel.\\xa0\\xa0A ce titre\\xa0: \\xa0\\xa0Vous assurerez le développement, l’évolution et la maintenance des flux de synchronisation entre les différents outils.Vous serez en charge du reporting et de l’analyse des données issues du datamart.Vous représenterez et analyserez les données\\xa0: proposition d’axes d’amélioration par des approches analytiques.Vous serez amené à travailler sur les différents projets de développement de l’entreprise (études des nouvelles innovations BI dans le domaine du Cloud, Big Data). Vous êtes jeune diplômé, vous avez minimum 1 an d’expérience et vous êtes spécialisé (e) dans la BI /data analyst, vous disposez de capacités dans l'informatique décisionnelle, vous avez un esprit de synthèse et d'analyse, vous avez une grande capacité d’adaptation, une véritable curiosité technologique et vous avez des connaissances en ETL/Talend.\\xa0Outils\\xa0: ETL / Talend / outils de reporting\\xa0Connaissances de MSSQL/ MYSQL / POSTGRESQL et Oracle\\xa0Conditions :- Type de contrat : CDI- Tickets restaurants, mutuelle famille, RTT- Remboursement titre de transport à 50%- Localisation : Carquefou\\xa0Vous hésitez encore ?\\xa0Leasecom c’est aussi :\\xa0- Un collectif RSE et une labellisation «\\xa0Positive Company\\xa0»- Un cadre de travail agréable et des activités riches et stimulantes- Un parcours d’intégration où nous serons aux petits soins pour vous- Des parcours formation pour que soyez toujours opérationnels- Des perspectives d’évolution- De supers évènements toute l’année- Une ouverture de toutes nos postes aux salariés reconnus travailleurs handicapés\\xa0Et enfin un process de recrutement ultra rapide!\"}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpustest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
