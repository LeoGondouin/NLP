{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "from dateutil import parser\n",
    "import html\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait,Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException,NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import random\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapCorpus(sources,keyword,nb_docs):\n",
    "\n",
    "    source = \"\"\n",
    "    position = \"\"\n",
    "    company = \"\"\n",
    "    workplace = \"\"\n",
    "    published_date = \"\"\n",
    "    contract_type = \"\"\n",
    "    long_infos = \"\"\n",
    "\n",
    "\n",
    "    if  \"emploi-territorial\" in sources:\n",
    "        pages = math.ceil(nb_docs/20)\n",
    "        source = \"emploi-territorial\"\n",
    "        rootLink = \"https://www.emploi-territorial.fr\"\n",
    "        # 20 offres par pages\n",
    "        # pages = math.ceil(nb_docs/20)\n",
    "        url = f\"{rootLink}/emploi-mobilite/?adv-search={keyword}&page={pages}\"\n",
    "        response = requests.get(url) \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        root = soup.find(\"body\")\n",
    "        offresLinkElems = root.select(\"div[class*='bloc-lien-offre'] > a[class*='lien-details-offre']\")[:nb_docs]    \n",
    "        links = [rootLink+offresLinkElem.get(\"href\") for offresLinkElem in offresLinkElems]\n",
    "\n",
    "        corpus = list(dict())\n",
    "\n",
    "        for link in links:\n",
    "            response = requests.get(link)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            root = soup.find(\"body\")\n",
    "\n",
    "            position = root.select(\"h2[class*='set-line-emploi']\")[0].text.strip()\n",
    "            company = root.select(\"div[class*='offre-item-value'] > strong > a\")[0].text.strip() if root.select(\"div[class*='offre-item-value'] > strong > a\") else \"NULL\"\n",
    "            workplace = root.select_one(\"div[class*='offre-item-label']:contains('Lieu de travail') + .offre-item-value\").text.strip() if root.select_one(\"div[class*='offre-item-label']:contains('Lieu de travail') + .offre-item-value\") else \"NULL\"\n",
    "            published_date = root.select_one(\"div[class*='px-3']:contains('Publi√©e le') > .set-color-green\").text.strip() if root.select_one(\"div[class*='px-3']:contains('Publi√©e le') > .set-color-green\") else \"NULL\"\n",
    "            contract_type = root.select_one('div[class*=\"offre-item-label\"]:contains(\"Type d\\'emploi\") + .offre-item-value').text.strip() if root.select_one('div[class*=\"offre-item-label\"]:contains(\"Type d\\'emploi\") + .offre-item-value') else \"NULL\"\n",
    "            position_type = root.select_one('div[class*=\"offre-item-label\"]:contains(\"Famille de m√©tiers\") + .offre-item-value').text.split(\">\")[0].strip()\n",
    "            \n",
    "            long_text = root.select('div[class*=\"offre-item-text\"]')\n",
    "\n",
    "            long_infos = \" \".join([long_text[0].text.strip(),long_text[1].text.strip(),long_text[2].text.strip()])\n",
    "            current_offer = {\"source\": source, \"link\": rootLink, \"position\": position, \"position_type\": position_type,\n",
    "                \"company\": company, \"workplace\": workplace, \"published_date\": published_date,\n",
    "                \"contract_type\": contract_type, \"description\": long_infos}\n",
    "\n",
    "            # Check if the offer is already in the corpus based on a frozenset comparison\n",
    "            corpus.append(current_offer)\n",
    "    \n",
    "    if \"apec\" in sources:\n",
    "        pages = math.ceil(nb_docs/20)\n",
    "        source = \"apec\"\n",
    "        service = ChromeService(\"C:/Users/leogo/Documents/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        rootLink = \"https://www.apec.fr\"\n",
    "        try:\n",
    "            for page in range(pages):    \n",
    "                try:\n",
    "                    driver.get(f'{rootLink}/candidat/recherche-emploi.html/emploi?motsCles={keyword}&page={pages}')\n",
    "                    # Initial find of elements\n",
    "                    try:\n",
    "                        deny_cookies_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#onetrust-reject-all-handler'))\n",
    "                        )\n",
    "\n",
    "                        deny_cookies_button.click()\n",
    "                    except TimeoutException:\n",
    "                        pass\n",
    "\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "                    )\n",
    "\n",
    "                    # Getting docs left if last page to query\n",
    "                    if nb_docs%20 != 0 and page==pages-1: \n",
    "                        limit = nb_docs%20\n",
    "                        div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, 'div.card-offer')[:limit]\n",
    "                    else :\n",
    "                        div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, 'div.card-offer')\n",
    "                        \n",
    "                    for index in range(len(div_elements_to_click_list)):\n",
    "                        try:\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "                            )\n",
    "                            # Re-find elements after navigating back\n",
    "                            div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, 'div.card-offer')\n",
    "\n",
    "                            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-offer\"))\n",
    "                            )\n",
    "                            # Check if the index is within the valid range\n",
    "\n",
    "                            div_elements_to_click = div_elements_to_click_list[index]\n",
    "                            company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "                            contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "                            workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "                            published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "                            # Scroll into view\n",
    "\n",
    "                            actions = ActionChains(driver)\n",
    "                            actions.move_to_element(div_elements_to_click).click().perform()\n",
    "\n",
    "                            # Wait for the child element to become present in the DOM\n",
    "                            WebDriverWait(driver, 20).until(\n",
    "                                EC.presence_of_element_located((By.XPATH, f\"//h4[text()='Descriptif du poste']\"))\n",
    "                            )\n",
    "                            # Get the page source after the click\n",
    "                            page_source = driver.page_source\n",
    "\n",
    "                            # Use Beautiful Soup to parse the page source\n",
    "                            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                            # Example: Retrieve the text of a specific element\n",
    "                            desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "                            descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "                            profile = soup.select(\"h4:contains('Profil recherch√©') + p\")\n",
    "                            profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "                            position = soup.select_one(\"h4:contains('M√©tier') + span\").text\n",
    "                            position_type = soup.select_one('h4:contains(\"Secteur d‚Äôactivit√© du poste\")+span').text\n",
    "                            long_infos = \" \".join([descText,profileText])\n",
    "                            \n",
    "                            corpus.append({\"source\":source,\"link\":rootLink,\"position\":position,\"position_type\":position_type,\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":long_infos})\n",
    "                        except Exception as e:\n",
    "                            # Print the exception for debugging purposes\n",
    "                            print(f\"Error: {e}\")\n",
    "\n",
    "                        finally:\n",
    "                            # Navigate back to the main page\n",
    "                            driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Print the exception for debugging purposes\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "        finally:\n",
    "            driver.quit()\n",
    "    if \"hellowork\" in sources:\n",
    "        pages = math.ceil(nb_docs/30)\n",
    "        source = \"hellowork\"\n",
    "        rootLink = \"https://www.hellowork.com\"\n",
    "        service = ChromeService(\"C:/Users/leogo/Documents/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "        driver = webdriver.Chrome(service=service) \n",
    "        try:\n",
    "            for page in range(pages):    \n",
    "                try:\n",
    "                    print(page)\n",
    "                    driver.get(f'{rootLink}/fr-fr/emploi/recherche.html?k={keyword}&k_autocomplete=&l=France&l_autocomplete=&p={page+1}')\n",
    "                    # Initial find of elements\n",
    "                    try:\n",
    "                        accept_cookies_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#hw-cc-notice-accept-btn'))\n",
    "                        )\n",
    "\n",
    "                        accept_cookies_button.click()\n",
    "\n",
    "                        combobox = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, \"select[name='country']\"))\n",
    "                        )\n",
    "\n",
    "                        select = Select(combobox)\n",
    "                        # Select a specific item by visible text\n",
    "                        select.select_by_value(\"FR\")\n",
    "\n",
    "                        form = driver.find_element(By.CSS_SELECTOR,\"form[data-action*='service-adaptation']\")\n",
    "                        next_button = form.find_element(By.CSS_SELECTOR,\"button\")\n",
    "                        next_button.click()\n",
    "                    except TimeoutException:\n",
    "                        pass\n",
    "\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"button[data-cy='seeOffer']\"))\n",
    "                    )\n",
    "                    # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    # Getting docs left if last page to query\n",
    "                    if nb_docs%20 != 0 and page==pages-1: \n",
    "                        limit = nb_docs%20\n",
    "                        div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, \"button[data-cy='seeOffer']\")[:limit]\n",
    "                    else :\n",
    "                        div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, \"button[data-cy='seeOffer']\")\n",
    "                        \n",
    "                    for index in range(len(div_elements_to_click_list)):\n",
    "                        try:\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"button[data-cy='seeOffer']\"))\n",
    "                            )\n",
    "\n",
    "                            # Re-find elements after navigating back\n",
    "                            div_elements_to_click_list = driver.find_elements(By.CSS_SELECTOR, \"button[data-cy='seeOffer']\")\n",
    "                            # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                            # driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"button[data-cy='seeOffer']\"))\n",
    "                            )\n",
    "                            # Check if the index is within the valid range\n",
    "\n",
    "                            div_elements_to_click = div_elements_to_click_list[index]\n",
    "                            # driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_elements_to_click)\n",
    "                            # company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "                            # contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "                            # workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "                            # published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "                            # Scroll into view\n",
    "\n",
    "                            # actions = ActionChains(driver)\n",
    "                            # actions.move_to_element(div_elements_to_click).click().perform()\n",
    "                            #On remote de deux niveau du bouton \"Voir offre\" pour pouvoir r√©cup√©rer les informations appropri√©es\n",
    "                            div_offer = driver.execute_script(\"return arguments[0].parentNode.parentNode;\", div_elements_to_click)\n",
    "                            company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "                            company = company_elem.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "                            company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "                            contract_type = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='contract']\").text\n",
    "                            workplace = div_offer.find_elements(By.CSS_SELECTOR, \"div[data-cy='loc']\")[-1].text\n",
    "                            published_date = div_offer.find_elements(By.CSS_SELECTOR, \"span[data-cy='publishDate']\")[-1].text\n",
    "\n",
    "                            driver.execute_script(\"arguments[0].click();\", div_elements_to_click)\n",
    "\n",
    "                            # Wait for the child element to become present in the DOM\n",
    "                            WebDriverWait(driver, 20).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"span[data-cy='jobTitle']\"))\n",
    "                            )\n",
    "                            # Get the page source after the click\n",
    "                            page_source = driver.page_source\n",
    "\n",
    "                            # Use Beautiful Soup to parse the page source\n",
    "                            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                            # Example: Retrieve the text of a specific element\n",
    "                            # desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "                            # descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "                            # profile = soup.select(\"h4:contains('Profil recherch√©') + p\")\n",
    "                            # profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "                            position = soup.select_one(\"span[data-cy='jobTitle']\").text\n",
    "                            # position_type = soup.select_one('h4:contains(\"Secteur d‚Äôactivit√© du poste\")+span').text\n",
    "                            long_infos = soup.select(\"section\")\n",
    "                            infos = [item.text.replace(\"\\n\",\" \").strip() for item in long_infos]\n",
    "                            infos = [re.sub(r'\\s+', ' ',item) for item in infos]\n",
    "                            infos = \" \".join([item for item in infos if item != ''])\n",
    "                            # infos = [item for item in infos if '' not in item]\n",
    "                            corpus.append({\"source\":source,\"link\":rootLink,\"position\":position,\"position_type\":\"NULL\",\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":infos})\n",
    "                        except Exception as e:\n",
    "                            # Print the exception for debugging purposes\n",
    "                            print(f\"Error: {e}\")\n",
    "\n",
    "                        finally:\n",
    "                            # Navigate back to the main page\n",
    "                            driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Print the exception for debugging purposes\n",
    "                    print(f\"Error: {e}\")\n",
    "        finally:\n",
    "            driver.quit()\n",
    " \n",
    "    if \"welcometothejungle\" in sources:\n",
    "        source = \"welcometothejungle\"\n",
    "        rootLink = \"https://www.welcometothejungle.com\"\n",
    "        service = ChromeService(\"C:/Users/leogo/Documents/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        try:\n",
    "            for page in range(1,pages+1):    \n",
    "                try:\n",
    "                    driver.get(f'{rootLink}/fr/jobs?query=data&aroundQuery=France&page={page}')\n",
    "                    # Initial find of elements\n",
    "                    try:\n",
    "                        accept_cookies_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#axeptio_btn_acceptAll'))\n",
    "                        )\n",
    "\n",
    "                        accept_cookies_button.click()\n",
    "                    except TimeoutException:\n",
    "                        pass\n",
    "                        \n",
    "                    offers = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"ol[data-testid='search-results']\"))\n",
    "                    )\n",
    "                    \n",
    "                    # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    # Getting docs left if last page to query\n",
    "                    if nb_docs%30 != 0 and page==pages: \n",
    "                        limit = nb_docs%30\n",
    "                        div_elements_to_click_list = offers.find_elements(By.CSS_SELECTOR, \"li\")[:limit]\n",
    "                    else :\n",
    "                        div_elements_to_click_list = offers.find_elements(By.CSS_SELECTOR, \"li\")\n",
    "\n",
    "                    for index in range(len(div_elements_to_click_list)):\n",
    "                        try:\n",
    "                            offers = WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"ol[data-testid='search-results']\"))\n",
    "                            )\n",
    "                            \n",
    "                            div_elements_to_click_list = offers.find_elements(By.CSS_SELECTOR, \"li\")\n",
    "                            div_elements_to_click = div_elements_to_click_list[index]\n",
    "                            # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                            # driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "                            # Check if the index is within the valid range\n",
    "                            div_offer = div_elements_to_click.find_element(By.CSS_SELECTOR,\"div\")\n",
    "\n",
    "                            position_elem = div_offer.find_element(By.CSS_SELECTOR,\"h4\")\n",
    "                            position = position_elem.text\n",
    "                            workplace = position_elem.find_elements(By.XPATH, \"./following::*//span\")[1].text\n",
    "                            contract_type_icon = div_offer.find_element(By.CSS_SELECTOR,\"i[name='contract']\")\n",
    "                            main_contract_div = driver.execute_script(\"return arguments[0].parentNode;\", contract_type_icon)\n",
    "                            contract_type = main_contract_div.find_element(By.CSS_SELECTOR,\"span\").text\n",
    "                            published_date = div_offer.find_element(By.CSS_SELECTOR,\"time\").get_attribute(\"datetime\").split(\"T\")[0]\n",
    "                            published_date = datetime.strptime(published_date, '%Y-%m-%d')\n",
    "                            published_date = published_date.strftime('%d/%m/%Y')\n",
    "                            # driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_elements_to_click)\n",
    "                            # company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "                            # contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "                            # workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "                            # published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "                            # Scroll into view\n",
    "                            # actions = ActionChains(driver)\n",
    "                            # actions.move_to_element(div_elements_to_click).click().perform()\n",
    "                            #On remote de deux niveau du bouton \"Voir offre\" pour pouvoir r√©cup√©rer les informations appropri√©es\n",
    "                            # div_offer = driver.execute_script(\"return arguments[0].parentNode.parentNode;\", div_elements_to_click)\n",
    "                            # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "                            # company = company_elem.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "                            # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "                            # contract_type = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='contract']\").text\n",
    "                            # workplace = div_offer.find_elements(By.CSS_SELECTOR, \"div[data-cy='loc']\")[-1].text\n",
    "                            # published_date = div_offer.find_elements(By.CSS_SELECTOR, \"span[data-cy='publishDate']\")[-1].text\n",
    "\n",
    "                            driver.execute_script(\"arguments[0].click();\", div_offer)\n",
    "                            WebDriverWait(driver, 20).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-testid='job-section-description']\"))\n",
    "                            )\n",
    "                            description_elem = driver.find_element(By.CSS_SELECTOR,\"div[data-testid='job-section-description']\")\n",
    "\n",
    "                            # driver.execute_script(\"arguments[0].click();\",description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "                            \n",
    "                            WebDriverWait(driver, 3)\n",
    "\n",
    "                            try:\n",
    "                                profile_elem = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='job-section-experience']\")\n",
    "                                profile_html = profile_elem.find_elements(By.CSS_SELECTOR, \"div\")[-2].get_attribute(\"innerHTML\")\n",
    "                                profile = BeautifulSoup(profile_html, 'html.parser').get_text()\n",
    "                            except NoSuchElementException:\n",
    "                                # If profile element is not found, set it to \"NULL\"\n",
    "                                profile = \"NULL\"\n",
    "                            # driver.execute_script(\"arguments[0].click();\",profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "\n",
    "                            description = description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "                            # profile = profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "                            \n",
    "                            #parsing tags\n",
    "                            description = BeautifulSoup(description, 'html.parser').get_text()\n",
    "                            company_elem = driver.find_element(By.CSS_SELECTOR,\"a[href*='/fr/companies/']\")\n",
    "                            company = company_elem.find_element(By.CSS_SELECTOR,\"img\").get_attribute(\"alt\")\n",
    "                            long_infos = \" \".join([description,profile])\n",
    "                            # print(long_infos)\n",
    "                            # Wait for the child element to become present in the DOM\n",
    "\n",
    "                            # # Get the page source after the click\n",
    "                            # page_source = driver.page_source\n",
    "\n",
    "                            # Use Beautiful Soup to parse the page source\n",
    "                            # soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                            # Example: Retrieve the text of a specific element\n",
    "                            # desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "                            # descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "                            # profile = soup.select(\"h4:contains('Profil recherch√©') + p\")\n",
    "                            # profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "                            # position = soup.select_one(\"span[data-cy='jobTitle']\").text\n",
    "                            # position_type = soup.select_one('h4:contains(\"Secteur d‚Äôactivit√© du poste\")+span').text\n",
    "                            # long_infos = soup.select(\"section\")\n",
    "                            # infos = [item.text.replace(\"\\n\",\" \").strip() for item in long_infos]\n",
    "                            # infos = [re.sub(r'\\s+', ' ',item) for item in infos]\n",
    "                            # infos = \" \".join([item for item in infos if item != ''])\n",
    "                            # infos = [item for item in infos if '' not in item]\n",
    "                            corpus.append({\"source\":source,\"link\":rootLink,\"position\":position,\"position_type\":\"NULL\",\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":long_infos})\n",
    "                        except Exception as e:\n",
    "                            # Print the exception for debugging purposes\n",
    "                            print(f\"Error: {e}\")\n",
    "\n",
    "                        finally:\n",
    "                            # Navigate back to the main page\n",
    "                            driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Print the exception for debugging purposes\n",
    "                    print(f\"Error: {e}\")\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    return(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "corpus = scrapCorpus(sources=[\"emploi-territorial\",\"hellowork\",\"welcometothejungle\"],keyword=\"data\",nb_docs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Officer - Data Factory H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'EURO-INFORMATION DEVELOPPEMENTS',\n",
       "  'workplace': 'Nantes - 44',\n",
       "  'published_date': '27/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Notre raison d'√™tre : Ensemble, Ecouter et Agir.Vos missionsVous souhaitez travailler dans un environnement innovant et au sein d'une √©quipe √† taille humaine ? La Data Factory est le d√©partement d√©di√© √† la donn√©e au sein d'Euro-Information au service de l'ensemble des entit√©s du groupe et la diversit√© de leurs m√©tiers pour la valorisation des donn√©es.- Nous fournissons les environnements (Vertica, Hadoop) et la technologie (Jupyter Lab pour python, R, SPSS, SAS, SAP BO ou IB Webfocus).- Nous les peuplons de donn√©es (plus de 90 billions de donn√©es et en extension).- Nous en assurons la s√©curit√© et le respect de l'intimit√© num√©rique des clients.- Nous accompagnons les m√©tiers du groupe dans l'utilisation des donn√©es au service de leurs clients, de la BI √† la Data science. Nous regroupons des profils compl√©mentaires qui travaillent ensemble. Data engineer, Data architect, Data scientists, Concepteurs BI, Data officers... Nous cherchons un(e) Data Officer.Nous avons une grande vari√©t√© de projets, tant sur les m√©tiers concern√©s (vente, gestion, fraude sur la banque, l'assurance, l'immobilier...) que sur les objectifs (scores pr√©dictifs, reporting, connaissance ou administration de la donn√©e...). Vous pilotez et menez √† bien des projets de valorisation de donn√©es :- Conduisez les projets de bout en bout : de l'expression du besoin jusqu'√† la r√©alisation et au suivi de sa performance.- Mobilisez l'ensemble des acteurs : Business, Data scientists et/ou concepteurs BI, Data engineer...- Eclairez et participez aux prises de d√©cision.- Mutualisez les travaux et les bonnes pratiques entre les acteurs et les diff√©rents m√©tiers du groupe.Vous √™tes l'un des gardiens des donn√©es :- Participez √† l'administration des alimentations, usages et droits d'acc√®s en contact avec les Data engineers, data architects et les m√©tiers.- Portez une am√©lioration continue de ces process.- Pilotez des projets de connaissance et de qualit√© des donn√©es.- Participez √† l'acculturation Data au sein du groupe, au sein de vos projets et au-del√†.Ce que vous allez vivre chez nous- T√©l√©travail (2 jours par semaine)- R√©mun√©ration fixe vers√©e sur 13 mois- RTT- Int√©ressement, participation et abondement- Plan √©pargne entreprise et PERCO- Contrat de sant√© collectif- Pr√©voyance- Retraite suppl√©mentaire prise en charge √† 100% par l'employeur- Conditions bancaires et assurances pr√©f√©rentielles- Politique parentale avantageuseCe que nous allons aimer chez vousDe formation √©cole d'ing√©nieur ou universitaire en statistiques, traitement de l'information, math√©matiques appliqu√©es et/ou informatique d√©cisionnelle vous maitrisez un outil/langage d√©cisionnel (Python, R, SAS, SPSS, SAP BO...). Vous avez le go√ªt de la Data. Vous avez acquis une solide exp√©rience dans les projets Data, BI ou Data science en tant que chef de projet. Une ma√Ætrise de l'anglais sera un plus. Ce qui nous plaira le plus chez vous, c'est vous ! Organis√©(e), motiv√©(e), ouvert(e) et force de proposition ? L'√©quipe vous attend.Autres informationsLe poste est √† pourvoir √† Villeneuve d'Ascq ou Nantes d√®s que possible. Bienvenue chez EURO-INFORMATION DEVELOPPEMENTS Qui sommes nousEuro-Information, filiale technologique de Cr√©dit Mutuel Alliance F√©d√©rale, con√ßoit, r√©alise, maintient et exploite un syst√®me d'information commun utilis√© par le Groupe. Les activit√©s de d√©veloppement et de production informatique au niveau national et international sont assur√©es par environ 4000 salari√©s r√©partis sur plusieurs sites g√©ographiques au niveau national : Strasbourg, Nancy, Dijon, Orl√©ans, Lyon, Lille, Cergy, Val de Fontenay, Paris et Nantes. Premi√®re Banque √† adopter le statut d'entreprise √† mission, le Cr√©dit Mutuel Alliance F√©d√©rale s'investit et s'engage dans diff√©rentes missions sociales et environnementales :- L'accompagnement de tous par notre organisation coop√©rative et mutualiste reste au coeur de notre ADN.- La technologie au service de l'humain est une r√©f√©rence dans notre monde connect√©.- La solidarit√© et l'√©co-responsabilit√© deviennent des axes cl√©s dans notre d√©veloppement. En r√©sum√© : Data Officer - Data Factory H/F EURO-INFORMATION DEVELOPPEMENTS Postuler sur le site du recruteur Nantes - 44 CDI 40 000 - 60 000 EUR par an üè† T√©l√©travail partiel Bac +5 Banque ‚Ä¢ Assurance ‚Ä¢ Finance 2 de plus 2 de moins Publi√©e le 27/12/2023 - R√©f : 74238_3\"},\n",
       " {'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Officer - Data Factory H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'EURO-INFORMATION DEVELOPPEMENTS',\n",
       "  'workplace': \"Villeneuve-d'Ascq - 59\",\n",
       "  'published_date': '27/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Notre raison d'√™tre : Ensemble, Ecouter et Agir.Vos missionsVous souhaitez travailler dans un environnement innovant et au sein d'une √©quipe √† taille humaine ? La Data Factory est le d√©partement d√©di√© √† la donn√©e au sein d'Euro-Information au service de l'ensemble des entit√©s du groupe et la diversit√© de leurs m√©tiers pour la valorisation des donn√©es.- Nous fournissons les environnements (Vertica, Hadoop) et la technologie (Jupyter Lab pour python, R, SPSS, SAS, SAP BO ou IB Webfocus).- Nous les peuplons de donn√©es (plus de 90 billions de donn√©es et en extension).- Nous en assurons la s√©curit√© et le respect de l'intimit√© num√©rique des clients.- Nous accompagnons les m√©tiers du groupe dans l'utilisation des donn√©es au service de leurs clients, de la BI √† la Data science. Nous regroupons des profils compl√©mentaires qui travaillent ensemble. Data engineer, Data architect, Data scientists, Concepteurs BI, Data officers... Nous cherchons un(e) Data Officer.Nous avons une grande vari√©t√© de projets, tant sur les m√©tiers concern√©s (vente, gestion, fraude sur la banque, l'assurance, l'immobilier...) que sur les objectifs (scores pr√©dictifs, reporting, connaissance ou administration de la donn√©e...). Vous pilotez et menez √† bien des projets de valorisation de donn√©es :- Conduisez les projets de bout en bout : de l'expression du besoin jusqu'√† la r√©alisation et au suivi de sa performance.- Mobilisez l'ensemble des acteurs : Business, Data scientists et/ou concepteurs BI, Data engineer...- Eclairez et participez aux prises de d√©cision.- Mutualisez les travaux et les bonnes pratiques entre les acteurs et les diff√©rents m√©tiers du groupe.Vous √™tes l'un des gardiens des donn√©es :- Participez √† l'administration des alimentations, usages et droits d'acc√®s en contact avec les Data engineers, data architects et les m√©tiers.- Portez une am√©lioration continue de ces process.- Pilotez des projets de connaissance et de qualit√© des donn√©es.- Participez √† l'acculturation Data au sein du groupe, au sein de vos projets et au-del√†.Ce que vous allez vivre chez nous- T√©l√©travail (2 jours par semaine)- R√©mun√©ration fixe vers√©e sur 13 mois- RTT- Int√©ressement, participation et abondement- Plan √©pargne entreprise et PERCO- Contrat de sant√© collectif- Pr√©voyance- Retraite suppl√©mentaire prise en charge √† 100% par l'employeur- Conditions bancaires et assurances pr√©f√©rentielles- Politique parentale avantageuseCe que nous allons aimer chez vousDe formation √©cole d'ing√©nieur ou universitaire en statistiques, traitement de l'information, math√©matiques appliqu√©es et/ou informatique d√©cisionnelle vous maitrisez un outil/langage d√©cisionnel (Python, R, SAS, SPSS, SAP BO...). Vous avez le go√ªt de la Data. Vous avez acquis une solide exp√©rience dans les projets Data, BI ou Data science en tant que chef de projet. Une ma√Ætrise de l'anglais sera un plus. Ce qui nous plaira le plus chez vous, c'est vous ! Organis√©(e), motiv√©(e), ouvert(e) et force de proposition ? L'√©quipe vous attend.Autres informationsLe poste est √† pourvoir √† Villeneuve d'Ascq ou Nantes d√®s que possible. Bienvenue chez EURO-INFORMATION DEVELOPPEMENTS Qui sommes nousEuro-Information, filiale technologique de Cr√©dit Mutuel Alliance F√©d√©rale, con√ßoit, r√©alise, maintient et exploite un syst√®me d'information commun utilis√© par le Groupe. Les activit√©s de d√©veloppement et de production informatique au niveau national et international sont assur√©es par environ 4000 salari√©s r√©partis sur plusieurs sites g√©ographiques au niveau national : Strasbourg, Nancy, Dijon, Orl√©ans, Lyon, Lille, Cergy, Val de Fontenay, Paris et Nantes. Premi√®re Banque √† adopter le statut d'entreprise √† mission, le Cr√©dit Mutuel Alliance F√©d√©rale s'investit et s'engage dans diff√©rentes missions sociales et environnementales :- L'accompagnement de tous par notre organisation coop√©rative et mutualiste reste au coeur de notre ADN.- La technologie au service de l'humain est une r√©f√©rence dans notre monde connect√©.- La solidarit√© et l'√©co-responsabilit√© deviennent des axes cl√©s dans notre d√©veloppement. En r√©sum√© : Data Officer - Data Factory H/F EURO-INFORMATION DEVELOPPEMENTS Villeneuve-d'Ascq - 59 CDI 40 000 - 60 000 EUR par an üè† T√©l√©travail partiel Bac +5 Banque ‚Ä¢ Assurance ‚Ä¢ Finance 2 de plus 2 de moins Publi√©e le 27/12/2023 - R√©f : 74238_70\"},\n",
       " {'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Technique H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'Utigroup',\n",
       "  'workplace': 'Dijon - 21',\n",
       "  'published_date': '25/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Vous intervenez activement sur la mont√©e en puissance du Syst√®me d'Information G√©ographique interne de notre client en Banque, votre mission constiste √† :- R√©alisez les d√©veloppements Python de nouvelles fonctionnalit√©s en utilisant les librairies adapt√©es (Folium, GeoPanda, OpenStreetMap) et proposez de nouveaux usages.- Etudiez les diff√©rentes sources open data et qualification des donn√©es.- Int√©grez de nouvelles sources de donn√©es (ETL Stambia ou script SQL) et construction d'automatisme d'int√©gration de donn√©es depuis un fichier open vers une BDD interne.- R√©alisez des POC avec les utilisateurs sur notre notebook Jupyter Lab.- Participez √† la r√©alisation de projet avec les utilisateurs m√©tiers (atelier m√©tier avec les utilisateurs, expression de besoin, √©tude de faisabilit√©, d√©veloppement et suivi projet). Le profil recherch√© - Vous √™tes titulaire d'un Bac +5.- Vous m√¢itrisez : Python, HP Vertica, Stambia, l'environnement SIG (Syst√®me d'Information G√©ographique).- Vous √™tes autonome.- Vous avez de bonnes capacit√©s d'analyse et √™tes capables de g√©rer plusieurs sujets en parall√®le.- Vous avez l'esprit d'√©quipe, des aptitudes √† communiquer et le sens du service rendu. L'entreprise Rejoindre UTIGroup, c'est rejoindre une Soci√©t√© √† taille humaine qui investit sur l'accompagnement de ses Consultants, et o√π la prise de d√©cision est rapide.Certifi√©e ISO 9001/2015, UTIGroup a eu 35 ans en 2021.Solidit√© et transparence financi√®re (notre soci√©t√© est cot√©e en Bourse depuis plus de 20 ansNotation ECO-Vadis exceptionnelle (79/100) : niveau PLATINIUM (RSE, √©thique, social et achats responsables)UTIGroup respecte les textes internationaux, europ√©ens et la l√©gislation Fran√ßaise en mati√®re de discrimination. Mais aussi... - Statut Cadre.- RTT.- Ticket restaurant.- Mutuelle.- Participation au transport.- Assurance d√©c√®s - invalidit√©. En r√©sum√© : Data Technique H/F Utigroup Super recruteur Postuler Dijon - 21 CDI 40 000 - 46 000 EUR par an Bac +5 M√©dia ‚Ä¢ Internet ‚Ä¢ Communication Distribution ‚Ä¢ Commerce de gros Secteur informatique ‚Ä¢ ESN Exp. 1 √† 7 ans Exp. + 7 ans 6 de plus 6 de moins Publi√©e le 25/12/2023 - R√©f : 617708/2022925 DT/21D\"},\n",
       " {'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Modeler H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'VOLT',\n",
       "  'workplace': 'Alpes-Maritimes - 06',\n",
       "  'published_date': '22/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Nous recherchons pour l'un de nos clients un Data modeler. Le poste est √† pourvoir aux alentours de Nice.Vos missions :- Soutien renforc√© sur la gestion des donn√©es- Mod√©lisation du Data Warehouse (DWH)- Collaboration au sein de l'√©quipe de data engineering- Travaux ax√©s sur Spotfire pour la Business Intelligence (BI)Votre environnement technique :- Data warehouses et la mod√©lisation dimensionnelle (en √©toile)- M√©thode sp√©cifique de mod√©lisation et de conception de syst√®mes d√©cisionnels Kimball- Avoir une bonne ma√Ætrise du langage SQL- Id√©alement, avoir des comp√©tences en Sas Designer, Python et Excel- M√©thodes Agiles notamment Kanban/Scrum Le profil recherch√© - Vous justifiez de minimum de 4 ans d'exp√©rience professionnelle en tant que Data modeler.- Vous √™tes un bon communiquant et appr√©ciez travailler en √©quipe.- Vous √™tes force de proposition et autonome.- Vous parlez couramment fran√ßaisD√©marrage : ASAPLieu du poste : Alentours de NiceContrat : CDI Bienvenue chez VOLT A la fois Cabinet de recrutement & Soci√©t√© de conseil, VOLT (Innova Solutions) a une couverture nationale. Nous sommes bas√©s √† Sophia Antipolis, au coeur de la French Riviera, nous accompagnons nos clients dans toute la France et offrons √† nos candidats des postes dans les secteurs de l'IT, des T√©l√©coms et de l'Engineering.Nos clients ont acc√®s √† plus de 85 bureaux √† travers le monde :- Aux √âtats-Unis- En Europe (Belgique et Nice)- Aux Royaume-Uni- A Singapour- En Inde En r√©sum√© : Data Modeler H/F VOLT Postuler Alpes-Maritimes - 06 CDI Bac +2 Bac +3, Bac +4 Bac +5 Secteur informatique ‚Ä¢ ESN Exp. 1 √† 7 ans Exp. + 7 ans 6 de plus 6 de moins Publi√©e le 22/12/2023 - R√©f : 1838682/10659445 DM/06A\"},\n",
       " {'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Manager Data H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'Interima',\n",
       "  'workplace': 'Cagnes-sur-Mer - 06',\n",
       "  'published_date': 'il y a 7 heures',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Nous recrutons pour l'un de nos client un(e) Manager Data H/F en CDI,Vos missions :Votre responsabilit√©, en tant que Manager Data s'√©tendra aux missions suivantes :- Mettre en place les process et workflow ¬´ Master Data ¬ª en √©troite collaboration avec des keys users- √ätre garant de la qualit√© de la donn√©e tout au long de son cycle de vie, notamment gr√¢ce aux outils appropri√©s- Construire le reporting et KPI dans PowerBI (Microsoft). Elaborer le plan des priorit√©s, mettre en place le RACI des droits utilisateurs/destinataires. Gestion des actifs, espace de travail...- Construire la Data Warehouse / Data Lake (agr√©gation des donn√©es) - Mettre en place un ETL (gestion des flux des donn√©es)- Construire la vision de la donn√©e IA (Intelligence Artificielle, big data, simulations...) - Fournir les requ√™tes SQL selon le besoin des m√©tiers Le profil recherch√© De formation Bac +3/+5 de type Business Intelligence, Data Analyste, PowerBI.Vous disposez d'une exp√©rience r√©ussie de d'environ 5 ans sur un poste similaire ou en ESN sp√©cialis√©e- Vous disposez de bases solides en connaissance SQL. Connaissance de l'outil PowerBI est un pr√©requis.- Vous avez construit un environnement de stockage de donn√©es de type Data Warehouse, Data Lake...- Vous avez g√©r√© la diffusion des reporting/KPI avec l'aide de pack office365.- Vous √™tes rigoureux¬∑se, autonome, dot√©¬∑e d'une vraie capacit√© d'analyse et de bonnes capacit√©s r√©dactionnelles. Vous aimez travailler en √©quipe et savez faire preuve de coop√©ration.Contrat 38h du Lundi au VendrediType d'emploi : Temps plein, CDI L'entreprise Le Groupe Interima est un r√©seau r√©gional ind√©pendant de travail temporaire, recrutement, formation et comp√©tences.Nos √©quipes vous proposent des postes en int√©rim, CDD, CDI et CDI Int√©rimaires via nos sept bureaux Interima r√©partis sur l'ensemble des Alpes-Maritimes. En r√©sum√© : Manager Data H/F Interima Postuler Cagnes-sur-Mer - 06 CDI 60 000 - 65 000 EUR par an Bac +3, Bac +4 Services aux Personnes ‚Ä¢ Particuliers Services aux Entreprises Exp. 1 √† 7 ans 4 de plus 4 de moins Publi√©e le 28/12/2023 - R√©f : 1787875/10169130 MD/06C\"}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'emploi-territorial',\n",
       "  'link': 'https://www.emploi-territorial.fr',\n",
       "  'position': 'Ing√©nieur data F/H',\n",
       "  'position_type': \"Informatique et syst√®me d'information\",\n",
       "  'company': 'CONSEIL DEPARTEMENTAL DU NORD',\n",
       "  'workplace': 'Lille cedex',\n",
       "  'published_date': '19/12/2023',\n",
       "  'contract_type': \"Emploi permanent - cr√©ation d'emploi\",\n",
       "  'description': \"Le D√©partement du Nord place les syst√®mes d'information au c≈ìur du projet de transformation digitale au service de l'usager et de ses partenaires. La Direction des Syst√®mes d'Information (environ 110 collaborateurs, 7000 postes de travail, 200 sites) poursuit le d√©veloppement de projets innovants :\\n-\\tLa s√©curisation de ses infrastructures, le d√©veloppement du haut d√©bit pour ses √©tablissements, des plateformes t√©l√©phoniques, des syst√®mes de GED et de num√©risation.\\n-\\tDe nombreux chantiers autour du poste de travail comme la mobilit√© en autres\\n-\\tLa mise en ≈ìuvre d'applications au service des comp√©tences d√©partementales, la solidarit√©, la mobilit√©, la jeunesse, le sport, la culture, le d√©veloppement des territoires.\\n\\nAu sein de la DSI, vous √™tes rattach√©-e au service Pilotage et S√©curisation SI, qui anime les Consultants Internes SI, les ing√©nieur-es S√©curit√© et une cellule Data (Donn√©es SI). La cellule DATA initie la structuration de la donn√©e dans ses missions de d√©finition et de pilotage d'un √©cosyst√®me Data de la collectivit√©.\\nLes missions de la cellule Data (Donn√©es SI) :\\n*\\tSTRUCTURER : d√©finir et piloter la mise en ≈ìuvre de l'√©cosyst√®me Data de la collectivit√©, autour de la collecte, du stockage, du r√©f√©rencement, de la qualit√©, de la visualisation et la diffusion des donn√©es.\\n*\\tACCOMPAGNER l'usage : aider √† faire parler les donn√©es et √™tre un support aux √©quipes de pilotage des directions m√©tiers. \\n*\\tCAPITALISER notre patrimoine de donn√©es : ≈ìuvrer au r√©f√©rencement et √† la collecte des donn√©es √† des fins de r√©emploi ; en premier lieu pour l'analyse des donn√©es (dont d√©cisionnel) puis pour la circulation des donn√©es entre les syst√®mes.\\n\\nEn qualit√© d'ing√©nieur-e data, vous √™tes le/la r√©f√©rent-e technique de la collectivit√© pour les projets d'int√©gration et de stockage des donn√©es et vous apportez l'expertise technique n√©cessaire pour le d√©veloppement des solutions data appropri√©es. Pour ce faire, vous contribuez activement √† :\\n*\\tD√©finir l'architecture d√©cisionnelle cible et les besoins d'infrastructures n√©cessaires au stockage et √† la valorisation des donn√©es.\\n*\\tConcevoir les projets d'industrialisation de traitement des donn√©es et superviser les √©quipes op√©rationnelles dans les projets d'int√©gration (process ETL, entrep√¥ts de donn√©es...). \\n*\\tParticiper aux chantiers data structurants (qualit√©, r√©f√©rentiels et cartographie des donn√©es, urbanisation...).\\n*\\tGarantir la coh√©rence et la s√©curit√© de l'√©cosyst√®me d√©cisionnel d√©partemental.\\n*\\tAccompagner les directions m√©tiers dans les projets d√©cisionnels (recueil des besoins, mod√©lisation des donn√©es...) et fournir aux √©quipes (data analystes) un appui technique √† l'exploration complexe des donn√©es. \\nRelations professionnelles : \\nInterne : Relations directes avec l'√©quipe de direction et les services de la DSI, les secr√©tariats g√©n√©raux et les autres directions de la collectivit√© (responsables et collaborateurs des dites directions).\\nExterne : Prestataires, √©diteurs, autres collectivit√©s, minist√®res. Savoir faire \\n Assistance √† la ma√Ætrise d'ouvrage op√©rationnelle \\n*\\tParticiper √† la conduite du changement \\n*\\tD√©finir des sp√©cifications fonctionnelles √† partir de l'expression des besoins \\n\\nPilotage et conduite de projet d'informatisation \\n*\\t√âvaluer les enjeux et les risques (techniques, financiers, organisationnels) d'un projet informatique \\n*\\t√âlaborer le cahier des charges et le calendrier de r√©alisation \\n*\\tOp√©rer des choix techniques en mati√®re de logiciels \\n*\\tOrganiser le d√©roulement du projet et planifier les travaux de d√©veloppement \\n\\nMaintien en conditions op√©rationnelles des applications et plateformes (MCO) \\n*\\tAssurer l'assistance de niveau 3 (expertise, probl√®mes complexes, etc.) \\n*\\tAssurer la maintenance corrective \\n*\\tAssurer la maintenance √©volutive et la gestion des changements (au sens ITIL)\\n\\nConception et int√©gration d'applications \\n*\\tR√©aliser les sp√©cifications fonctionnelles et techniques \\n*\\tMettre en ≈ìuvre des progiciels (param√©trage, reprise de donn√©es, interfaces, d√©veloppements sp√©cifiques, etc.) \\n*\\tR√©aliser des tests des programmes et des prototypes \\n*\\tR√©diger la documentation (guides, modes op√©ratoires, etc.) \\n\\nAssistance et appui technique aupr√®s des services de la collectivit√© \\n*\\tSensibiliser les services et diffuser des supports d'information \\n*\\tConduire une action de formation en interne \\n\\nVeille et observation sectorielle \\n*\\tEnrichir des bases documentaires et d'information \\n\\nGestion de la commande publique \\n*\\t√âlaborer les cahiers des charges et pi√®ces du march√© public * D√©finir des crit√®res de s√©lection des offres \\n*\\tPr√©parer les dossiers des commissions d'appels d'offres \\n*\\tAnalyser les propositions techniques et financi√®res des fournisseurs et entreprises \\n*\\tN√©gocier avec les fournisseurs et les entreprises \\n*\\tAttester le service fait \\n\\nElaboration et suivi du budget \\n*\\tPlanifier les besoins budg√©taires et √©laborer un budget pr√©visionnel \\n*\\tSuivre et contr√¥ler l'ex√©cution du budget \\n*\\tRenseigner des outils de pilotage et de suivi (tableaux de bord) \\n\\nContr√¥le de la qualit√© des services rendus \\n*\\tV√©rifier la conformit√© des prestations des entreprises avec les clauses techniques d√©finies dans les pi√®ces du march√© \\n*\\t√âtablir des rapports et bilans d'activit√©s \\n\\nContr√¥le et suivi des prestations effectu√©es par des tiers \\n*\\tR√©ceptionner et contr√¥ler les projets, travaux et prestations fournis par des tiers \\n\\nConduite de projet \\n*\\tOrganiser et animer des groupes projet et des comit√©s de pilotage \\n*\\tIdentifier et mobiliser les acteurs et les comp√©tences n√©cessaires √† la conduite d'un projet Savoirs  \\n*\\t M√©thodes et outils de la planification \\n*\\tArchitecture et fonctionnalit√©s des SI \\n*\\tR√®gles et aspects l√©gaux des SI \\n*\\tTechniques de conception, mod√©lisation et architecture d'applications \\n*\\tMarch√© de l'offre informatique \\n*\\tNormes et proc√©dures de s√©curit√© \\nFonctionnement de la collectivit√© et des services \\n*\\tTechniques d'√©laboration de cahier des charges et de planification d'√©tudes  \\n*\\tTechniques d'analyses comparatives (benchmarking) \\n*\\tCode des march√©s publics et modalit√©s d'application \\n*\\tR√®gles et techniques d'expression √©crite et r√©dactionnelles (notes, compte-rendu, rapports, etc.) \\n*\\tR√®gles relatives √† l'acc√®s aux documents administratifs \\n*\\tTechniques r√©dactionnelles de rapports et bilans d'activit√© \\n*\\tM√©thodes et techniques de r√©ception des travaux et prestations \\n\\n   Savoir - √™tre \\n*\\tDisposer d'une bonne aisance relationnelle \\n*\\tDisposer de bonnes capacit√©s d'analyse et de synth√®se \\n*\\tSavoir travailler en transversalit√© \\n*\\tFaire preuve d'esprit d'√©quipe et de capacit√© √† coop√©rer  \\n*\\tFaire preuve d'autonomie \\n*\\tAvoir de bonnes capacit√©s d'√©coute  \\n\\n Obligations du poste : \\n- Formation sup√©rieure, id√©alement bac+5 en informatique ou √©cole d'ing√©nieurs, \\n- Une ou plusieurs exp√©riences dans le d√©veloppement de projets d'int√©gration de donn√©es\\n\\nConditions particuli√®res : \\n - D√©placements possibles sur les sites \\n-  Fonction T√©l√©travaillable\"},\n",
       " {'source': 'emploi-territorial',\n",
       "  'link': 'https://www.emploi-territorial.fr',\n",
       "  'position': 'Ing√©nieur DATA H/F',\n",
       "  'position_type': 'Pilotage',\n",
       "  'company': 'CONSEIL DEPARTEMENTAL DE HAUTE-SAVOIE',\n",
       "  'workplace': 'Annecy',\n",
       "  'published_date': '15/12/2023',\n",
       "  'contract_type': \"Emploi permanent - cr√©ation d'emploi\",\n",
       "  'description': 'Sous l\\'autorit√© du responsable de l\\'Unit√© Urbanisation et Intelligence de la donn√©e, l\\'Ing√©nieur data assure la disponibilit√© des diff√©rentes briques DATA de notre syst√®me d\\'information. En √©troite collaboration avec les diff√©rents services de la collectivit√©, vous contribuez √† la collecte, nettoyage et organisation des donn√©es provenant de diff√©rentes sources. Vous utilisez des outils et des techniques d\\'analyse de donn√©es pour extraire des informations pertinentes, identifier des tendances et des mod√®les, et effectuer des analyses approfondies. L\\'Ing√©nieur data travaille en √©troite collaboration avec les √©quipes m√©tier et les autres services de la DSI pour comprendre leurs besoins et proposer des solutions bas√©es sur les donn√©es. Il surveille √©galement les performances des mod√®les et des analyses, en effectuant des ajustements et des am√©liorations r√©guli√®res.\\n\\nL\\'objectif global de l\\'Ing√©nieur data sera de s\\'assurer en priorit√© de la disponibilit√© des infrastructure et moteur de base de donn√©es, puis ensuite d\\'exploiter les donn√©es pour g√©n√©rer des connaissances et des informations exploitables, afin de soutenir la prise de d√©cisions √©clair√©es et d\\'am√©liorer la performance globale de la collectivit√©. Construire et faire √©voluer le socle DATA\\nParticiper activement, en tant qu\\'expert, √† la construction des entrep√¥ts de donn√©e du CD74 qui contiendra une plateforme d\\'int√©gration, des conteneurs de donn√©es, un moteur d\\'indexation et de recherche, un bus de message, un gestionnaire de workflow, un API manager et des ETL (Talend) ;\\nParticiper activement √† la mod√©lisation de l\\'architecture Data global du CD74 (mod√©lisation des flux et des ressources techniques associ√©es) visant √† rendre interop√©rables des volumes importants et h√©t√©rog√®nes de donn√©es de mani√®re s√©curis√©e ;\\nMaintenir en condition op√©rationnelle ces m√™mes briques ;\\nFaire √©voluer ce socle d\\'application orient√© DATA.\\nGarantir la disponibilit√© des donn√©es du SI\\nAdministrer les bases de donn√©es du SI (Oracle, PostgreSQL, MySQL) ;\\nSauvegarder, restaurer ;\\nSuivre le versioning et le licensing des moteurs de bases de donn√©es ;\\n√ätre force de proposition d\\'axes d\\'am√©lioration (processus et technique) visant √† professionnaliser/industrialiser la gestion des donn√©es du SI.\\nTransformer la performance en excellence, en contribuant aux projets d\\'efficience\\nComprendre les besoins m√©tiers en s\\'appuyant sur les √©quipes et utilisateurs cl√©s ;\\nParticiper √† la r√©alisation des cahiers des charges ;\\n√ätre le point de contact privil√©gi√© des interlocuteurs m√©tiers sur les sujets data ;\\nMener les tests en interactions avec les √©quipes de la DSI et les utilisateurs cl√©s ;\\nTenir le bon niveau de discours apte √† rendre les sujets Data compr√©hensibles par les diff√©rentes populations d\\'utilisateurs cl√©s.\\nMesurer la performance, avec un √©tat d\\'esprit \" data \" avec les comp√©tences et connaissances appr√©ci√©s suivantes\\nMa√Ætrise des solutions de bases de donn√©es (SQL, NoSQL...) ;\\nConnaissances en langages structur√©s (Javascript, Java, Python...) ;\\nApp√©tence pour l\\'IA et capacit√© √† construire ou participer √† construire des mod√®les de machine learning, Deep Learning et l\\'analyse de texte ;\\nForte expertise le stockage de donn√©es et les outils ETL tels que Talend, Business Objects ;\\nConnaissance en technologies du Big Data permettant le traitement et la manipulation de donn√©es (Hadoop, Spark, Kafka...) ;\\nConnaissance en Master Data Management, DataWarehouses et Data Lakes. Maitrise des moteurs de bases de donn√©es\\nUne bonne connaissance d\\'Oracle, de PostgreSQL et du langage SQL (requ√™te et Scripting)\\nR√©daction de la documentation sur les architectures d√©ploy√©es et les proc√©dures techniques associ√©es pour le MCO\\nCapacit√© √† r√©soudre les probl√®mes techniques et √† diagnostiquer les pannes li√©es aux bases de donn√©es\\nCapacit√© √† documenter les proc√©dures et les meilleures pratiques\\nNous recherchons une personne ayant le sens du travail en √©quipe, le sens du service et de l\\'organisation, et le sens du respect des proc√©dures.\\n\\nVous √™tes curieux(se), autonome et rigoureux(se) ? Vous savez relever les incoh√©rences et faites attention au d√©tail ?Vous avez su faire preuve d\\'organisation et de fiabilit√© au cours de vos pr√©c√©dentes exp√©riences ? Vous √™tes motiv√©(e) pour apprendre et acqu√©rir de nouvelles comp√©tences ? Alors ce poste est fait pour vous et le D√©partement attend votre candidature avant le 15/01/2024'},\n",
       " {'source': 'emploi-territorial',\n",
       "  'link': 'https://www.emploi-territorial.fr',\n",
       "  'position': 'Chef(fe) de projet DATA',\n",
       "  'position_type': \"Informatique et syst√®me d'information\",\n",
       "  'company': \"Conseil D√©partemental d'Eure-et-Loir\",\n",
       "  'workplace': 'Chartres cedex',\n",
       "  'published_date': '19/12/2023',\n",
       "  'contract_type': \"Emploi permanent - cr√©ation d'emploi\",\n",
       "  'description': \"R√©mun√©ration statutaire, r√©gime indemnitaire, collectivit√© affili√©e au cnas, tickets restaurant. Le Conseil d√©partemental, c'est un collectif d'environ 2 000 collaborateurs qui ≈ìuvrent quotidiennement au service des Eur√©liens.\\n\\nLa Direction du num√©rique rassemble une quarantaine de collaborateurs et a pour objectif d'impulser et d'accompagner les changements professionnels, organisationnels et manag√©riaux n√©cessaires √† la transition num√©rique de la collectivit√© et du territoire.\\n\\nDans ce cadre, vous serez rattach√©(e) au Service ing√©nierie des projets et encadrez l'ensemble  des projets de Big data, Data Intelligence et/ou Data Gouvernance.\\n\\nEn tant que responsable de tous les projets innovants dans le domaine de la donn√©e et de l'intelligence artificielle et de leur bonne r√©alisation, vous jouerez un r√¥le d'interface entre les toutes les Directions m√©tiers mais aussi de toutes les parties prenantes du projet. En tant que Chef de projet DATA, vos principales missions seront de :\\n\\n    D√©ployer la strat√©gie de la Collectivit√© en mati√®re d'analyse et de traitement de donn√©es ;\\n    Assurer la coh√©rence des actions des diff√©rents intervenants dans le cadre des plans d'actions li√©s √† la gestion de la donn√©e ;\\n    Veiller √† la conformit√© et √† la bonne organisation des donn√©es dans les syst√®mes d'information, piloter et accompagner le d√©ploiement de la solution aupr√®s des utilisateurs ;\\n     Assurer une veille technologique ;\\n    Apporter des conseils au sujet de la restitution de donn√©es,\\n    Participer activement √† l'activit√© Opendata\\n    D√©finir les r√¥les et responsabilit√©s autour de la donn√©e IT et des r√©f√©rentiels attenants\\n    Mettre en place un contr√¥le qualit√© et une gouvernance sur ces donn√©es\\n    Valoriser ces donn√©es, faire en sorte qu'elles soient compr√©hensibles et exploitables\\n    Faciliter l'acc√®s √† ces donn√©es en respectant les exigences et standards de s√©curit√© et conformit√©.\\n    Assurer le pilotage, la coordination et le suivi de projets num√©riques (√©tat des lieux, d√©finition des objectifs et suivi des d√©lais, plan d'actions, coordination des acteurs, √©valuation...),\\n    Contribuer √† la traduction technique des besoins fonctionnels (analyse fonctionnelle, identification des opportunit√©s et de la faisabilit√© technologique, √©valuation des risques, s√©curit√© du SI)\\n    Assurer une mission de conception et de d√©veloppement (architecture logicielle, r√©alisation d'applications, cartographie de flux, structuration et documentation des bases de donn√©es)\"},\n",
       " {'source': 'emploi-territorial',\n",
       "  'link': 'https://www.emploi-territorial.fr',\n",
       "  'position': \"UN(E) CHEF(FE) DE PROJET RESPONSABLE D'APPLICATIONS SI DATA ET DOCUMENTATION\",\n",
       "  'position_type': 'Mobilit√©, d√©placements et transports',\n",
       "  'company': 'SYNDICAT MIXTE (SM) SYTRAL',\n",
       "  'workplace': 'LYON CEDEX 03',\n",
       "  'published_date': '15/12/2023',\n",
       "  'contract_type': \"Emploi permanent - cr√©ation d'emploi\",\n",
       "  'description': \"Au sein de la Direction des Expertises Techniques et du Patrimoine et du service syst√®mes transverses\\nPlac√©(e) sous la responsabilit√© hi√©rarchique de la responsable du p√¥le informatique\\n\\nMISSIONS\\n* Piloter les activit√©s de mise en ≈ìuvre, de maintenance et d'√©volution des syst√®mes de collecte et d'exploitation des donn√©es des r√©seaux de transport en r√©ponse aux besoins fonctionnels identifi√©s.\\n* Charg√©(e) du bon fonctionnement quotidien des outils mis √† la disposition des utilisateurs SYTRAL Mobilit√©s, op√©rateurs et partenaires, ainsi que du suivi des usages de la plateforme Cloud h√©bergeant les donn√©es.\\n* √ätre le/la r√©f√©rent(e) technique sur les projets data et documentation en lien avec les m√©tiers. 1- Mise en ≈ìuvre des solutions Data et Documentation,\\n- Piloter la mise en ≈ìuvre des projets sur son p√©rim√®tre : cadrage des besoins, chiffrage, r√©daction des cahiers des charges, pilotage des prestations, suivi des risques, validation des livrables et recettes en lien avec les acteurs m√©tier,\\n- Veiller au respect des r√®gles d'urbanisation et de s√©curit√© SI sur les solutions mises en place,\\n- Garantir la qualit√© de la documentation des solutions et assurer la mise √† jour de la cartographie des donn√©es et des flux d'alimentation sur son p√©rim√®tre,\\n- Garantir le respect du budget des solutions Cloud par une surveillance r√©guli√®re des consommations et le suivi d'alertes.\\n2- Fonctionnement quotidien des outils mis √† disposition,\\n- Assurer la gestion des contrats de maintenance des applications du p√©rim√®tre\\n- √ätre l'interface avec les √©diteurs, int√©grateurs ou √©quipe en charge d'une tierce maintenance applicative (TMA),\\n- G√©rer les authentifications et droits sur les donn√©es et sur les infrastructures de la plateforme data (cr√©ation de ressources, stockages, machines...),\\n- G√©rer l'administration fonctionnelle et la maintenance √©volutive des outils de restitution (PowerBi, BO etc...),\\n- Suivre les anomalies et prendre en charge des adaptations sur les applications du p√©rim√®tre,\\n- Animer un plan d'am√©lioration continue et identifier des pistes d'optimisation,\\n- Suivre la qualit√© de service,\\n- R√©diger des proc√©dures et animer les communaut√©s d'utilisateurs.\\n\\n3- Contact technique sur les projets Data en lien avec les m√©tiers,\\n- Contribuer aux √©tudes sur les nouvelles donn√©es √† collecter, en lien avec les op√©rateurs et partenaires,\\n- R√©aliser les analyses d'impacts (faisabilit√©, co√ªts, d√©lais...) sur les demandes relatives √† des fonctionnalit√©s ou √† de nouveaux algorithmes de calculs, en s'appuyant au besoin sur des expertises techniques sp√©cifiques data/IA. Les savoirs\\n\\tIng√©nieur, Bac + 5 avec une exp√©rience dans les domaines de la conduite de projets informatiques ou en tant que responsable d'applications, \\n\\tExpertise technico-fonctionnelle de solutions de Gestion Electronique Documentaire, de mod√©lisation de workflow, de reporting et d'outils de manipulation des donn√©es (ETL),\\n\\tConnaissances des syst√®mes de gestion de bases de donn√©es, mod√®les relationnels ou objets et formats de stockages,\\n\\tConnaissances du fonctionnement des clouds publics,\\n\\tConnaissances en mati√®re de march√©s publics appr√©ci√©es.\\n\\nLes savoir-√™tre\\n\\tPragmatisme,\\n\\tRigueur,\\n\\tEsprit d'analyse et de synth√®se,\\n\\tAisance relationnelle, facult√©s de communication, \\n\\tSens du service client.\\n\\nCONDITIONS DE TRAVAIL\\n\\n- Lieu : 21 Boulevard Vivier Merle 69003 LYON - √† proximit√© de la gare Part-Dieu,\\n- Temps de travail : 35h (7h/j), 37h30 (7h30/j + 15 jours de RTT) ou 38h45 (7h45/j + 22 jours de RTT),\\n- Poste ouvert au t√©l√©travail jusqu'√† 2 jours par semaine sans conditions d'anciennet√©,\\n- R√©mun√©ration statutaire, RIFSEEP (IFSE et CIA), prime de fin d'ann√©e, tickets-restaurant, adh√©sion au Comit√© Social de la M√©tropole de Lyon (voyages, billetterie, culture, loisirs, aides...),\\n- Poste ouvert aux contractuels : il est possible de recruter sur ce poste une personne qui n'est pas laur√©ate d'un concours de la fonction publique.\"},\n",
       " {'source': 'emploi-territorial',\n",
       "  'link': 'https://www.emploi-territorial.fr',\n",
       "  'position': \"Un(e) chef(fe) de projet responsable d'applications SI Data et documentation\",\n",
       "  'position_type': \"Informatique et syst√®me d'information\",\n",
       "  'company': 'SYNDICAT MIXTE (SM) SYTRAL',\n",
       "  'workplace': 'LYON CEDEX 03',\n",
       "  'published_date': '15/12/2023',\n",
       "  'contract_type': \"Emploi permanent - cr√©ation d'emploi\",\n",
       "  'description': \"Au sein de la Direction des Expertises Techniques et du Patrimoine et du service syst√®mes transverses\\nPlac√©(e) sous la responsabilit√© hi√©rarchique de la responsable du p√¥le informatique\\n\\nMISSIONS\\n* Piloter les activit√©s de mise en ≈ìuvre, de maintenance et d'√©volution des syst√®mes de collecte et d'exploitation des donn√©es des r√©seaux de transport en r√©ponse aux besoins fonctionnels identifi√©s.\\n* Charg√©(e) du bon fonctionnement quotidien des outils mis √† la disposition des utilisateurs SYTRAL Mobilit√©s, op√©rateurs et partenaires, ainsi que du suivi des usages de la plateforme Cloud h√©bergeant les donn√©es.\\n* √ätre le/la r√©f√©rent(e) technique sur les projets data et documentation en lien avec les m√©tiers. ACTIVITES PRINCIPALES\\n1- Mise en ≈ìuvre des solutions Data et Documentation,\\n- Piloter la mise en ≈ìuvre des projets sur son p√©rim√®tre : cadrage des besoins, chiffrage, r√©daction des cahiers des charges, pilotage des prestations, suivi des risques, validation des livrables et recettes en lien avec les acteurs m√©tier,\\n- Veiller au respect des r√®gles d'urbanisation et de s√©curit√© SI sur les solutions mises en place,\\n- Garantir la qualit√© de la documentation des solutions et assurer la mise √† jour de la cartographie des donn√©es et des flux d'alimentation sur son p√©rim√®tre,\\n- Garantir le respect du budget des solutions Cloud par une surveillance r√©guli√®re des consommations et le suivi d'alertes.\\n2- Fonctionnement quotidien des outils mis √† disposition,\\n- Assurer la gestion des contrats de maintenance des applications du p√©rim√®tre\\n- √ätre l'interface avec les √©diteurs, int√©grateurs ou √©quipe en charge d'une tierce maintenance applicative (TMA),\\n- G√©rer les authentifications et droits sur les donn√©es et sur les infrastructures de la plateforme data (cr√©ation de ressources, stockages, machines...),\\n- G√©rer l'administration fonctionnelle et la maintenance √©volutive des outils de restitution (PowerBi, BO etc...),\\n- Suivre les anomalies et prendre en charge des adaptations sur les applications du p√©rim√®tre,\\n- Animer un plan d'am√©lioration continue et identifier des pistes d'optimisation,\\n- Suivre la qualit√© de service,\\n- R√©diger des proc√©dures et animer les communaut√©s d'utilisateurs.\\n3- Contact technique sur les projets Data en lien avec les m√©tiers,\\n- Contribuer aux √©tudes sur les nouvelles donn√©es √† collecter, en lien avec les op√©rateurs et partenaires,\\n- R√©aliser les analyses d'impacts (faisabilit√©, co√ªts, d√©lais...) sur les demandes relatives √† des fonctionnalit√©s ou √† de nouveaux algorithmes de calculs, en s'appuyant au besoin sur des expertises techniques sp√©cifiques data/IA. Les savoirs\\n\\tIng√©nieur, Bac + 5 avec une exp√©rience dans les domaines de la conduite de projets informatiques ou en tant que responsable d'applications, \\n\\tExpertise technico-fonctionnelle de solutions de Gestion Electronique Documentaire, de mod√©lisation de workflow, de reporting et d'outils de manipulation des donn√©es (ETL),\\n\\tConnaissances des syst√®mes de gestion de bases de donn√©es, mod√®les relationnels ou objets et formats de stockages,\\n\\tConnaissances du fonctionnement des clouds publics,\\n\\tConnaissances en mati√®re de march√©s publics appr√©ci√©es.\\n\\nLes savoir-√™tre\\n\\tPragmatisme,\\n\\tRigueur,\\n\\tEsprit d'analyse et de synth√®se,\\n\\tAisance relationnelle, facult√©s de communication, \\n\\tSens du service client.\\nCONDITIONS DE TRAVAIL\\n\\n- Lieu : 21 Boulevard Vivier Merle 69003 LYON - √† proximit√© de la gare Part-Dieu,\\n- Temps de travail : 35h (7h/j), 37h30 (7h30/j + 15 jours de RTT) ou 38h45 (7h45/j + 22 jours de RTT),\\n- Poste ouvert au t√©l√©travail jusqu'√† 2 jours par semaine sans conditions d'anciennet√©,\\n- R√©mun√©ration statutaire, RIFSEEP (IFSE et CIA), prime de fin d'ann√©e, tickets-restaurant, adh√©sion au Comit√© Social de la M√©tropole de Lyon (voyages, billetterie, culture, loisirs, aides...),\\n- Poste ouvert aux contractuels : il est possible de recruter sur ce poste une personne qui n'est pas laur√©ate d'un concours de la fonction publique.\"}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in corpus if item[\"source\"]==\"emploi-territorial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Modeler H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'VOLT',\n",
       "  'workplace': 'Alpes-Maritimes - 06',\n",
       "  'published_date': '22/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Nous recherchons pour l'un de nos clients un Data modeler. Le poste est √† pourvoir aux alentours de Nice.Vos missions :- Soutien renforc√© sur la gestion des donn√©es- Mod√©lisation du Data Warehouse (DWH)- Collaboration au sein de l'√©quipe de data engineering- Travaux ax√©s sur Spotfire pour la Business Intelligence (BI)Votre environnement technique :- Data warehouses et la mod√©lisation dimensionnelle (en √©toile)- M√©thode sp√©cifique de mod√©lisation et de conception de syst√®mes d√©cisionnels Kimball- Avoir une bonne ma√Ætrise du langage SQL- Id√©alement, avoir des comp√©tences en Sas Designer, Python et Excel- M√©thodes Agiles notamment Kanban/Scrum Le profil recherch√© - Vous justifiez de minimum de 4 ans d'exp√©rience professionnelle en tant que Data modeler.- Vous √™tes un bon communiquant et appr√©ciez travailler en √©quipe.- Vous √™tes force de proposition et autonome.- Vous parlez couramment fran√ßaisD√©marrage : ASAPLieu du poste : Alentours de NiceContrat : CDI Bienvenue chez VOLT A la fois Cabinet de recrutement & Soci√©t√© de conseil, VOLT (Innova Solutions) a une couverture nationale. Nous sommes bas√©s √† Sophia Antipolis, au coeur de la French Riviera, nous accompagnons nos clients dans toute la France et offrons √† nos candidats des postes dans les secteurs de l'IT, des T√©l√©coms et de l'Engineering.Nos clients ont acc√®s √† plus de 85 bureaux √† travers le monde :- Aux √âtats-Unis- En Europe (Belgique et Nice)- Aux Royaume-Uni- A Singapour- En Inde En r√©sum√© : Data Modeler H/F VOLT Postuler Alpes-Maritimes - 06 CDI Bac +2 Bac +3, Bac +4 Bac +5 Secteur informatique ‚Ä¢ ESN Exp. 1 √† 7 ans Exp. + 7 ans 6 de plus 6 de moins Publi√©e le 22/12/2023 - R√©f : 1838682/10659445 DM/06A\"},\n",
       " {'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Technique H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'Utigroup',\n",
       "  'workplace': 'Dijon - 21',\n",
       "  'published_date': 'il y a 13 heures',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Vous intervenez activement sur la mont√©e en puissance du Syst√®me d'Information G√©ographique interne de notre client en Banque, votre mission constiste √† :- R√©alisez les d√©veloppements Python de nouvelles fonctionnalit√©s en utilisant les librairies adapt√©es (Folium, GeoPanda, OpenStreetMap) et proposez de nouveaux usages.- Etudiez les diff√©rentes sources open data et qualification des donn√©es.- Int√©grez de nouvelles sources de donn√©es (ETL Stambia ou script SQL) et construction d'automatisme d'int√©gration de donn√©es depuis un fichier open vers une BDD interne.- R√©alisez des POC avec les utilisateurs sur notre notebook Jupyter Lab.- Participez √† la r√©alisation de projet avec les utilisateurs m√©tiers (atelier m√©tier avec les utilisateurs, expression de besoin, √©tude de faisabilit√©, d√©veloppement et suivi projet). Le profil recherch√© - Vous √™tes titulaire d'un Bac +5.- Vous m√¢itrisez : Python, HP Vertica, Stambia, l'environnement SIG (Syst√®me d'Information G√©ographique).- Vous √™tes autonome.- Vous avez de bonnes capacit√©s d'analyse et √™tes capables de g√©rer plusieurs sujets en parall√®le.- Vous avez l'esprit d'√©quipe, des aptitudes √† communiquer et le sens du service rendu. L'entreprise Rejoindre UTIGroup, c'est rejoindre une Soci√©t√© √† taille humaine qui investit sur l'accompagnement de ses Consultants, et o√π la prise de d√©cision est rapide.Certifi√©e ISO 9001/2015, UTIGroup a eu 35 ans en 2021.Solidit√© et transparence financi√®re (notre soci√©t√© est cot√©e en Bourse depuis plus de 20 ansNotation ECO-Vadis exceptionnelle (79/100) : niveau PLATINIUM (RSE, √©thique, social et achats responsables)UTIGroup respecte les textes internationaux, europ√©ens et la l√©gislation Fran√ßaise en mati√®re de discrimination. Mais aussi... - Statut Cadre.- RTT.- Ticket restaurant.- Mutuelle.- Participation au transport.- Assurance d√©c√®s - invalidit√©. En r√©sum√© : Data Technique H/F Utigroup Super recruteur Postuler Dijon - 21 CDI 40 000 - 46 000 EUR par an Bac +5 M√©dia ‚Ä¢ Internet ‚Ä¢ Communication Distribution ‚Ä¢ Commerce de gros Secteur informatique ‚Ä¢ ESN Exp. 1 √† 7 ans Exp. + 7 ans 6 de plus 6 de moins Publi√©e le 25/12/2023 - R√©f : 617708/2022925 DT/21D\"},\n",
       " {'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Engineer - Big Data - Data Factory - Nantes H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'Sopra Steria',\n",
       "  'workplace': 'Nantes - 44',\n",
       "  'published_date': '23/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Votre environnement de travail :La division ¬´ Banque ¬ª s'est d√©velopp√©e autour des m√©tiers de la banque de d√©tail, de la banque priv√©e et des services financiers sp√©cialis√©s. Nous participons √† la r√©volution digitale gr√¢ce √† notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos comp√©tences dans les domaines fonctionnels des Cr√©dits, des Risques/Conformit√© et des Moyens de Paiement.Si vous √™tes passionn√©(e) par la valorisation de la donn√©e, rejoignez notre Data Factory localis√©e √† Nantes et les quelques 100 Data Ing√©nieurs qui la composent. Vous y rencontrerez des experts de la mise en oeuvre de Plateforme de Donn√©es, des Data Architectes ou autres experts solution autour des probl√©matiques de valorisation de la donn√©e.Vous √™tes accompagn√©(e) au d√©veloppement de vos connaissances aux travers de diff√©rents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donn√©e, la mod√©lisation et mise √† disposition. Rejoindre la Data Factory Sopra Steria, c'est rejoindre une communaut√© de Data Ing√©nieurs fiers de partager leur savoir et ouverts aux nouvelles exp√©riences et exp√©rimentations de la donn√©e.Votre r√¥le et vos missions :Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre exp√©rience et votre app√©tence pour l'un de nos chapitres Data ci-dessous, vous participez √† :- La compr√©hension des besoins m√©tiers et la traduction solution de data ing√©nierie et ou data analysis ;- La mise en oeuvre de solution d'ingestion des donn√©es quelles soit en batch et/ou en streaming dans un contexte Cloud ;- La structuration du DataLake, la mise en place des processus de gouvernance et de s√©curisation des donn√©es ;- Le traitement de la donn√©e jusqu'√† l'exposition au m√©tier ;- La mise en place de la chaine CI/CD et de sa supervision ;- La veille technologie avec nos partenaires √©diteurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'id√©ation pour nos clients.Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, R Le profil recherch√© Votre profil :Dipl√¥m√©(e) d'une Ecole d'ing√©nieur ou formation √©quivalente, vous avez d√©j√† particip√© √† un projet Data (Big Data, BI) et vous avez une exp√©rience de minimum 2 ans.Vous accordez une importance particuli√®re au d√©veloppement de vos comp√©tences sur plusieurs technologies. Vous souhaitez une √©volution r√©elle de carri√®re √† travers l'exp√©rience projet. Vous √™tes soucieux de l'apport de valeur pour vos clients. Et vous voulez transmettre votre savoir aupr√®s de collaborateurs moins exp√©riment√©s. Alors, n'attendez-plus, ce poste est fait pour vous ! Bienvenue chez Sopra Steria Sopra Steria, l'un des leaders europ√©ens de la Tech reconnu pour ses activit√©s de conseil, de services num√©riques et d'√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activit√© et des technologies innovantes √† une approche r√©solument collaborative.Sopra Steria place l'humain au centre de son action et s'engage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif. Fort de 50 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d'affaires de 5, 1 milliards d'Euros en 2022.The world is how we shape IT. Mais aussi... - Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions.- Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation.- Un accompagnement individualis√© avec un mentor.- Des opportunit√©s de carri√®res multiples : plus de 30 familles de m√©tiers, autant de passerelles √† imaginer ensemble.- Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.- La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.- L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore...).Employeur inclusif et engag√©, notre soci√©t√© oeuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements HelloWork a estim√© le salaire pour ce m√©tier √† Nantes Le recruteur n'a pas communiqu√© le salaire de cette offre mais HelloWork vous propose une estimation (fourchette variable selon l'exp√©rience). Estimation bas√©e sur les donn√©es INSEE et les offres d‚Äôemploi similaires. Estimation basse 38 000 ‚Ç¨ par an Salaire brut estim√© 42 500 ‚Ç¨ par an Estimation haute 47 500 ‚Ç¨ par an Cette information vous semble-t-elle utile ? Oui Non Merci pour votre retour ! En r√©sum√© : Data Engineer - Big Data - Data Factory - Nantes H/F Sopra Steria Postuler Nantes - 44 CDI üè† T√©l√©travail occasionnel Bac +5 Secteur informatique ‚Ä¢ ESN Exp. + 7 ans 3 de plus 3 de moins Publi√©e le 23/12/2023 - R√©f : 5abd22dc-057d-4f51-ab91-4defe9ed3bed\"},\n",
       " {'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Officer H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'SYNERGIE',\n",
       "  'workplace': \"Villeneuve-d'Ascq - 59\",\n",
       "  'published_date': '23/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Vos missionsEn tant que Data Officer, vous √™tes l'un(e) des gardien(ne)s des donn√©es.Au sein du Data Office de la Direction de la Donn√©e de Synergie, vous rejoindrez une √©quipe de 5 personnes en charge de la gouvernance des donn√©es et des projets Data en lien avec les entit√©s de Cofidis Group, la Data Factory (fili√®re Data au sein d'Euro-Information) et le Cr√©dit Mutuel Alliance F√©d√©rale.Vous √™tes un(e) acteur(trice) important(e) dans le d√©veloppement de la culture des donn√©es.- Concernant la gouvernance et les outils, vous contribuez √† l'√©laboration et la diffusion des politiques de gouvernance des donn√©es au sein du groupe, en collaboration √©troite avec le DPO. Vous assurez la coh√©rence avec la strat√©gie data, notamment sur l'exploitation responsable des donn√©es et la mutualisation de la pr√©paration des donn√©es. Vous √™tes force de proposition sur la d√©marche de data management (documentation du data catalogue & dictionnaire m√©tier, supervision de la qualit√© des donn√©es).Pour nourrir les r√©flexions prospectives, vous √™tes en veille sur les nouveaux outils du march√© et vous portez les besoins d'√©volution des outils de data management et de business intelligence au regard des enjeux m√©tier.Vous animez et contr√¥lez les entit√©s sur le respect des principes de gouvernance des donn√©es (connaissance du patrimoine de donn√©es, s√©curit√©, usage √©conome et responsable...).- En tant que chef de projet, vous pilotez des projets pour les filiales de Cofidis Group. Ces projets peuvent concerner notamment la collecte de nouvelles sources de donn√©es, la mise en place d'outils de gouvernance des donn√©es, l'accompagnement sur des migrations...Vous coordonnez les diff√©rents acteurs et les actions du projet, du cadrage √† la mise en production.Ce que vous allez vivre chez nousEn plus de votre r√¥le de Data Officer, vous pourrez participer √† des projets m√©tier, collaboratifs ou caritatifs qui mettront votre engagement au service de notre projet d'entreprise. Certifi√© ¬´ Great Place to Work ¬ª en 2022, en rejoignant Synergie, vous int√©grerez un environnement o√π il fait bon travailler, et b√©n√©ficierez des avantages suivants :- R√©mun√©ration fixe sur 13 mois- Int√©ressement, participation et abondement- Plan d'Epargne Groupe et PERECOL- Mutuelle et pr√©voyance- T√©l√©travail jusqu'√† 2 jours par semaine- Ch√®ques restaurant et restaurant d'entreprise- CESU et ch√®ques vacances- Parking assur√© et gratuit- CSE dynamiqueEt si vous souhaitez poursuivre votre carri√®re chez nous, et √©voluer vers un autre m√©tier, ou sur l'une des autres marques de Cofidis Group, c'est √©galement possible.Ce que nous allons aimer chez vous- Vous √™tes dipl√¥m√©(e) d'une √©cole d'ing√©nieur ou √©quivalent universitaire ou un autodidacte reconnu par ses pairs.- Vous justifiez de 3 ans ou plus d'exercice de missions dans la Data, en collaboration avec des experts Data Analyst ou Data Scientists.- Vous avez l'exp√©rience du management de projets.- Vous ma√Ætrisez l'Anglais (compr√©hension √©crite et orale niveau B2).- Vous √™tes autonome, force de proposition et vous avez un grand sens de l'organisation et une capacit√© √† traiter plusieurs sujets en m√™me temps avec pers√©v√©rance et dynamisme.- Vous fa√Ætes preuve de curiosit√© et vous appr√©ciez contribuer √† l'acculturation et l'accompagnement au changement.- Vos qualit√©s de communication orale et √©crite vous permettent de diffuser un message clair, synth√©tique et p√©dagogique.- Vous fa√Ætes preuve d'un bon leadership et vous collaborez activement avec les autres membres du service et vos clients internes, en favorisant l'esprit d'√©quipe et le partage.CE QUI SERAIT UN VRAI PLUS !- Vous avez des comp√©tences avanc√©es en statistique ou informatique d√©cisionnelle (id√©alement dans le domaine bancaire ou assurance)40- Les langages de programmation tels que SQL, SAS, Python ne vous sont pas inconnus et vous avez une connaissance des principes d'architecture (SI d√©cisionnel).Autres informationsPour postuler, merci de joindre votre CVManager recruteur : Anne-Laure TARTAR Bienvenue chez SYNERGIE Qui sommes nousCofidis Group cr√©e, vend et g√®re une large gamme de services financiers pour les particuliers et les commer√ßants partenaires. Implant√© dans 9 pays, pionnier du cr√©dit √† distance, Cofidis Group est depuis 40 ans l'un des principaux acteurs du cr√©dit √† la consommation en Europe (pr√™ts personnels et cr√©dits √† la consommation, solutions de paiement, services bancaires, assurance, rachat de cr√©ances et partenariats). En France, Cofidis Group regroupe 3 enseignes commerciales, sp√©cialistes dans la vente de produits et services financiers, et son GEIE Synergie : - Cofidis, sp√©cialiste europ√©en du cr√©dit en ligne - Monabanq, la banque en ligne nouvelle g√©n√©ration - Creatis, sp√©cialiste du regroupement de cr√©dits √† la consommation - Le GEIE Synergie qui apporte aux enseignes son expertise dans les domaines de la gestion du risque, du recouvrement /contentieux, des ressources humaines et de la communication, du juridique, du risk management, des fonctions financi√®res/ comptables et organisationnelles.Pourquoi nous recrutonsChez Cofidis Group, nous avons entam√© une transformation, sur notre organisation et notre business, afin de devenir un acteur complet et leader de l'exp√©rience client, partenaire et collaborateur. Synergie, √† travers ses m√©tiers d'expertise, se positionne en tant qu'acc√©l√©rateur de la transformation du groupe. Nous avons pour mission de stimuler la collaboration entre nos 3 entit√©s commerciales et nos filiales √† l'international, de fixer le cadre et de nous assurer de son respect et d'impulser et stimuler l'innovation. En parall√®le, nous continuons √† r√©aliser et d√©velopper des activit√©s op√©rationnelles pour le compte de nos entit√©s partenaires, nous accompagnons, challengeons les filiales et veillons √† la mise en oeuvre des actions. C'est ensemble que nous voulons cr√©er l'entreprise de demain et c'est pour cela que nous avons besoin de vous. En r√©sum√© : Data Officer H/F SYNERGIE Villeneuve-d'Ascq - 59 CDI 40 000 - 50 000 EUR par an üè† T√©l√©travail partiel Bac +5 Banque ‚Ä¢ Assurance ‚Ä¢ Finance 2 de plus 2 de moins Publi√©e le 23/12/2023 - R√©f : 80466_70\"},\n",
       " {'source': 'hellowork',\n",
       "  'link': 'https://www.hellowork.com',\n",
       "  'position': 'Data Officer H/F',\n",
       "  'position_type': 'NULL',\n",
       "  'company': 'ENGIE',\n",
       "  'workplace': 'Courbevoie - 92',\n",
       "  'published_date': '22/12/2023',\n",
       "  'contract_type': 'CDI',\n",
       "  'description': \"Les missions du poste Rejoins ENGIE IT et fais vivre l'IT au coeur de la transition √©nerg√©tique en tant que :Data Officer (H/F)Poste bas√© √† La D√©fense (92)Description du posteNous recherchons un data Officer pour accompagner les directions du Corporate sur des sujets innovants autour de l'Analytics, de la Datascience, de la data en g√©n√©ral avec les qualifications ci-dessous.Interlocuteur Data privil√©gi√© du Corporate vous pourrez accompagner les directions du Corporate sur l'id√©ation et la r√©alisation de use case Data.Qualifications- Formation Bac +5 (√©cole d'ing√©nieur ou master) dans un domaine relatif √† la Data & √† l'Analytics- Au moins 3 ans d'exp√©rience en Analytics- Exp√©rience sur un ou plusieurs cloud provider (AWS fortement appr√©ci√©, Azure, GCP)- Bonnes connaissances sur les architectures de donn√©es.- Exp√©riences en Data Management- Exp√©riences en Power BI- Ma√Ætrise de l'anglais √† l'√©crit comme √† l'oral- Nice to have :- A d√©j√† travaill√© sur des projets en mode agile- Exp√©riences avec Datiku- Connaissance de Databricks- Connaissance de Palantir- Connaissance de CollibraComp√©tences comportementales- Aisance relationnelle- Rigueur et organisation- Savoir prendre des initiatives- Sens du r√©sultat et de l'engagement- Pro activit√©- Esprit de Synth√®se- Force de conviction- Pragmatisme- Curiosit√© et volont√© d'apprendre Bienvenue chez ENGIE ENGIE IT apporte les meilleures solutions IT √† l'ensemble des BU du Groupe ENGIE et les aide √† relever tous les d√©fis √©nerg√©tiques d'aujourd'hui et de demain.Avec nous, tu pourras avoir √† la fois l'agilit√© et la bienveillance d'une PME et la solidit√© et l'envergure d'un grand groupe, l'expertise et l'engagement, l'audace et l'excellence. En r√©sum√© : Data Officer H/F ENGIE Courbevoie - 92 CDI Bac +5 Secteur Energie ‚Ä¢ Environnement 2 de plus 2 de moins Publi√©e le 22/12/2023 - R√©f : 10497\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, Date, ForeignKey,text,String\n",
    "from sqlalchemy.orm import declarative_base, Session, relationship\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "# Modele de bdd\n",
    "class HPositionType(Base):\n",
    "    __tablename__ = 'h_position_type'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    position_type = Column(String)\n",
    "    d_positions = relationship('DPosition', back_populates='h_position_type')\n",
    "\n",
    "class DPosition(Base):\n",
    "    __tablename__ = 'd_position'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    position = Column(String)\n",
    "    position_type_id = Column(Integer, ForeignKey('h_position_type.id'))\n",
    "    h_position_type = relationship('HPositionType', back_populates='d_positions')\n",
    "\n",
    "class DWebsite(Base):\n",
    "    __tablename__ = 'd_website'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    label = Column(String)\n",
    "    link = Column(String)\n",
    "\n",
    "class DCompany(Base):\n",
    "    __tablename__ = 'd_company'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    label = Column(String)\n",
    "\n",
    "class DCity(Base):\n",
    "    __tablename__ = 'd_city'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    city = Column(String)\n",
    "\n",
    "class DContractType(Base):\n",
    "    __tablename__ = 'd_contract_type'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    contract_type = Column(String)\n",
    "\n",
    "class DCalendar(Base):\n",
    "    __tablename__ = 'd_calendar'\n",
    "    date = Column(Date, primary_key=True)\n",
    "    day = Column(Integer)\n",
    "    month = Column(Integer)\n",
    "    year = Column(Integer)\n",
    "\n",
    "\n",
    "class FJobAdvertisements(Base):\n",
    "    __tablename__ = 'f_job_advertisements'\n",
    "    nb_occurences = Column(Integer)\n",
    "    contract_type_id = Column(Integer, ForeignKey('d_contract_type.id'),primary_key=True)\n",
    "    position_id = Column(Integer, ForeignKey('d_position.id'),primary_key=True)\n",
    "    website_id = Column(Integer, ForeignKey('d_website.id'),primary_key=True)\n",
    "    city_id = Column(Integer, ForeignKey('d_city.id'),primary_key=True)\n",
    "    company_id = Column(Integer, ForeignKey('d_company.id'),primary_key=True)\n",
    "    published_date = Column(Date, ForeignKey('d_calendar.date'),primary_key=True)\n",
    "\n",
    "    position = relationship('DPosition', back_populates='job_advertisements')\n",
    "    website = relationship('DWebsite', back_populates='job_advertisements')\n",
    "    company = relationship('DCompany', back_populates='job_advertisements')\n",
    "    city = relationship('DCity', back_populates='job_advertisements')\n",
    "    contract_type = relationship('DContractType', back_populates='job_advertisements')\n",
    "\n",
    "# D√©finition des relations\n",
    "DPosition.job_advertisements = relationship('FJobAdvertisements', back_populates='position')\n",
    "DWebsite.job_advertisements = relationship('FJobAdvertisements', back_populates='website')\n",
    "DCompany.job_advertisements = relationship('FJobAdvertisements', back_populates='company')\n",
    "DCity.job_advertisements = relationship('FJobAdvertisements', back_populates='city')\n",
    "DContractType.job_advertisements = relationship('FJobAdvertisements', back_populates='contract_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "#Seulement √† executer une fois (contrainte avec la table de fait)\n",
    "def insertCalendar(yearsRange):\n",
    "    engine = create_engine('mysql+mysqlconnector://root:@localhost/job_scrapping')\n",
    "    Base.metadata.create_all(engine)\n",
    "    session = Session(bind=engine)\n",
    "    session.commit()\n",
    "    for year in yearsRange:\n",
    "        for month in range(1, 13):\n",
    "            num_days_in_month = (datetime(year, month % 12 + 1, 1) - timedelta(days=1)).day\n",
    "            for day in range(1, num_days_in_month + 1):\n",
    "                date_details = datetime(year, month, day)\n",
    "                date = DCalendar(date=date_details.strftime('%Y-%m-%d'),day=date_details.day,month=date_details.month,year=date_details.year)\n",
    "                session.add(date)\n",
    "                session.commit()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertCalendar(range(2015,2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alimentation du DW\n",
    "def fillDW(corpus):\n",
    "    engine = create_engine('mysql+mysqlconnector://root:@localhost/job_scrapping')\n",
    "    Base.metadata.create_all(engine)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    duplicates = False\n",
    "    #Vidage du DW\n",
    "    session = Session()\n",
    "    session.execute(text(\"CALL pTruncateDW()\"))\n",
    "    session.commit()\n",
    "    i=0\n",
    "    #It√©ration sur les √©l√©ments du corpus r√©cup√©r√©s\n",
    "    for item in corpus:\n",
    "        corpus_position = item[\"position\"]\n",
    "        corpus_website = item[\"source\"]\n",
    "        print(corpus_position,corpus_website)\n",
    "        corpus_link = item[\"link\"]\n",
    "        corpus_company = item[\"company\"]\n",
    "        corpus_city = item[\"workplace\"]\n",
    "        corpus_contract_type = item[\"contract_type\"]\n",
    "        corpus_position_type = item['position_type']\n",
    "        corpus_published_date = item['published_date']\n",
    "        try:\n",
    "                date_object = datetime.strptime(corpus_published_date, '%d/%m/%Y')\n",
    "                # If successful, use the formatted date\n",
    "                corpus_published_date = date_object.strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            corpus_published_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        # print(corpus_position)\n",
    "        # print(corpus_position_type)\n",
    "        \n",
    "        position_type = HPositionType(position_type=corpus_position_type)\n",
    "        position = DPosition(position=corpus_position)\n",
    "        website = DWebsite(label=corpus_website,link=corpus_link)\n",
    "        company = DCompany(label=corpus_company)\n",
    "        city = DCity(city=corpus_city)\n",
    "        contract_type = DContractType(contract_type=corpus_contract_type)\n",
    "        session = Session()\n",
    "\n",
    "        # Recherche des √©lements de chaque dimensions pour √©viter les doublons\n",
    "        existing_position_type = session.query(HPositionType).filter_by(position_type=corpus_position_type).first()\n",
    "        existing_position = session.query(DPosition).filter_by(position=corpus_position).first()\n",
    "        existing_website = session.query(DWebsite).filter_by(label=corpus_website).first()\n",
    "        existing_company = session.query(DCompany).filter_by(label=corpus_company).first()\n",
    "        existing_city = session.query(DCity).filter_by(city=corpus_city).first()\n",
    "        existing_contract_type = session.query(DContractType).filter_by(contract_type=corpus_contract_type).first()\n",
    "\n",
    "        #Si elle existe je r√©cup√®re la ligne existante, sinon j'insert la nouvelle ligne\n",
    "        if existing_position_type:\n",
    "            position_type = existing_position_type\n",
    "        else:\n",
    "            session.add(position_type)\n",
    "            session.commit()\n",
    "        if existing_position:\n",
    "            position = existing_position\n",
    "        else:\n",
    "            position.position_type_id = position_type.id\n",
    "            session.add(position)\n",
    "\n",
    "        if existing_website:\n",
    "            website = existing_website\n",
    "        else:\n",
    "            session.add(website)\n",
    "\n",
    "        if existing_company:\n",
    "            company = existing_company\n",
    "        else:\n",
    "            session.add(company)\n",
    "\n",
    "        if existing_city:\n",
    "            city = existing_city\n",
    "        else:\n",
    "            session.add(city)\n",
    "\n",
    "        if existing_contract_type:\n",
    "            contract_type = existing_contract_type\n",
    "        else:\n",
    "            session.add(contract_type)\n",
    "        session.commit()\n",
    "        \n",
    "        # J'insert les donn√©es dans la table de fait (id des dimensions + KPI)\n",
    "        job_advertisement = FJobAdvertisements(\n",
    "            nb_occurences=random.randint(3,10),\n",
    "            position=position,\n",
    "            website=website,\n",
    "            company=company,\n",
    "            city=city,\n",
    "            contract_type=contract_type,\n",
    "            published_date = corpus_published_date\n",
    "        )\n",
    "\n",
    "        session.add(job_advertisement)\n",
    "        try:\n",
    "            session.add(job_advertisement)\n",
    "            session.commit()\n",
    "            i = i + 1\n",
    "        except IntegrityError as e:\n",
    "            duplicates = True\n",
    "            session.rollback()\n",
    "        session.commit()\n",
    "    session.close()\n",
    "    if duplicates:\n",
    "        print(f\"Some exact duplicates have been detected in the job scrapping process, less documents have been saved then asked : {i} documents saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chef de projet Data (H/F) welcometothejungle\n",
      "Data Project Coordinator / Charg√©(e) de donn√©es PIM DAM (F/H) welcometothejungle\n",
      "Data Analytics Engineer H/F/X welcometothejungle\n",
      "Manageur (euse) Data et Analytics welcometothejungle\n",
      "Data Center Security Manager, DC Security welcometothejungle\n",
      "Senior Data Scientist welcometothejungle\n",
      "Consultant.e Data Marketing Confirm√©.e welcometothejungle\n",
      "Data Analyst confirm√© - (F/H) welcometothejungle\n",
      "Scrum Master Data F/H welcometothejungle\n",
      "Data Privacy Analyst F/H welcometothejungle\n",
      "DATA ANALYST EXPERT POWER BI welcometothejungle\n",
      "Data Engineer - Expert Big Data H/F welcometothejungle\n",
      "Auditeur exp√©riment√© Outils, Data & M√©thodologie F/H welcometothejungle\n",
      "Ing√©nieur Big Data - Banque - Bordeaux welcometothejungle\n",
      "Consultant junior Data x Business Consulting H/F - Stage de fin d'√©tudes welcometothejungle\n",
      "Data Analyst (Stage de fin d'√©tude) welcometothejungle\n",
      "Product Owner Data Marketing H/F/X welcometothejungle\n",
      "Data engineer F/H welcometothejungle\n",
      "Ing√©nieur / Ing√©nieure Oc√©ano-m√©t√©o / Data science welcometothejungle\n",
      "Data Engineer Intern welcometothejungle\n",
      "Data Science Intern welcometothejungle\n",
      "Data Scientist Finance, Risque et Performance (H/F) ‚Äì CDI ‚Äì Paris welcometothejungle\n",
      "STAGE - Ing√©nieur - Data Scientist - F/H welcometothejungle\n",
      "Senior Data Scientist welcometothejungle\n",
      "Data scientist chez OrdoSafe start-up incub√©e chez Matrice welcometothejungle\n",
      "ARCHITECTE DATA - H/F welcometothejungle\n",
      "Business unit manager- SaaS/Digital/Data welcometothejungle\n",
      "Stage - Data analyst risques op√©rationnels F/H welcometothejungle\n",
      "DATA Analyst H/F welcometothejungle\n",
      "Team Lead Data Science (F/M) welcometothejungle\n",
      "Data Analyst Supply Chain F/H welcometothejungle\n",
      "Senior Data Engineer welcometothejungle\n",
      "Intern Data Analyst welcometothejungle\n"
     ]
    }
   ],
   "source": [
    "fillDW(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"welcometothejungle\"\n",
    "rootLink = \"https://www.welcometothejungle.com\"\n",
    "service = ChromeService(\"C:/Users/leogo/Documents/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service) \n",
    "keyword=\"data\"\n",
    "pages=2\n",
    "nb_docs=33\n",
    "corpus = list()\n",
    "try:\n",
    "    for page in range(1,pages+1):    \n",
    "        try:\n",
    "            driver.get(f'{rootLink}/fr/jobs?query=data&aroundQuery=France&page={page}')\n",
    "            # Initial find of elements\n",
    "            try:\n",
    "                accept_cookies_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#axeptio_btn_acceptAll'))\n",
    "                )\n",
    "\n",
    "                accept_cookies_button.click()\n",
    "            except TimeoutException:\n",
    "                pass\n",
    "                \n",
    "            offers = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"ol[data-testid='search-results']\"))\n",
    "            )\n",
    "            \n",
    "            # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            # Getting docs left if last page to query\n",
    "            if nb_docs%30 != 0 and page==pages: \n",
    "                limit = nb_docs%30\n",
    "                div_elements_to_click_list = offers.find_elements(By.CSS_SELECTOR, \"li\")[:limit]\n",
    "            else :\n",
    "                div_elements_to_click_list = offers.find_elements(By.CSS_SELECTOR, \"li\")\n",
    "\n",
    "            for index in range(len(div_elements_to_click_list)):\n",
    "                try:\n",
    "                    offers = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"ol[data-testid='search-results']\"))\n",
    "                    )\n",
    "                    \n",
    "                    div_elements_to_click_list = offers.find_elements(By.CSS_SELECTOR, \"li\")\n",
    "                    div_elements_to_click = div_elements_to_click_list[index]\n",
    "                    # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    # driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "                    # Check if the index is within the valid range\n",
    "                    div_offer = div_elements_to_click.find_element(By.CSS_SELECTOR,\"div\")\n",
    "\n",
    "                    position_elem = div_offer.find_element(By.CSS_SELECTOR,\"h4\")\n",
    "                    position = position_elem.text\n",
    "                    workplace = position_elem.find_elements(By.XPATH, \"./following::*//span\")[1].text\n",
    "                    contract_type_icon = div_offer.find_element(By.CSS_SELECTOR,\"i[name='contract']\")\n",
    "                    main_contract_div = driver.execute_script(\"return arguments[0].parentNode;\", contract_type_icon)\n",
    "                    contract_type = main_contract_div.find_element(By.CSS_SELECTOR,\"span\").text\n",
    "                    published_date = div_offer.find_element(By.CSS_SELECTOR,\"time\").get_attribute(\"datetime\").split(\"T\")[0]\n",
    "                    published_date = datetime.strptime(published_date, '%Y-%m-%d')\n",
    "                    published_date = published_date.strftime('%d/%m/%Y')\n",
    "                    # driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_elements_to_click)\n",
    "                    # company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "                    # contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "                    # workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "                    # published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "                    # Scroll into view\n",
    "                    # actions = ActionChains(driver)\n",
    "                    # actions.move_to_element(div_elements_to_click).click().perform()\n",
    "                    #On remote de deux niveau du bouton \"Voir offre\" pour pouvoir r√©cup√©rer les informations appropri√©es\n",
    "                    # div_offer = driver.execute_script(\"return arguments[0].parentNode.parentNode;\", div_elements_to_click)\n",
    "                    # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "                    # company = company_elem.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "                    # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "                    # contract_type = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='contract']\").text\n",
    "                    # workplace = div_offer.find_elements(By.CSS_SELECTOR, \"div[data-cy='loc']\")[-1].text\n",
    "                    # published_date = div_offer.find_elements(By.CSS_SELECTOR, \"span[data-cy='publishDate']\")[-1].text\n",
    "\n",
    "                    driver.execute_script(\"arguments[0].click();\", div_offer)\n",
    "                    WebDriverWait(driver, 20).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-testid='job-section-description']\"))\n",
    "                    )\n",
    "                    description_elem = driver.find_element(By.CSS_SELECTOR,\"div[data-testid='job-section-description']\")\n",
    "\n",
    "                    # driver.execute_script(\"arguments[0].click();\",description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "                    \n",
    "                    WebDriverWait(driver, 3)\n",
    "\n",
    "                    try:\n",
    "                        profile_elem = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='job-section-experience']\")\n",
    "                        profile_html = profile_elem.find_elements(By.CSS_SELECTOR, \"div\")[-2].get_attribute(\"innerHTML\")\n",
    "                        profile = BeautifulSoup(profile_html, 'html.parser').get_text()\n",
    "                    except NoSuchElementException:\n",
    "                        # If profile element is not found, set it to \"NULL\"\n",
    "                        profile = \"NULL\"\n",
    "                    # driver.execute_script(\"arguments[0].click();\",profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "\n",
    "                    description = description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "                    # profile = profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "                    \n",
    "                    #parsing tags\n",
    "                    description = BeautifulSoup(description, 'html.parser').get_text()\n",
    "                    company_elem = driver.find_element(By.CSS_SELECTOR,\"a[href*='/fr/companies/']\")\n",
    "                    company = company_elem.find_element(By.CSS_SELECTOR,\"img\").get_attribute(\"alt\")\n",
    "                    long_infos = \" \".join([description,profile])\n",
    "                    # print(long_infos)\n",
    "                    # Wait for the child element to become present in the DOM\n",
    "\n",
    "                    # # Get the page source after the click\n",
    "                    # page_source = driver.page_source\n",
    "\n",
    "                    # Use Beautiful Soup to parse the page source\n",
    "                    # soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                    # Example: Retrieve the text of a specific element\n",
    "                    # desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "                    # descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "                    # profile = soup.select(\"h4:contains('Profil recherch√©') + p\")\n",
    "                    # profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "                    # position = soup.select_one(\"span[data-cy='jobTitle']\").text\n",
    "                    # position_type = soup.select_one('h4:contains(\"Secteur d‚Äôactivit√© du poste\")+span').text\n",
    "                    # long_infos = soup.select(\"section\")\n",
    "                    # infos = [item.text.replace(\"\\n\",\" \").strip() for item in long_infos]\n",
    "                    # infos = [re.sub(r'\\s+', ' ',item) for item in infos]\n",
    "                    # infos = \" \".join([item for item in infos if item != ''])\n",
    "                    # infos = [item for item in infos if '' not in item]\n",
    "                    corpus.append({\"source\":source,\"link\":rootLink,\"position\":position,\"position_type\":\"NULL\",\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":long_infos})\n",
    "                except Exception as e:\n",
    "                    # Print the exception for debugging purposes\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "                finally:\n",
    "                    # Navigate back to the main page\n",
    "                    driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Print the exception for debugging purposes\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Int√©rim\n",
      "Error: name 'description_elem' is not defined\n",
      "Error: Message: stale element reference: stale element not found\n",
      "  (Session info: chrome=120.0.6099.130)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF75A2882B2+55298]\n",
      "\t(No symbol) [0x00007FF75A1F5E02]\n",
      "\t(No symbol) [0x00007FF75A0B05AB]\n",
      "\t(No symbol) [0x00007FF75A0BE59A]\n",
      "\t(No symbol) [0x00007FF75A0B59E9]\n",
      "\t(No symbol) [0x00007FF75A0B5AF3]\n",
      "\t(No symbol) [0x00007FF75A0B4298]\n",
      "\t(No symbol) [0x00007FF75A0B732A]\n",
      "\t(No symbol) [0x00007FF75A12B12B]\n",
      "\t(No symbol) [0x00007FF75A1120AA]\n",
      "\t(No symbol) [0x00007FF75A12AAA4]\n",
      "\t(No symbol) [0x00007FF75A111E83]\n",
      "\t(No symbol) [0x00007FF75A0E670A]\n",
      "\t(No symbol) [0x00007FF75A0E7964]\n",
      "\tGetHandleVerifier [0x00007FF75A600AAB+3694587]\n",
      "\tGetHandleVerifier [0x00007FF75A65728E+4048862]\n",
      "\tGetHandleVerifier [0x00007FF75A64F173+4015811]\n",
      "\tGetHandleVerifier [0x00007FF75A3247D6+695590]\n",
      "\t(No symbol) [0x00007FF75A200CE8]\n",
      "\t(No symbol) [0x00007FF75A1FCF34]\n",
      "\t(No symbol) [0x00007FF75A1FD062]\n",
      "\t(No symbol) [0x00007FF75A1ED3A3]\n",
      "\tBaseThreadInitThunk [0x00007FF90948257D+29]\n",
      "\tRtlUserThreadStart [0x00007FF90A8CAA58+40]\n",
      "\n",
      "Error: Message: stale element reference: stale element not found\n",
      "  (Session info: chrome=120.0.6099.130)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF75A2882B2+55298]\n",
      "\t(No symbol) [0x00007FF75A1F5E02]\n",
      "\t(No symbol) [0x00007FF75A0B05AB]\n",
      "\t(No symbol) [0x00007FF75A0BE59A]\n",
      "\t(No symbol) [0x00007FF75A0B59E9]\n",
      "\t(No symbol) [0x00007FF75A0B5AF3]\n",
      "\t(No symbol) [0x00007FF75A0B4298]\n",
      "\t(No symbol) [0x00007FF75A0B732A]\n",
      "\t(No symbol) [0x00007FF75A12B12B]\n",
      "\t(No symbol) [0x00007FF75A1120AA]\n",
      "\t(No symbol) [0x00007FF75A12AAA4]\n",
      "\t(No symbol) [0x00007FF75A111E83]\n",
      "\t(No symbol) [0x00007FF75A0E670A]\n",
      "\t(No symbol) [0x00007FF75A0E7964]\n",
      "\tGetHandleVerifier [0x00007FF75A600AAB+3694587]\n",
      "\tGetHandleVerifier [0x00007FF75A65728E+4048862]\n",
      "\tGetHandleVerifier [0x00007FF75A64F173+4015811]\n",
      "\tGetHandleVerifier [0x00007FF75A3247D6+695590]\n",
      "\t(No symbol) [0x00007FF75A200CE8]\n",
      "\t(No symbol) [0x00007FF75A1FCF34]\n",
      "\t(No symbol) [0x00007FF75A1FD062]\n",
      "\t(No symbol) [0x00007FF75A1ED3A3]\n",
      "\tBaseThreadInitThunk [0x00007FF90948257D+29]\n",
      "\tRtlUserThreadStart [0x00007FF90A8CAA58+40]\n",
      "\n",
      "Error: Message: stale element reference: stale element not found\n",
      "  (Session info: chrome=120.0.6099.130)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF75A2882B2+55298]\n",
      "\t(No symbol) [0x00007FF75A1F5E02]\n",
      "\t(No symbol) [0x00007FF75A0B05AB]\n",
      "\t(No symbol) [0x00007FF75A0BE59A]\n",
      "\t(No symbol) [0x00007FF75A0B59E9]\n",
      "\t(No symbol) [0x00007FF75A0B5AF3]\n",
      "\t(No symbol) [0x00007FF75A0B4298]\n",
      "\t(No symbol) [0x00007FF75A0B732A]\n",
      "\t(No symbol) [0x00007FF75A12B12B]\n",
      "\t(No symbol) [0x00007FF75A1120AA]\n",
      "\t(No symbol) [0x00007FF75A12AAA4]\n",
      "\t(No symbol) [0x00007FF75A111E83]\n",
      "\t(No symbol) [0x00007FF75A0E670A]\n",
      "\t(No symbol) [0x00007FF75A0E7964]\n",
      "\tGetHandleVerifier [0x00007FF75A600AAB+3694587]\n",
      "\tGetHandleVerifier [0x00007FF75A65728E+4048862]\n",
      "\tGetHandleVerifier [0x00007FF75A64F173+4015811]\n",
      "\tGetHandleVerifier [0x00007FF75A3247D6+695590]\n",
      "\t(No symbol) [0x00007FF75A200CE8]\n",
      "\t(No symbol) [0x00007FF75A1FCF34]\n",
      "\t(No symbol) [0x00007FF75A1FD062]\n",
      "\t(No symbol) [0x00007FF75A1ED3A3]\n",
      "\tBaseThreadInitThunk [0x00007FF90948257D+29]\n",
      "\tRtlUserThreadStart [0x00007FF90A8CAA58+40]\n",
      "\n",
      "Error: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF75A2882B2+55298]\n",
      "\t(No symbol) [0x00007FF75A1F5E02]\n",
      "\t(No symbol) [0x00007FF75A0B05AB]\n",
      "\t(No symbol) [0x00007FF75A0F175C]\n",
      "\t(No symbol) [0x00007FF75A0F18DC]\n",
      "\t(No symbol) [0x00007FF75A12CBC7]\n",
      "\t(No symbol) [0x00007FF75A1120EF]\n",
      "\t(No symbol) [0x00007FF75A12AAA4]\n",
      "\t(No symbol) [0x00007FF75A111E83]\n",
      "\t(No symbol) [0x00007FF75A0E670A]\n",
      "\t(No symbol) [0x00007FF75A0E7964]\n",
      "\tGetHandleVerifier [0x00007FF75A600AAB+3694587]\n",
      "\tGetHandleVerifier [0x00007FF75A65728E+4048862]\n",
      "\tGetHandleVerifier [0x00007FF75A64F173+4015811]\n",
      "\tGetHandleVerifier [0x00007FF75A3247D6+695590]\n",
      "\t(No symbol) [0x00007FF75A200CE8]\n",
      "\t(No symbol) [0x00007FF75A1FCF34]\n",
      "\t(No symbol) [0x00007FF75A1FD062]\n",
      "\t(No symbol) [0x00007FF75A1ED3A3]\n",
      "\tBaseThreadInitThunk [0x00007FF90948257D+29]\n",
      "\tRtlUserThreadStart [0x00007FF90A8CAA58+40]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(div_elements_to_click_list)):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m         \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma[id=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhypViewJob\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m         div_elements_to_click_list \u001b[38;5;241m=\u001b[39m offers\n\u001b[0;32m     37\u001b[0m         div_elements_to_click \u001b[38;5;241m=\u001b[39m div_elements_to_click_list[index]\n",
      "File \u001b[1;32mc:\\Users\\leogo\\miniconda3\\envs\\text-mining\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:86\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     84\u001b[0m     screen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(exc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     85\u001b[0m     stacktrace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(exc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstacktrace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 86\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Probl√®me toutes les entreprises sont Adecco, si autre, redirection sur un autre site\n",
    "# source = \"adecco\"\n",
    "# rootLink = \"https://www.adecco.fr\"\n",
    "# service = ChromeService(\"C:/Users/leogo/Documents/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "# driver = webdriver.Chrome(service=service) \n",
    "# keyword=\"data\"\n",
    "# pages=1\n",
    "# nb_docs=33\n",
    "# corpus = list()\n",
    "# try:\n",
    "#     for page in range(1,pages+1):    \n",
    "#         try:\n",
    "#             print(page)\n",
    "#             driver.get(f'{rootLink}/resultats-offres-emploi/m-{keyword}?pageNum={page}')\n",
    "#             # Initial find of elements\n",
    "                \n",
    "#             WebDriverWait(driver, 10).until(\n",
    "#                 EC.presence_of_element_located((By.CSS_SELECTOR, \"a[id='hypViewJob']\"))\n",
    "#             )\n",
    "\n",
    "#             offers = driver.find_elements(By.CSS_SELECTOR, \"a[id='hypViewJob']\")\n",
    "\n",
    "#             # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#             # Getting docs left if last page to query\n",
    "#             if nb_docs%50!= 0 and page==pages: \n",
    "#                 limit = nb_docs%50\n",
    "#                 div_elements_to_click_list = offers[:limit]\n",
    "#             else :\n",
    "#                 div_elements_to_click_list = offers\n",
    "#             # print(len(div_elements_to_click_list))\n",
    "#             for index in range(len(div_elements_to_click_list)):\n",
    "#                 try:\n",
    "#                     WebDriverWait(driver, 10).until(\n",
    "#                         EC.presence_of_element_located((By.CSS_SELECTOR, \"a[id='hypViewJob']\"))\n",
    "#                     )\n",
    "                    \n",
    "#                     div_elements_to_click_list = offers\n",
    "#                     div_elements_to_click = div_elements_to_click_list[index]\n",
    "#                     # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#                     # driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "#                     # Check if the index is within the valid range\n",
    "#                     # div_offer = div_elements_to_click.find_element(By.CSS_SELECTOR,\"div\")\n",
    "\n",
    "#                     # position_elem = div_offer.find_element(By.CSS_SELECTOR,\"h4\")\n",
    "#                     # position = position_elem.text\n",
    "#                     # workplace = position_elem.find_elements(By.XPATH, \"./following::*//span\")[1].text\n",
    "#                     # contract_type_icon = div_offer.find_element(By.CSS_SELECTOR,\"i[name='contract']\")\n",
    "#                     # main_contract_div = driver.execute_script(\"return arguments[0].parentNode;\", contract_type_icon)\n",
    "#                     # contract_type = main_contract_div.find_element(By.CSS_SELECTOR,\"span\").text\n",
    "#                     # published_date = div_offer.find_element(By.CSS_SELECTOR,\"time\").get_attribute(\"datetime\").split(\"T\")[0]\n",
    "#                     # published_date = datetime.strptime(published_date, '%Y-%m-%d')\n",
    "#                     # published_date = published_date.strftime('%d/%m/%Y')\n",
    "#                     # driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_elements_to_click)\n",
    "#                     # company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "#                     # contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "#                     # workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "#                     # published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "#                     # Scroll into view\n",
    "#                     # actions = ActionChains(driver)\n",
    "#                     # actions.move_to_element(div_elements_to_click).click().perform()\n",
    "#                     #On remote de deux niveau du bouton \"Voir offre\" pour pouvoir r√©cup√©rer les informations appropri√©es\n",
    "#                     # div_offer = driver.execute_script(\"return arguments[0].parentNode.parentNode;\", div_elements_to_click)\n",
    "#                     # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "#                     # company = company_elem.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "#                     # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "#                     # contract_type = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='contract']\").text\n",
    "#                     # workplace = div_offer.find_elements(By.CSS_SELECTOR, \"div[data-cy='loc']\")[-1].text\n",
    "#                     # published_date = div_offer.find_elements(By.CSS_SELECTOR, \"span[data-cy='publishDate']\")[-1].text\n",
    "\n",
    "#                     driver.execute_script(\"arguments[0].click();\", div_elements_to_click)\n",
    "\n",
    "#                     WebDriverWait(driver, 20).until(\n",
    "#                         EC.presence_of_element_located((By.CSS_SELECTOR, \"div[class='media-body']\"))\n",
    "#                     )\n",
    "                    \n",
    "#                     workplace = driver.find_element(By.CSS_SELECTOR,\"span[id='lblCity']\").text\n",
    "#                     contract_type_elem = driver.find_element(By.CSS_SELECTOR,\"span[id='ltEmploymentType']\")\n",
    "#                     contract_type = contract_type_elem.find_element(By.CSS_SELECTOR,\"a\").text\n",
    "                    \n",
    "#                     # driver.execute_script(\"arguments[0].click();\",description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "                    \n",
    "#                     WebDriverWait(driver, 3)\n",
    "\n",
    "#                     try:\n",
    "#                         profile_elem = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='job-section-experience']\")\n",
    "#                         profile_html = profile_elem.find_elements(By.CSS_SELECTOR, \"div\")[-2].get_attribute(\"innerHTML\")\n",
    "#                         profile = BeautifulSoup(profile_html, 'html.parser').get_text()\n",
    "#                     except NoSuchElementException:\n",
    "#                         # If profile element is not found, set it to \"NULL\"\n",
    "#                         profile = \"NULL\"\n",
    "#                     # driver.execute_script(\"arguments[0].click();\",profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "\n",
    "#                     description = description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "#                     # profile = profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "                    \n",
    "#                     #parsing tags\n",
    "#                     # description = BeautifulSoup(description, 'html.parser').get_text()\n",
    "#                     # company_elem = driver.find_element(By.CSS_SELECTOR,\"a[href*='/fr/companies/']\")\n",
    "#                     # company = company_elem.find_element(By.CSS_SELECTOR,\"img\").get_attribute(\"alt\")\n",
    "#                     # long_infos = \" \".join([description,profile])\n",
    "#                     # print(long_infos)\n",
    "#                     # Wait for the child element to become present in the DOM\n",
    "\n",
    "#                     # # Get the page source after the click\n",
    "#                     # page_source = driver.page_source\n",
    "\n",
    "#                     # Use Beautiful Soup to parse the page source\n",
    "#                     # soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "#                     # Example: Retrieve the text of a specific element\n",
    "#                     # desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "#                     # descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "#                     # profile = soup.select(\"h4:contains('Profil recherch√©') + p\")\n",
    "#                     # profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "#                     # position = soup.select_one(\"span[data-cy='jobTitle']\").text\n",
    "#                     # position_type = soup.select_one('h4:contains(\"Secteur d‚Äôactivit√© du poste\")+span').text\n",
    "#                     # long_infos = soup.select(\"section\")\n",
    "#                     # infos = [item.text.replace(\"\\n\",\" \").strip() for item in long_infos]\n",
    "#                     # infos = [re.sub(r'\\s+', ' ',item) for item in infos]\n",
    "#                     # infos = \" \".join([item for item in infos if item != ''])\n",
    "#                     # infos = [item for item in infos if '' not in item]\n",
    "#                     corpus.append({\"source\":source,\"link\":rootLink,\"position\":position,\"position_type\":\"NULL\",\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":long_infos})\n",
    "#                 except Exception as e:\n",
    "#                     # Print the exception for debugging purposes\n",
    "#                     print(f\"Error: {e}\")\n",
    "\n",
    "#                 finally:\n",
    "#                     # Navigate back to the main page\n",
    "#                     driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             # Print the exception for debugging purposes\n",
    "#             print(f\"Error: {e}\")\n",
    "\n",
    "# finally:\n",
    "#     driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m         deny_cookies_button \u001b[38;5;241m=\u001b[39m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_to_be_clickable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbutton#pecookies-continue-btn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m         deny_cookies_button\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutException:\n",
      "File \u001b[1;32mc:\\Users\\leogo\\miniconda3\\envs\\text-mining\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:86\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     84\u001b[0m     screen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(exc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     85\u001b[0m     stacktrace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(exc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstacktrace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 86\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Probl√®me toutes les entreprises sont Adecco, si autre, redirection sur un autre site\n",
    "# source = \"jobintree\"\n",
    "# rootLink = \"https://www.jobintree.com\"\n",
    "# service = ChromeService(\"C:/Users/leogo/Documents/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "# driver = webdriver.Chrome(service=service) \n",
    "# keyword=\"data\"\n",
    "# pages=1\n",
    "# nb_docs=33\n",
    "# corpus = list()\n",
    "# try:\n",
    "#     for page in range(pages):    \n",
    "#         try:\n",
    "#             driver.get(f'{rootLink}/emploi?keywords={keyword}&page={page}')\n",
    "#             # Initial find of elements\n",
    "                \n",
    "#             offers = WebDriverWait(driver, 10).until(\n",
    "#                 EC.presence_of_element_located((By.CSS_SELECTOR, \"div[class='annonces_normales']\"))\n",
    "#             )\n",
    "\n",
    "#             offers = offers.find_elements(By.CSS_SELECTOR,\"a\")\n",
    "#             print(len(offers))\n",
    "#             # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#             # Getting docs left if last page to query\n",
    "#             if nb_docs%20!= 0 and page==pages-1: \n",
    "#                 limit = nb_docs%20\n",
    "#                 div_elements_to_click_list = offers[:limit]\n",
    "#             else :\n",
    "#                 div_elements_to_click_list = offers\n",
    "#             # print(len(div_elements_to_click_list))\n",
    "#             for index in range(len(div_elements_to_click_list)):\n",
    "#                 try:\n",
    "#                     WebDriverWait(driver, 10).until(\n",
    "#                         EC.presence_of_element_located((By.CSS_SELECTOR, \"a[id='hypViewJob']\"))\n",
    "#                     )\n",
    "                    \n",
    "#                     div_elements_to_click_list = offers\n",
    "#                     div_elements_to_click = div_elements_to_click_list[index]\n",
    "#                     # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#                     # driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "#                     # Check if the index is within the valid range\n",
    "#                     # div_offer = div_elements_to_click.find_element(By.CSS_SELECTOR,\"div\")\n",
    "\n",
    "#                     # position_elem = div_offer.find_element(By.CSS_SELECTOR,\"h4\")\n",
    "#                     # position = position_elem.text\n",
    "#                     # workplace = position_elem.find_elements(By.XPATH, \"./following::*//span\")[1].text\n",
    "#                     # contract_type_icon = div_offer.find_element(By.CSS_SELECTOR,\"i[name='contract']\")\n",
    "#                     # main_contract_div = driver.execute_script(\"return arguments[0].parentNode;\", contract_type_icon)\n",
    "#                     # contract_type = main_contract_div.find_element(By.CSS_SELECTOR,\"span\").text\n",
    "#                     # published_date = div_offer.find_element(By.CSS_SELECTOR,\"time\").get_attribute(\"datetime\").split(\"T\")[0]\n",
    "#                     # published_date = datetime.strptime(published_date, '%Y-%m-%d')\n",
    "#                     # published_date = published_date.strftime('%d/%m/%Y')\n",
    "#                     # driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_elements_to_click)\n",
    "#                     # company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "#                     # contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "#                     # workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "#                     # published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "#                     # Scroll into view\n",
    "#                     # actions = ActionChains(driver)\n",
    "#                     # actions.move_to_element(div_elements_to_click).click().perform()\n",
    "#                     #On remote de deux niveau du bouton \"Voir offre\" pour pouvoir r√©cup√©rer les informations appropri√©es\n",
    "#                     # div_offer = driver.execute_script(\"return arguments[0].parentNode.parentNode;\", div_elements_to_click)\n",
    "#                     # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "#                     # company = company_elem.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "#                     # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "#                     # contract_type = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='contract']\").text\n",
    "#                     # workplace = div_offer.find_elements(By.CSS_SELECTOR, \"div[data-cy='loc']\")[-1].text\n",
    "#                     # published_date = div_offer.find_elements(By.CSS_SELECTOR, \"span[data-cy='publishDate']\")[-1].text\n",
    "\n",
    "#                     driver.execute_script(\"arguments[0].click();\", div_elements_to_click)\n",
    "\n",
    "#                     WebDriverWait(driver, 20).until(\n",
    "#                         EC.presence_of_element_located((By.CSS_SELECTOR, \"div[class='media-body']\"))\n",
    "#                     )\n",
    "                    \n",
    "#                     workplace = driver.find_element(By.CSS_SELECTOR,\"span[id='lblCity']\").text\n",
    "#                     contract_type_elem = driver.find_element(By.CSS_SELECTOR,\"span[id='ltEmploymentType']\")\n",
    "#                     contract_type = contract_type_elem.find_element(By.CSS_SELECTOR,\"a\").text\n",
    "                    \n",
    "#                     # driver.execute_script(\"arguments[0].click();\",description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "                    \n",
    "#                     WebDriverWait(driver, 3)\n",
    "\n",
    "#                     try:\n",
    "#                         profile_elem = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='job-section-experience']\")\n",
    "#                         profile_html = profile_elem.find_elements(By.CSS_SELECTOR, \"div\")[-2].get_attribute(\"innerHTML\")\n",
    "#                         profile = BeautifulSoup(profile_html, 'html.parser').get_text()\n",
    "#                     except NoSuchElementException:\n",
    "#                         # If profile element is not found, set it to \"NULL\"\n",
    "#                         profile = \"NULL\"\n",
    "#                     # driver.execute_script(\"arguments[0].click();\",profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "\n",
    "#                     description = description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "#                     # profile = profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "                    \n",
    "#                     #parsing tags\n",
    "#                     # description = BeautifulSoup(description, 'html.parser').get_text()\n",
    "#                     # company_elem = driver.find_element(By.CSS_SELECTOR,\"a[href*='/fr/companies/']\")\n",
    "#                     # company = company_elem.find_element(By.CSS_SELECTOR,\"img\").get_attribute(\"alt\")\n",
    "#                     # long_infos = \" \".join([description,profile])\n",
    "#                     # print(long_infos)\n",
    "#                     # Wait for the child element to become present in the DOM\n",
    "\n",
    "#                     # # Get the page source after the click\n",
    "#                     # page_source = driver.page_source\n",
    "\n",
    "#                     # Use Beautiful Soup to parse the page source\n",
    "#                     # soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "#                     # Example: Retrieve the text of a specific element\n",
    "#                     # desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "#                     # descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "#                     # profile = soup.select(\"h4:contains('Profil recherch√©') + p\")\n",
    "#                     # profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "#                     # position = soup.select_one(\"span[data-cy='jobTitle']\").text\n",
    "#                     # position_type = soup.select_one('h4:contains(\"Secteur d‚Äôactivit√© du poste\")+span').text\n",
    "#                     # long_infos = soup.select(\"section\")\n",
    "#                     # infos = [item.text.replace(\"\\n\",\" \").strip() for item in long_infos]\n",
    "#                     # infos = [re.sub(r'\\s+', ' ',item) for item in infos]\n",
    "#                     # infos = \" \".join([item for item in infos if item != ''])\n",
    "#                     # infos = [item for item in infos if '' not in item]\n",
    "#                     corpus.append({\"source\":source,\"link\":rootLink,\"position\":position,\"position_type\":\"NULL\",\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":long_infos})\n",
    "#                 except Exception as e:\n",
    "#                     # Print the exception for debugging purposes\n",
    "#                     print(f\"Error: {e}\")\n",
    "\n",
    "#                 finally:\n",
    "#                     # Navigate back to the main page\n",
    "#                     driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             # Print the exception for debugging purposes\n",
    "#             print(f\"Error: {e}\")\n",
    "\n",
    "# finally:\n",
    "#     driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = \"pole-emploi\"\n",
    "# rootLink = \"https://candidat.pole-emploi.fr\"\n",
    "# service = ChromeService(\"C:/Users/leogo/Documents/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "# driver = webdriver.Chrome(service=service) \n",
    "# keyword=\"data\"\n",
    "# pages=2\n",
    "# nb_docs=33\n",
    "# corpus = list()\n",
    "# try:\n",
    "#     driver.get(f'{rootLink}/offres/recherche?motsCles={keyword}&range=0-{nb_docs-1}')\n",
    "#     # Initial find of elements\n",
    "#     try:\n",
    "#         accept_cookies_button = WebDriverWait(driver, 10).until(\n",
    "#             EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#pecookies-accept-all'))\n",
    "#         )\n",
    "#         print(\"test\")\n",
    "#         accept_cookies_button.click()\n",
    "#     except TimeoutException:\n",
    "#         pass\n",
    "#     WebDriverWait(driver, 10).until(\n",
    "#     EC.presence_of_element_located((By.CSS_SELECTOR, \"a[class='media with-fav']\"))\n",
    "#     )\n",
    "\n",
    "#     offers = driver.find_elements(By.CSS_SELECTOR, \"a[class='media with-fav']\")\n",
    "\n",
    "#     div_elements_to_click_list = offers\n",
    "#     # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#     # Getting docs left if last page to query\n",
    "#     # print(len(div_elements_to_click_list))\n",
    "#     for index in range(len(div_elements_to_click_list)):\n",
    "#         try:\n",
    "#             WebDriverWait(driver, 10).until(\n",
    "#                 EC.presence_of_element_located((By.CSS_SELECTOR, \"a[class='media with-fav']\"))\n",
    "#             )\n",
    "#             offers = driver.find_elements(By.CSS_SELECTOR, \"a[class='media with-fav']\")\n",
    "\n",
    "#             div_elements_to_click_list = offers\n",
    "#             div_elements_to_click = div_elements_to_click_list[index]\n",
    "#             # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#             # driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "#             # Check if the index is within the valid range\n",
    "#             # div_offer = div_elements_to_click.find_element(By.CSS_SELECTOR,\"div\")\n",
    "\n",
    "#             # position_elem = div_offer.find_element(By.CSS_SELECTOR,\"h4\")\n",
    "#             # position = position_elem.text\n",
    "#             # workplace = position_elem.find_elements(By.XPATH, \"./following::*//span\")[1].text\n",
    "#             # contract_type_icon = div_offer.find_element(By.CSS_SELECTOR,\"i[name='contract']\")\n",
    "#             # main_contract_div = driver.execute_script(\"return arguments[0].parentNode;\", contract_type_icon)\n",
    "#             # contract_type = main_contract_div.find_element(By.CSS_SELECTOR,\"span\").text\n",
    "#             # published_date = div_offer.find_element(By.CSS_SELECTOR,\"time\").get_attribute(\"datetime\").split(\"T\")[0]\n",
    "#             # published_date = datetime.strptime(published_date, '%Y-%m-%d')\n",
    "#             # published_date = published_date.strftime('%d/%m/%Y')\n",
    "#             # driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_elements_to_click)\n",
    "#             # company = div_elements_to_click.find_element(By.CSS_SELECTOR, 'p.card-offer__company').text\n",
    "#             # contract_type = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[0].text\n",
    "#             # workplace = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[1].text\n",
    "#             # published_date = div_elements_to_click.find_elements(By.CSS_SELECTOR, 'ul.important-list > li')[2].text\n",
    "#             # Scroll into view\n",
    "#             # actions = ActionChains(driver)\n",
    "#             # actions.move_to_element(div_elements_to_click).click().perform()\n",
    "#             #On remote de deux niveau du bouton \"Voir offre\" pour pouvoir r√©cup√©rer les informations appropri√©es\n",
    "#             # div_offer = driver.execute_script(\"return arguments[0].parentNode.parentNode;\", div_elements_to_click)\n",
    "#             # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "#             # company = company_elem.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "#             # company_elem = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='companyName']\")\n",
    "#             # contract_type = div_offer.find_element(By.CSS_SELECTOR, \"span[data-cy='contract']\").text\n",
    "#             # workplace = div_offer.find_elements(By.CSS_SELECTOR, \"div[data-cy='loc']\")[-1].text\n",
    "#             # published_date = div_offer.find_elements(By.CSS_SELECTOR, \"span[data-cy='publishDate']\")[-1].text\n",
    "\n",
    "#             driver.execute_script(\"arguments[0].click();\", div_elements_to_click)\n",
    "\n",
    "#             WebDriverWait(driver, 3000).until(\n",
    "#                 EC.presence_of_element_located((By.CSS_SELECTOR, \"div[class='media-body']\"))\n",
    "#             )\n",
    "            \n",
    "#             # workplace = driver.find_element(By.CSS_SELECTOR,\"span[id='lblCity']\").text\n",
    "#             # contract_type_elem = driver.find_element(By.CSS_SELECTOR,\"span[id='ltEmploymentType']\")\n",
    "#             # contract_type = contract_type_elem.find_element(By.CSS_SELECTOR,\"a\").text\n",
    "            \n",
    "#             # # driver.execute_script(\"arguments[0].click();\",description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "            \n",
    "#             # WebDriverWait(driver, 3)\n",
    "\n",
    "#             # try:\n",
    "#             #     profile_elem = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='job-section-experience']\")\n",
    "#             #     profile_html = profile_elem.find_elements(By.CSS_SELECTOR, \"div\")[-2].get_attribute(\"innerHTML\")\n",
    "#             #     profile = BeautifulSoup(profile_html, 'html.parser').get_text()\n",
    "#             # except NoSuchElementException:\n",
    "#             #     # If profile element is not found, set it to \"NULL\"\n",
    "#             #     profile = \"NULL\"\n",
    "#             # driver.execute_script(\"arguments[0].click();\",profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-1].find_element(By.CSS_SELECTOR,\"span\"))\n",
    "\n",
    "#             # description = description_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "#             # profile = profile_elem.find_elements(By.CSS_SELECTOR,\"div\")[-2].get_attribute(\"innerHTML\")\n",
    "            \n",
    "#             #parsing tags\n",
    "#             # description = BeautifulSoup(description, 'html.parser').get_text()\n",
    "#             # company_elem = driver.find_element(By.CSS_SELECTOR,\"a[href*='/fr/companies/']\")\n",
    "#             # company = company_elem.find_element(By.CSS_SELECTOR,\"img\").get_attribute(\"alt\")\n",
    "#             # long_infos = \" \".join([description,profile])\n",
    "#             # print(long_infos)\n",
    "#             # Wait for the child element to become present in the DOM\n",
    "\n",
    "#             # # Get the page source after the click\n",
    "#             # page_source = driver.page_source\n",
    "\n",
    "#             # Use Beautiful Soup to parse the page source\n",
    "#             # soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "#             # Example: Retrieve the text of a specific element\n",
    "#             # desc = soup.select(\"h4:contains('Descriptif du poste') + p\")\n",
    "#             # descText = [\"\".join(elem.text) for elem in desc][0]\n",
    "\n",
    "#             # profile = soup.select(\"h4:contains('Profil recherch√©') + p\")\n",
    "#             # profileText = [\"\".join(elem.text) for elem in profile][0]                  \n",
    "\n",
    "#             # position = soup.select_one(\"span[data-cy='jobTitle']\").text\n",
    "#             # position_type = soup.select_one('h4:contains(\"Secteur d‚Äôactivit√© du poste\")+span').text\n",
    "#             # long_infos = soup.select(\"section\")\n",
    "#             # infos = [item.text.replace(\"\\n\",\" \").strip() for item in long_infos]\n",
    "#             # infos = [re.sub(r'\\s+', ' ',item) for item in infos]\n",
    "#             # infos = \" \".join([item for item in infos if item != ''])\n",
    "#             # infos = [item for item in infos if '' not in item]\n",
    "#             # corpus.append({\"source\":source,\"link\":rootLink,\"position\":position,\"position_type\":\"NULL\",\"company\":company,\"workplace\":workplace,\"published_date\":published_date,\"contract_type\":contract_type,\"description\":long_infos})\n",
    "#         except Exception as e:\n",
    "#             # Print the exception for debugging purposes\n",
    "#             print(f\"Error: {e}\")\n",
    "\n",
    "#         finally:\n",
    "#             # Navigate back to the main page\n",
    "#             driver.execute_script(\"window.history.go(-1);\")\n",
    "# finally:\n",
    "#     driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed with status code 404\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"fr\" xml:lang=\"fr\" class=\"no-js\">\n",
      "\t<head> \n",
      " <meta name=\"robots\" content=\"noindex,nofollow\"/>\n",
      " <meta name=\"pragma\" content=\"no-cache\"/>\n",
      "\t\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
      "\t\t<meta charset=\"utf-8\">\n",
      "\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\t\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "\n",
      "\t\t<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->\n",
      "\t\t<meta name=\"description\" content=\"\">\n",
      "\t\t<meta name=\"author\" content=\"\">\n",
      "\t\t<link rel=\"icon\" href=\"favicon.ico\">\n",
      "\n",
      "\t\t<title>Erreur 404 | pole-emploi.fr, fusion des sites anpe.fr et assedic.fr</title>\n",
      "\t\t<link href=\"/css/pages-autonomes.css\" rel=\"stylesheet\">\n",
      "\t\t<!-- JS -->\n",
      "\t\t<script src=\"/js/jquery.min.js\"></script>\n",
      "\t\t<!--[if lt IE 9]>\n",
      "\t\t\t<script src=\"/js/ie8-svg-support.js\"></script>\n",
      "\t\t\t<script src=\"/js/html5shiv.min.js\"></script>\n",
      "\t\t\t<script src=\"/js/respond.min.js\"></script>\n",
      "\t\t<![endif]-->\n",
      "\t</head>\n",
      "\t<body class=\"candidat erreur\"> \n",
      "\t\t<div class=\"container small-container text-center\">\n",
      "\t\t\t<header role=\"banner\" class=\"text-center\">\t\n",
      "\t\t\t\t<a href=\"http://www.pole-emploi.fr\">\n",
      "\t\t\t\t\t<img src=\"/img/logo-pe.svg\" alt=\"Logo de P√É¬¥le emploi\" /><span class=\"sr-only\">Accueil P√É¬¥le emploi</span>\n",
      "\t\t\t\t</a>\n",
      "\t\t\t\t<h1 class=\"t2\">Page <span class=\"text-candidat\">introuvable</span></h1>\t\t\n",
      "\t\t\t</header>\n",
      "\t\t\t\n",
      "\t\t\t<hr aria-hidden=\"true\">\n",
      "\t\t\t<p class=\"t5\">La page demand√É¬©e n'est malheureusement pas disponible</p>\n",
      "\t\t\t<a class=\"btn btn-primary btn-lg btn-block\" href=\"http://www.pole-emploi.fr\" role=\"button\">Retour</a>\t\n",
      "\t\t\t\t\n",
      "\t\t</div>\n",
      "\t\t<footer role=\"content-info\" class=\"footer center-block text-center\">\n",
      "\t\t\t<div class=\"container-fluid\">\n",
      "\t\t\t\t<small>&#169; 2016 POLE EMPLOI. Tous droits r√É¬©serv√É¬©s.</small>\n",
      "\t\t\t</div>\n",
      "\t\t</footer>\n",
      "\t\t<!-- fin de la page -->\n",
      "\t</body>\t\n",
      "<script type=\"text/javascript\">\n",
      "xtnv = document;\n",
      "xtsd = \"http://logp6\";\n",
      "xtsite = \"475540\";\n",
      "xtn2 = \"10\";\n",
      "xtpage = \"api::Page_indisponible_(Erreur_404-candidat.html)\";\n",
      "xterr = \"\";\n",
      "xtmc = \"\";\n",
      "xtnp = \"\";\n",
      "xt_ac = \"\";\n",
      "xt_an = \"\";\n",
      "xtprm = \"\";\n",
      "roimt = \"\";\n",
      "roitest = false;\n",
      "visiteciblee = false;\n",
      "xtidmod = \"\";\n",
      "xtergo = \"0\";\n",
      "xt_multc = \"&amp;x1=Tapestry&amp;x2=Transverse&amp;x3=0\"; //all the xi indicators (like \"&x1=...&x2=....&x3=...\")\n",
      "</script>\n",
      "<script src=\"/js/xtclicks.js\" type=\"text/javascript\" ></script>\n",
      "<script src=\"/js/xtcore.js\" type=\"text/javascript\" ></script>\n",
      "<noscript>\n",
      "<img alt=\"\" height=\"1\" src=\"http://logp6.xiti.com/hit.xiti?s=475540&amp;s2=10&amp;p=api::Page_indisponible_(Erreur_404-candidat.html)&amp;roimt=&amp;roivc=&amp;x1=Tapestry&amp;x2=Transverse&amp;x3=0\" width=\"1\">\n",
      "</noscript>\n",
      "\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
